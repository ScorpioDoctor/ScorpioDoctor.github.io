

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
    <title>无监督学习: 探索寻找数据的表现方式(representations) &#8212; scikit-learn 0.20.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../../static/css/bootstrap-responsive.css"/>

    <link rel="stylesheet" href="../../static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../static/documentation_options.js"></script>
    <script type="text/javascript" src="../../static/jquery.js"></script>
    <script type="text/javascript" src="../../static/underscore.js"></script>
    <script type="text/javascript" src="../../static/doctools.js"></script>
    <script type="text/javascript" src="../../static/js/copybutton.js"></script>
    <script type="text/javascript" src="../../static/js/extra.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="shortcut icon" href="../../static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="将所有东西放在一起" href="putting_together.html" />
    <link rel="prev" title="模型选择: 选择合适的估计器及其参数" href="model_selection.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../static/js/bootstrap.min.js" type="text/javascript"></script>
  <script>
     VERSION_SUBDIR = (function(groups) {
         return groups ? groups[1] : null;
     })(location.href.match(/^https?:\/\/scikit-learn.org\/([^\/]+)/));
  </script>
  <link rel="canonical" href="http://scikit-learn.org/stable/tutorial/statistical_inference/unsupervised_learning.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    function showMenu() {
      var topNav = document.getElementById("scikit-navbar");
      if (topNav.className === "navbar") {
          topNav.className += " responsive";
      } else {
          topNav.className = "navbar";
      }
    };
  </script>

  <!-- 百度站长统计代码 -->
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?e7836e37a4cb7584127a787e9b44e3f1";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  </head><body>

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../../index.html">
            <img src="../../static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar" id="scikit-navbar">
            <ul>
                <li><a href="../../index.html">首页</a></li>
                <li><a href="../../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn <script>document.write(DOCUMENTATION_OPTIONS.VERSION + (VERSION_SUBDIR ? " (" + VERSION_SUBDIR + ")" : ""));</script></li>
            <li><a href="../index.html">教程</a></li>
            <li><a href="../../user_guide.html">用户指南</a></li>
            <li><a href="../../modules/classes.html">API</a></li>
            <li><a href="../../glossary.html">术语表</a></li>
            <li><a href="../../faq.html">FAQ</a></li>
            <li><a href="../../developers/contributing.html">贡献者</a></li>
            <li class="divider"></li>
                <script>if (VERSION_SUBDIR != "stable") document.write('<li><a href="http://scikit-learn.org/stable/documentation.html">稳定版</a></li>')</script>
                <script>if (VERSION_SUBDIR != "dev") document.write('<li><a href="http://scikit-learn.org/dev/documentation.html">开发版</a></li>')</script>
                <li><a href="http://scikit-learn.org/dev/versions.html">所有可用版本</a></li>
                <li><a href="../../downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../../auto_examples/index.html">案例</a></li>
            </ul>
            <a href="javascript:void(0);" onclick="showMenu()">
                <div class="nav-icon">
                    <div class="hamburger-line"></div>
                    <div class="hamburger-line"></div>
                    <div class="hamburger-line"></div>
                </div>
            </a>
            <div class="search_form">
                <div class="gcse-search" id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- GitHub "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    
        <div class="rellink">
        <a href="model_selection.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        模型选择: 选择合适的估计器及其参数
        </span>
            <span class="hiddenrellink">
            模型选择: 选择合适的估计器及其参数
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="putting_together.html"
        accesskey="N">Next
        <br/>
        <span class="smallrellink">
        将所有东西放在一起
        </span>
            <span class="hiddenrellink">
            将所有东西放在一起
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="index.html">
        Up
        <br/>
        <span class="smallrellink">
        用于科学数据处理的统计学习教程
        </span>
            <span class="hiddenrellink">
            用于科学数据处理的统计学习教程
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version"><b>scikit-learn v0.20.1</b><br/>
      <a href="http://scikit-learn.org/dev/versions.html">其他版本</a></p>
    <p class="citing">该中文文档由人工智能社区的<a href="http://www.studyai.com/antares" target="_blank">Antares</a>翻译!</p>
    <ul>
<li><a class="reference internal" href="#">无监督学习: 探索寻找数据的表现方式(representations)</a><ul>
<li><a class="reference internal" href="#id1">聚类: 把观测数据分组</a><ul>
<li><a class="reference internal" href="#k-means">K-means 聚类</a></li>
<li><a class="reference internal" href="#ward">分层聚合聚类法: Ward</a><ul>
<li><a class="reference internal" href="#connectivity-constrained-clustering">连接约束聚类(Connectivity-constrained clustering)</a></li>
<li><a class="reference internal" href="#feature-agglomeration">特征聚集(Feature agglomeration)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id6">分解: 从整个信号到其各个分量与负载</a><ul>
<li><a class="reference internal" href="#pca">主成分分析: PCA</a></li>
<li><a class="reference internal" href="#ica">独立分量分析: ICA</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="representations">
<h1>无监督学习: 探索寻找数据的表现方式(representations)<a class="headerlink" href="#representations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>聚类: 把观测数据分组<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first">聚类算法要解决啥样的问题？</p>
<p>对于 iris 数据集来说，我们知道所有样本有 3 种不同的类型，但是并不知道每一个样本是那种类型：
此时我们可以尝试一个 <a href="#id2"><span class="problematic" id="id3">**</span></a>clustering task**（聚类任务） 聚类算法: 将样本进行分组，相似的样本被聚在一起，
而不同组别之间的样本是有明显区别的，这样的分组方式就是 clusters（聚类）。</p>
</div>
<div class="section" id="k-means">
<h3>K-means 聚类<a class="headerlink" href="#k-means" title="Permalink to this headline">¶</a></h3>
<p>关于聚类有很多不同的聚类标准和相关算法，其中最简便的算法是 <a class="reference internal" href="../../modules/clustering.html#k-means"><span class="std std-ref">K-均值(K-means)</span></a>。</p>
<a class="reference external image-reference" href="../../auto_examples/cluster/plot_cluster_iris.html"><img alt="../../images/sphx_glr_plot_cluster_iris_002.png" class="align-right" src="../../images/sphx_glr_plot_cluster_iris_002.png" style="width: 280.0px; height: 210.0px;" /></a>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_iris</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_iris</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">k_means</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k_means</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span> 
<span class="go">KMeans(algorithm=&#39;auto&#39;, copy_x=True, init=&#39;k-means++&#39;, ...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">k_means</span><span class="o">.</span><span class="n">labels_</span><span class="p">[::</span><span class="mi">10</span><span class="p">])</span>
<span class="go">[1 1 1 1 1 0 0 0 0 0 2 2 2 2 2]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y_iris</span><span class="p">[::</span><span class="mi">10</span><span class="p">])</span>
<span class="go">[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>k_means 算法无法保证聚类结果完全绝对真实的反应实际情况。首先，选择正确合适的聚类数量不是一件容易的事情，
第二，该算法对初始值的设置敏感，容易陷入局部最优。尽管 scikit-learn 采取了不同的方式来缓解以上问题，
目前仍没有完美的解决方案。</p>
<table border="1" class="centered docutils">
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference external" href="../../auto_examples/cluster/plot_cluster_iris.html"><img alt="k_means_iris_bad_init" src="../../images/sphx_glr_plot_cluster_iris_003.png" style="width: 252.0px; height: 189.0px;" /></a></td>
<td><a class="reference external" href="../../auto_examples/cluster/plot_cluster_iris.html"><img alt="k_means_iris_8" src="../../images/sphx_glr_plot_cluster_iris_001.png" style="width: 252.0px; height: 189.0px;" /></a></td>
<td><a class="reference external" href="../../auto_examples/cluster/plot_cluster_iris.html"><img alt="cluster_iris_truth" src="../../images/sphx_glr_plot_cluster_iris_004.png" style="width: 252.0px; height: 189.0px;" /></a></td>
</tr>
<tr class="row-even"><td><strong>Bad initialization</strong></td>
<td><strong>8 clusters</strong></td>
<td><strong>Ground truth</strong></td>
</tr>
</tbody>
</table>
<p class="last"><strong>Don’t over-interpret clustering results</strong></p>
</div>
<div class="topic">
<p class="topic-title first"><strong>应用案例:向量量化(vector quantization)</strong></p>
<p>一般来说, 聚类方法,特别是 K_means 聚类, 可以作为一种用少量样本来压缩信息的方式。
这种方式有时候被称作 <a class="reference external" href="https://en.wikipedia.org/wiki/Vector_quantization">vector quantization</a> 。
例如，K_means 算法可以用于对一张图片进行色调分离</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>   <span class="n">face</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">face</span><span class="p">(</span><span class="n">gray</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
<span class="gp">... </span>   <span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">misc</span>
<span class="gp">... </span>   <span class="n">face</span> <span class="o">=</span> <span class="n">misc</span><span class="o">.</span><span class="n">face</span><span class="p">(</span><span class="n">gray</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># We need an (n_sample, n_feature) array</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k_means</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">k_means</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
<span class="go">KMeans(algorithm=&#39;auto&#39;, copy_x=True, init=&#39;k-means++&#39;, ...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">values</span> <span class="o">=</span> <span class="n">k_means</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">k_means</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">face_compressed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">choose</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">face_compressed</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<table border="1" class="centered docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference external" href="../../auto_examples/cluster/plot_face_compress.html"><img alt="face" src="../../images/sphx_glr_plot_face_compress_001.png" style="width: 180.0px; height: 132.0px;" /></a></td>
<td><a class="reference external" href="../../auto_examples/cluster/plot_face_compress.html"><img alt="face_compressed" src="../../images/sphx_glr_plot_face_compress_003.png" style="width: 180.0px; height: 132.0px;" /></a></td>
<td><a class="reference external" href="../../auto_examples/cluster/plot_face_compress.html"><img alt="face_regular" src="../../images/sphx_glr_plot_face_compress_002.png" style="width: 180.0px; height: 132.0px;" /></a></td>
<td><a class="reference external" href="../../auto_examples/cluster/plot_face_compress.html"><img alt="face_histogram" src="../../images/sphx_glr_plot_face_compress_004.png" style="width: 180.0px; height: 132.0px;" /></a></td>
</tr>
<tr class="row-even"><td>Raw image</td>
<td>K-means quantization</td>
<td>Equal bins</td>
<td>Image histogram</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="ward">
<h3>分层聚合聚类法: Ward<a class="headerlink" href="#ward" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../../modules/clustering.html#hierarchical-clustering"><span class="std std-ref">层次聚类(Hierarchical clustering)</span></a> 方法是一种旨在构建聚类层次结构的聚类分析方法，
一般来说，实现该算法的大多数方法有以下两种:</p>
<blockquote>
<div><ul class="simple">
<li><strong>聚合(Agglomerative)</strong> - 自底向上的方法: 初始阶段，每一个样本将自己作为单独的一个簇，聚类的簇以最小
化距离的标准进行迭代聚合。当感兴趣的簇只有少量的样本时，该方法是很合适的。
如果需要聚类的 簇数量很大，该方法比K_means算法的计算效率也更高。</li>
<li><strong>分裂(Divisive)</strong> -自顶向下的方法: 初始阶段，所有的样本是一个簇，当一个簇下移时，它被迭代的进 行分裂。
当估计聚类簇数量较大的数据时，该算法不仅效率低(由于样本始于一个簇，需要被递归的进行 分裂)，
而且从统计学的角度来讲也是不合适的。</li>
</ul>
</div></blockquote>
<div class="section" id="connectivity-constrained-clustering">
<h4>连接约束聚类(Connectivity-constrained clustering)<a class="headerlink" href="#connectivity-constrained-clustering" title="Permalink to this headline">¶</a></h4>
<p>对于逐次聚合聚类(agglomerative clustering)，通过连接图可以指定哪些样本可以被聚合在一个簇。在 scikit-learn 中，图由邻接矩阵来表示，
通常该矩阵是一个稀疏矩阵。这种表示方法是非常有用的，例如在聚类图像时检索连接区域(有时也被称为连接要素):</p>
<a class="reference external image-reference" href="../../auto_examples/cluster/plot_coin_ward_segmentation.html"><img alt="../../images/sphx_glr_plot_coin_ward_segmentation_001.png" class="align-right" src="../../images/sphx_glr_plot_coin_ward_segmentation_001.png" style="width: 200.0px; height: 200.0px;" /></a>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">skimage.data</span> <span class="k">import</span> <span class="n">coins</span>
<span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="k">import</span> <span class="n">rescale</span>

<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.image</span> <span class="k">import</span> <span class="n">grid_to_graph</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="k">import</span> <span class="n">AgglomerativeClustering</span>


<span class="c1"># #############################################################################</span>
<span class="c1"># Generate data</span>
<span class="n">orig_coins</span> <span class="o">=</span> <span class="n">coins</span><span class="p">()</span>

<span class="c1"># Resize it to 20% of the original size to speed up the processing</span>
<span class="c1"># Applying a Gaussian filter for smoothing prior to down-scaling</span>
<span class="c1"># reduces aliasing artifacts.</span>
<span class="n">smoothened_coins</span> <span class="o">=</span> <span class="n">gaussian_filter</span><span class="p">(</span><span class="n">orig_coins</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rescaled_coins</span> <span class="o">=</span> <span class="n">rescale</span><span class="p">(</span><span class="n">smoothened_coins</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;reflect&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">rescaled_coins</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># #############################################################################</span>
<span class="c1"># Define the structure A of the data. Pixels connected to their neighbors.</span>
<span class="n">connectivity</span> <span class="o">=</span> <span class="n">grid_to_graph</span><span class="p">(</span><span class="o">*</span><span class="n">rescaled_coins</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="feature-agglomeration">
<h4>特征聚集(Feature agglomeration)<a class="headerlink" href="#feature-agglomeration" title="Permalink to this headline">¶</a></h4>
<p>我们已经知道，稀疏性可以缓解特征维度带来的问题，i.e 即与特征数量相比，样本数量太少。
另一个解决该问题的方式是合并相似的维度：<a href="#id4"><span class="problematic" id="id5">**</span></a>feature agglomeration**（特征聚集）。
该方法可以通过对特征聚类来实现。换 句话说，就是对样本数据转置后进行聚类。</p>
<a class="reference external image-reference" href="../../auto_examples/cluster/plot_digits_agglomeration.html"><img alt="../../images/sphx_glr_plot_digits_agglomeration_001.png" class="align-right" src="../../images/sphx_glr_plot_digits_agglomeration_001.png" style="width: 227.99999999999997px; height: 199.49999999999997px;" /></a>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">connectivity</span> <span class="o">=</span> <span class="n">grid_to_graph</span><span class="p">(</span><span class="o">*</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">agglo</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">FeatureAgglomeration</span><span class="p">(</span><span class="n">connectivity</span><span class="o">=</span><span class="n">connectivity</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="n">n_clusters</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">agglo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
<span class="go">FeatureAgglomeration(affinity=&#39;euclidean&#39;, compute_full_tree=&#39;auto&#39;,...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">agglo</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_approx</span> <span class="o">=</span> <span class="n">agglo</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images_approx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_approx</span><span class="p">,</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first"><code class="docutils literal notranslate"><span class="pre">transform</span></code> and <code class="docutils literal notranslate"><span class="pre">inverse_transform</span></code> methods</p>
<p>Some estimators expose a <code class="docutils literal notranslate"><span class="pre">transform</span></code> method, for instance to reduce
the dimensionality of the dataset.</p>
</div>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>分解: 从整个信号到其各个分量与负载<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first"><strong>Components and loadings (成分和载荷)</strong></p>
<p>如果 X 是多维数据，那么我们试图解决的问题是在不同的观察基础上对数据进行重写：
我们希望学习得到载荷 L 和成分 C 使得 <em>X = L C</em> 。提取成分 C 有多种不同的方法。</p>
</div>
<div class="section" id="pca">
<h3>主成分分析: PCA<a class="headerlink" href="#pca" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../../modules/decomposition.html#pca"><span class="std std-ref">主成分分析 (PCA)</span></a> 将能够解释数据信息最大方差的的连续成分提取出来(selects the successive components that
explain the maximum variance in the signal)。</p>
<p class="centered"><a class="reference external" href="../../auto_examples/decomposition/plot_pca_3d.html"><img alt="pca_3d_axis" src="../../images/sphx_glr_plot_pca_3d_001.png" style="width: 280.0px; height: 210.0px;" /></a> <a class="reference external" href="../../auto_examples/decomposition/plot_pca_3d.html"><img alt="pca_3d_aligned" src="../../images/sphx_glr_plot_pca_3d_002.png" style="width: 280.0px; height: 210.0px;" /></a></p>
<p>上图中样本点的分布在一个方向上是非常平坦的：即三个单变量特征中的任何一个都可以有另外两个特征来表示。
主成分分析法(PCA)可以找到使得数据分布不 flat 的矢量方向(可以反映数据主要信息的特征方向)。</p>
<p>当用PCA来 transform（转换） 数据时，它可以通过在主子空间(principal subspace)上投影来降低数据的维数。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a signal with only 2 useful dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x3</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">x2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">decomposition</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pca</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">PCA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">PCA(copy=True, iterated_power=&#39;auto&#39;, n_components=None, random_state=None,</span>
<span class="go">  svd_solver=&#39;auto&#39;, tol=0.0, whiten=False)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_</span><span class="p">)</span>  
<span class="go">[  2.18565811e+00   1.19346747e+00   8.43026679e-32]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># As we can see, only the 2 first components are useful</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pca</span><span class="o">.</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_reduced</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(100, 2)</span>
</pre></div>
</div>
</div>
<div class="section" id="ica">
<h3>独立分量分析: ICA<a class="headerlink" href="#ica" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="../../modules/decomposition.html#ica"><span class="std std-ref">独立分量分析(ICA)</span></a> 可以提取数据信息中的独立成分，这些成分载荷的分布包含了最多的独立信息(
selects components so that the distribution of their loadings carries
a maximum amount of independent information.)。
该方法能够恢复 <a href="#id7"><span class="problematic" id="id8">**</span></a>non-Gaussian**（非高斯）独立信号:</p>
<a class="reference external image-reference" href="../../auto_examples/decomposition/plot_ica_blind_source_separation.html"><img alt="../../images/sphx_glr_plot_ica_blind_source_separation_001.png" class="align-center" src="../../images/sphx_glr_plot_ica_blind_source_separation_001.png" style="width: 448.0px; height: 336.0px;" /></a>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generate sample data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">signal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">time</span><span class="p">)</span>  <span class="c1"># Signal 1 : sinusoidal signal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">time</span><span class="p">))</span>  <span class="c1"># Signal 2 : square signal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s3</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">sawtooth</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">time</span><span class="p">)</span>  <span class="c1"># Signal 3: saw tooth signal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S</span> <span class="o">+=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># Add noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S</span> <span class="o">/=</span> <span class="n">S</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Standardize data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Mix data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>  <span class="c1"># Mixing matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># Generate observations</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Compute ICA</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ica</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">FastICA</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S_</span> <span class="o">=</span> <span class="n">ica</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Get the estimated sources</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_</span> <span class="o">=</span> <span class="n">ica</span><span class="o">.</span><span class="n">mixing_</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>  <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_</span><span class="p">,</span> <span class="n">A_</span><span class="p">)</span> <span class="o">+</span> <span class="n">ica</span><span class="o">.</span><span class="n">mean_</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2007 - 2018, scikit-learn developers (BSD License).
      <a href="../../_sources/tutorial/statistical_inference/unsupervised_learning.rst.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="model_selection.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="putting_together.html">Next
      </a>
    </div>
    
     </div>

    
    <script>
        window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
        ga('create', 'UA-22606712-2', 'auto');
        ga('set', 'anonymizeIp', true);
        ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    
    <script>
      (function() {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </body>
</html>