

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>3.1. 交叉验证:评估估计器的性能 &#8212; scikit-learn 0.20.2 documentation</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.css" />

    <link rel="stylesheet" href="../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/copybutton.js"></script>
    <script type="text/javascript" src="../_static/js/extra.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.2. 通过网格搜索调节估计器超参数" href="grid_search.html" />
    <link rel="prev" title="3. 模型选择与评估" href="../model_selection.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../_static/js/bootstrap.min.js" type="text/javascript"></script>
<script>
  VERSION_SUBDIR = (function (groups) {
    return groups ? groups[1] : null;
  })(location.href.match(/^https?:\/\/scikit-learn.org\/([^\/]+)/));
</script>
<link rel="canonical" href="http://scikit-learn.org/stable/modules/cross_validation.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
    function () {
      $(this).css('background-color', '#FF9C34');
    },
    function () {
      $(this).css('background-color', '#A7D6E2');
    }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
      topNav.className += " responsive";
    } else {
      topNav.className = "navbar";
    }
  };
</script>

<!-- 百度站长统计代码 -->
<script>
  var _hmt = _hmt || [];
  (function () {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e7836e37a4cb7584127a787e9b44e3f1";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>


  </head><body>

<div class="header-wrapper">
  <div class="header">
    <p class="logo"><a href="../index.html">
        <img src="../_static/scikit-learn-logo-small.png" alt="Logo" />
      </a>
    </p><div class="navbar" id="scikit-navbar">
      <ul>
        <li><a href="../index.html">首页</a></li>
        <li><a href="../install.html">安装</a></li>
        <li class="btn-li">
          <div class="btn-group">
            <a href="../documentation.html">文档</a>
            <a class="btn dropdown-toggle" data-toggle="dropdown">
              <span class="caret"></span>
            </a>
            <ul class="dropdown-menu">
              <li class="link-title">Scikit-learn
                <script>document.write(DOCUMENTATION_OPTIONS.VERSION + (VERSION_SUBDIR ? " (" + VERSION_SUBDIR + ")" : ""));</script>
              </li>
              <li><a href="../tutorial/index.html">教程</a></li>
              <li><a href="../user_guide.html">用户指南</a></li>
              <li><a href="classes.html">API</a></li>
              <li><a href="../glossary.html">词汇表</a></li>
              <li><a href="../faq.html">FAQ</a></li>
              <li><a href="../developers/contributing.html">贡献</a></li>
              <li><a href="../roadmap.html">路线图</a></li>
              <li class="divider"></li>
              <script>if (VERSION_SUBDIR != "stable") document.write('<li><a href="https://www.studyai.cn">稳定版</a></li>')</script>
              <script>if (VERSION_SUBDIR != "dev") document.write('<li><a href="http://scikit-learn.org/dev/documentation.html" target="_blank">开发版</a></li>')</script>
              <li><a href="http://scikit-learn.org/dev/versions.html">所有可用版本</a></li>
              <li><a href="../_downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
            </ul>
          </div>
        </li>
        <li><a href="../auto_examples/index.html">案例</a></li>
      </ul>
      <a href="javascript:void(0);" onclick="showMenu()">
        <div class="nav-icon">
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
        </div>
      </a>
      <div class="search_form">
        <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div> <!-- end navbar --></div>
</div>


<!-- GitHub "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me" style="position: absolute; top: 0; right: 0; border: 0;" src="../_static/img/forkme.png"
    alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
      <div class="rel">
        
          <div class="rellink">
            <a href="../model_selection.html" accesskey="P">Previous
              <br />
              <span class="smallrellink">
                3. 模型选择与评估
              </span>
              <span class="hiddenrellink">
                3. 模型选择与评估
              </span>
            </a>
          </div>
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="grid_search.html" accesskey="N">Next
              <br />
              <span class="smallrellink">
                3.2. 通过网格搜索调节估计器超参数
              </span>
              <span class="hiddenrellink">
                3.2. 通过网格搜索调节估计器超参数
              </span>
            </a>
          </div>

          <!-- Ad a link to the 'up' page -->
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="../model_selection.html">
              Up
              <br />
              <span class="smallrellink">
                3. 模型选择与评估
              </span>
                <span class="hiddenrellink">
                  3. 模型选择与评估
                </span>
                
            </a>
          </div>
        </div>
        
        <p class="doc-version"><b>scikit-learn v0.20.2</b><br />
          <a href="http://scikit-learn.org/dev/versions.html">其他版本</a></p>
        <!-- <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite
              us </a></b>if you use the software.</p> -->
        <p class="citing">该中文文档由人工智能社区的<a href="http://www.studyai.com/antares" target="_blank">Antares</a>翻译!
        </p>
        <ul>
<li><a class="reference internal" href="#">3.1. 交叉验证:评估估计器的性能</a><ul>
<li><a class="reference internal" href="#id4">3.1.1. 计算交叉验证的测度</a><ul>
<li><a class="reference internal" href="#cross-validate">3.1.1.1. cross_validate 函数 与 多测度评估</a></li>
<li><a class="reference internal" href="#id5">3.1.1.2. 通过cross-validation获得预测</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id6">3.1.2. 交叉验证迭代器</a><ul>
<li><a class="reference internal" href="#i-i-d-cross-validation">3.1.2.1. 用于独立同分布(i.i.d.)数据的Cross-validation迭代器</a><ul>
<li><a class="reference internal" href="#k-k-fold">3.1.2.1.1. K-折法(K-fold)</a></li>
<li><a class="reference internal" href="#k">3.1.2.1.2. 重复K-折法</a></li>
<li><a class="reference internal" href="#loo">3.1.2.1.3. 留一法(LOO)</a></li>
<li><a class="reference internal" href="#p-lpo">3.1.2.1.4. 留P法(LPO)</a></li>
<li><a class="reference internal" href="#shufflesplit">3.1.2.1.5. 随机置换交叉验证,也就是: 洗牌 &amp; 分割</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id8">3.1.2.2. 基于类标签分层的Cross-validation迭代器.</a><ul>
<li><a class="reference internal" href="#stratified-k-fold">3.1.2.2.1. Stratified k-fold</a></li>
<li><a class="reference internal" href="#stratified-shuffle-split">3.1.2.2.2. Stratified Shuffle Split</a></li>
</ul>
</li>
<li><a class="reference internal" href="#group-cv">3.1.2.3. 用于分组数据的交叉验证迭代器.</a><ul>
<li><a class="reference internal" href="#group-k-fold">3.1.2.3.1. Group k-fold</a></li>
<li><a class="reference internal" href="#leave-one-group-out">3.1.2.3.2. Leave One Group Out</a></li>
<li><a class="reference internal" href="#leave-p-groups-out">3.1.2.3.3. Leave P Groups Out</a></li>
<li><a class="reference internal" href="#group-shuffle-split">3.1.2.3.4. Group Shuffle Split</a></li>
</ul>
</li>
<li><a class="reference internal" href="#predefined-fold-splits-validation-sets">3.1.2.4. Predefined Fold-Splits / Validation-Sets</a></li>
<li><a class="reference internal" href="#timeseries-cv">3.1.2.5. 时间序列数据的交叉验证</a><ul>
<li><a class="reference internal" href="#id13">3.1.2.5.1. 时间序列划分</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#id14">3.1.3. 随机洗牌需要注意的地方</a></li>
<li><a class="reference internal" href="#id15">3.1.4. 交叉验证与模型选择</a></li>
</ul>
</li>
</ul>

        <br />
        <p>
          <a href="http://www.studyai.com" target="_blank">
            <img src="../_static/img/xxx.png" alt="座右铭" />
          </a>
        </p>
        <br />
        <p class="doc-version" style="font-size:10%">
          注意!本网站的网址是以 <em>https://</em> 开头的，而不是以 <em>http://</em> 开头的!!!
        </p>
      </div>
    </div>
    
    <input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
    <label for="nav-trigger"></label>
    
    


    <div class="content">
      
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="cross-validation">
<span id="id1"></span><h1>3.1. 交叉验证:评估估计器的性能<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first">译者注</p>
<p>这一节的重点是交叉验证以及对应的数据集划分方法，再次献上我做的视频，希望对大家有所帮助。视频地址：
(<a class="reference external" href="http://www.studyai.com/course/play/e3fe73c3ebd44e86bd60c450acef94bf">交叉验证以及对应的数据集划分方法</a>)</p>
</div>
<p>学习 预测函数 的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，
但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 过拟合（ <strong>overfitting</strong> ）.
为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为测试集（ <strong>test set</strong> ）： <code class="docutils literal notranslate"><span class="pre">X_test,</span> <span class="pre">y_test</span></code>。</p>
<p>需要强调的是这里说的 “experiment(实验)” 并不仅限于学术（academic），因为即使是在商业场景下机器学习也往往是从实验开始的。</p>
<dl class="docutils">
<dt>利用 scikit-learn 包中的 <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a> 辅助函数可以很快地将实验数据集划分为训练集（training sets）和测试集（test sets）。</dt>
<dd><p class="first">下面让我们载入 iris 数据集，并在此数据集上训练出线性支持向量机</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((150, 4), (150,))</span>
</pre></div>
</div>
</dd>
</dl>
<p>我们能快速采样到原数据集的 40% 作为测试集，从而测试（评估）我们的分类器</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((90, 4), (90,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((60, 4), (60,))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>                           
<span class="go">0.96...</span>
</pre></div>
</div>
<p>当评价估计器的不同设置（”hyperparameters(超参数)”）时，例如手动为 SVM 设置的 <code class="docutils literal notranslate"><span class="pre">C</span></code> 参数，
由于在训练集上，通过调整参数设置使估计器的性能达到了最佳状态；但 在测试集上 可能会出现过拟合的情况。
此时，测试集上的信息反馈足以颠覆（”leak”）训练好的模型，评估的指标不再有效反映出模型的泛化性能。
为了解决此类问题，还应该准备另一部分被称为 “validation set(验证集)” 的数据集，模型训练完成以后在验证集上对模型进行评估。
当验证集上的评估实验比较成功时，在测试集上进行最后的评估。</p>
<p>然而，通过将原始数据分为3个数据集合，我们就大大减少了可用于模型训练的样本数量， 并且得到的结果依赖于集合对（训练，验证）的随机选择。</p>
<p>这个问题可以通过 交叉验证(<a class="reference external" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a>)（CV 缩写） 来解决。
交叉验证仍需要测试集做最后的模型评估，但不再需要验证集。
在所有CV方法中， 最基本的方法被称之为，<em>k</em>-折交叉验证 。 k-折交叉验证将原始的完整训练集划分为 <em>k</em> 个较小的集合（其他方法会在下面描述，主要原则基本相同）。
每一个 <em>k</em> “folds” 都会遵循下面的过程 :</p>
<blockquote>
<div><ul class="simple">
<li>将 <span class="math notranslate nohighlight">\(k-1\)</span> 份训练集子集作为 training data （训练集）训练模型;</li>
<li>将剩余的 1 份训练集子集作为验证集用于模型验证（也就是利用该数据子集计算模型的性能指标，例如准确率）。</li>
</ul>
</div></blockquote>
<p><em>k</em>-折交叉验证得出的性能指标是循环计算中每个验证集上的值的平均值。 该方法虽然计算代价很高，但是它不会浪费太多的数据
（如固定任意测试集的情况一样）， 在处理样本数据集较少的问题（例如，逆向推理）时比较有优势。</p>
<div class="section" id="id4">
<h2>3.1.1. 计算交叉验证的测度<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>使用交叉验证最简单的方法是在估计器和数据集上调用 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> 辅助函数。</p>
<p>下面的例子展示了如何通过分割数据，拟合模型和计算连续 5 次的分数（每次不同分割）来估计带有线性核函数的支持向量机在 iris 数据集上的精度:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span>                                              
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
</pre></div>
</div>
<p>评分估计的平均得分和 95% 置信区间由此给出</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%0.2f</span><span class="s2"> (+/- </span><span class="si">%0.2f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
<span class="go">Accuracy: 0.98 (+/- 0.03)</span>
</pre></div>
</div>
<p>默认情况下，每次 CV 迭代计算分数的方法是调用估计器的 <code class="docutils literal notranslate"><span class="pre">score</span></code> 方法。可以通过使用 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数来改变计算方式如下</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_macro&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span>                                              
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数的详情请参阅 <a class="reference internal" href="model_evaluation.html#scoring-parameter"><span class="std std-ref">scoring 参数: 定义模型评估准则</span></a> 。
在 Iris 数据集的情形下，样本在各个目标类别之间是平衡的，因此准确率和 F1-score 几乎相等。</p>
<p>当 <code class="docutils literal notranslate"><span class="pre">cv</span></code> 参数是一个整数时，<a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> 默认使用 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> 或 <a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> 策略，
后者会在估计器派生自 <a class="reference internal" href="generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassifierMixin</span></code></a> 时使用。</p>
<p>也可以通过传入一个交叉验证迭代器来使用其他交叉验证策略，比如</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">ShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>  
<span class="go">array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])</span>
</pre></div>
</div>
<p>另外一种可选方案是使用一个可迭代生成器作为索引数组产生(train, test) 划分，比如:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">custom_cv_2folds</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">... </span>    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">yield</span> <span class="n">idx</span><span class="p">,</span> <span class="n">idx</span>
<span class="gp">... </span>        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">custom_cv</span> <span class="o">=</span> <span class="n">custom_cv_2folds</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">custom_cv</span><span class="p">)</span>
<span class="go">array([1.        , 0.973...])</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">Data transformation with held out data</p>
<p>正如在训练集中保留的数据上测试一个 predictor （预测器）是很重要的一样，预处理（如标准化，特征选择等）和
类似的 <a class="reference internal" href="../data_transforms.html#data-transforms"><span class="std std-ref">data transformations</span></a> 也应该从训练集中学习，并应用于预测数据以进行预测:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_transformed</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  
<span class="go">0.9333...</span>
</pre></div>
</div>
<p><a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a> 可以更容易地组合估计器，在交叉验证下使用如下</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">make_pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="gp">... </span>                                                
<span class="go">array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="compose.html#combining-estimators"><span class="std std-ref">管道流与复合估计器(Pipelines and composite estimators)</span></a>.</p>
</div>
<div class="section" id="cross-validate">
<span id="multimetric-cross-validation"></span><h3>3.1.1.1. cross_validate 函数 与 多测度评估<a class="headerlink" href="#cross-validate" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> 函数与 <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> 在下面的两个方面有些不同 -</p>
<ul class="simple">
<li>它允许指定多个指标进行评估.</li>
<li>除了测试得分之外，它还会返回一个包含训练得分，拟合次数， score-times （得分次数）的一个字典。</li>
</ul>
<p>对于单个测度(single metric)评估，其中 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数是一个字符串，可调用对象 或 None ， keys 将是 - <code class="docutils literal notranslate"><span class="pre">['test_score',</span> <span class="pre">'fit_time',</span> <span class="pre">'score_time']</span></code></p>
<p>而对于多测度(multiple metric)评估，返回值是一个带有以下的 keys 的字典 -
<code class="docutils literal notranslate"><span class="pre">['test_&lt;scorer1_name&gt;',</span> <span class="pre">'test_&lt;scorer2_name&gt;',</span> <span class="pre">'test_&lt;scorer...&gt;',</span> <span class="pre">'fit_time',</span> <span class="pre">'score_time']</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">return_train_score</span></code> 默认设置为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 。 它增加了所有 scorers(得分器) 的训练得分 keys 。如果不需要训练 scores ，则应将其明确设置为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p>
<p>你还可以通过设置 <code class="docutils literal notranslate"><span class="pre">return_estimator=True</span></code> 来保留在所有训练集上拟合好的估计器。</p>
<p>可以将多个测度指标指定为 list ，tuple 或者是 预定义评分器(predefined scorer)的名字的集合</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">recall_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span> <span class="s1">&#39;recall_macro&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_precision_macro&#39;, &#39;test_recall_macro&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_recall_macro&#39;</span><span class="p">]</span>                       
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
</pre></div>
</div>
<p>或将多个测度指标指定为一个字典,该字典将评分器名称(scorer name)映射到预定义或自定义的得分函数(scoring function):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.scorer</span> <span class="k">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;prec_macro&#39;</span><span class="p">:</span> <span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span>
<span class="gp">... </span>           <span class="s1">&#39;rec_micro&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">recall_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>                 
<span class="go">[&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_prec_macro&#39;, &#39;test_rec_micro&#39;,</span>
<span class="go"> &#39;train_prec_macro&#39;, &#39;train_rec_micro&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_rec_micro&#39;</span><span class="p">]</span>                         
<span class="go">array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])</span>
</pre></div>
</div>
<p>这里是一个使用单一测度指标(single metric)的 <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> 的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;estimator&#39;, &#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_score&#39;, &#39;train_score&#39;]</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>3.1.1.2. 通过cross-validation获得预测<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>除了返回结果不同，函数 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> 具有和 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> 相同的接口， 对于每一个输入的元素，
如果其在测试集合中，将会得到预测结果。只有那些将所有元素分配到一个测试集合仅一次的交叉验证策略可以在这个函数中使用（否则会抛出一个异常）。
Only cross-validation strategies that assign all elements to a test set exactly once
can be used (otherwise, an exception is raised).</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>交叉预测(cross_val_predict)使用不当的注记</p>
<p class="last"><a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> 函数的结果可能会与 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> 函数的结果不一样，因为在这两种方法中元素的分组方式不一样
(elements are grouped in different ways) 。
函数 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> 在所有交叉验证的折子(cross-validation folds)上取平均。但是， 函数 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> 只是
简单的返回由若干不同模型预测出的标签或概率(labels or probabilities) 。 因此, <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a>
不是一种适当的泛化错误(generalisation error)的度量。</p>
</div>
<dl class="docutils">
<dt>函数 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> 比较适合做下列事儿:</dt>
<dd><ul class="first last simple">
<li>从不同模型获得的预测结果的可视化。</li>
<li>模型混合: When predictions of one supervised estimator are used to
train another estimator in ensemble methods.</li>
</ul>
</dd>
</dl>
<p>可用的交叉验证迭代器(cross validation iterators) 会在下面的章节介绍：</p>
<div class="topic">
<p class="topic-title first">案例</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Parameter estimation using grid search with cross-validation</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"><span class="std std-ref">Sample pipeline for text feature extraction and evaluation</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/model_selection/plot_cv_predict.html#sphx-glr-auto-examples-model-selection-plot-cv-predict-py"><span class="std std-ref">Plotting Cross-Validated Predictions</span></a>,</li>
<li><a class="reference internal" href="../auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py"><span class="std std-ref">Nested versus non-nested cross-validation</span></a>.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="id6">
<h2>3.1.2. 交叉验证迭代器<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>接下来的部分列出了一些用于生成索引标号，用于在不同的交叉验证策略中生成数据划分的工具。</p>
<div class="section" id="i-i-d-cross-validation">
<span id="iid-cv"></span><h3>3.1.2.1. 用于独立同分布(i.i.d.)数据的Cross-validation迭代器<a class="headerlink" href="#i-i-d-cross-validation" title="Permalink to this headline">¶</a></h3>
<p>假设一些数据是独立的和同分布的 (i.i.d); 假定所有的样本来源于相同的生成过程，
并假设生成过程没有记忆过去生成的样本。</p>
<p>在这种情况下可以使用下面的交叉验证器。</p>
<p><strong>NOTE</strong></p>
<p>尽管 i.i.d 数据是机器学习理论中的一个常见假设，但在实践中很少成立。如果知道样本是使用时间相关的过程生成的，
则使用 <a class="reference internal" href="#timeseries-cv"><span class="std std-ref">time-series aware cross-validation scheme</span></a> 更安全。
同样，如果我们知道生成过程具有分组结构(group structure)（从不同 subjects（主体），experiments（实验），
measurement devices（测量设备）收集的样本），则使用 <a class="reference internal" href="#group-cv"><span class="std std-ref">group-wise cross-validation</span></a> 更安全。</p>
<div class="section" id="k-k-fold">
<h4>3.1.2.1.1. K-折法(K-fold)<a class="headerlink" href="#k-k-fold" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> 将所有的样例划分为 <span class="math notranslate nohighlight">\(k\)</span> 个组，称为折叠(fold)（如果 <span class="math notranslate nohighlight">\(k = n\)</span>，这等价于 <em>Leave One Out</em> 策略），都具有相同的大小（如果可能）。
预测函数学习时使用其中的 <span class="math notranslate nohighlight">\(k - 1\)</span> 个折叠中的数据，最后一个剩下的折叠会用于测试。</p>
<p>在 4 个样例的数据集上使用 2-fold 交叉验证的例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">KFold</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[0 1] [2 3]</span>
</pre></div>
</div>
<p>这个例子是关于交叉验证的可视化的。请注意 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> is not affected by classes or groups.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0041.png" src="../_images/sphx_glr_plot_cv_indices_0041.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
<p>每个折叠由两个 arrays 组成，第一个作为 <em>training set</em> ，另一个作为 <em>test set</em> 。 由此，可以通过使用 numpy 的索引创建训练/测试集合:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="k">
<h4>3.1.2.1.2. 重复K-折法<a class="headerlink" href="#k" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold" title="sklearn.model_selection.RepeatedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedKFold</span></code></a> 重复 K-Fold n 次。当你需要运行 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> n 次 时可以使用它，在每次重复中产生不同的分割。</p>
<p>2折 K-Fold 重复 2 次的示例</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">RepeatedKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">12883823</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rkf</span> <span class="o">=</span> <span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">rkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="gp">...</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[0 1] [2 3]</span>
<span class="go">[0 2] [1 3]</span>
<span class="go">[1 3] [0 2]</span>
</pre></div>
</div>
<p>类似地， <a class="reference internal" href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a> 在每个重复中以不同的随机化重复 n 次 Stratified K-Fold 。</p>
</div>
<div class="section" id="loo">
<h4>3.1.2.1.3. 留一法(LOO)<a class="headerlink" href="#loo" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> (或 LOO) 是一个简单的交叉验证。每个学习集都是通过除去一个样本以外的所有剩余样本创建的，
测试集是被留下的样本。 因此，对于 <span class="math notranslate nohighlight">\(n\)</span> 个样本，我们有 <span class="math notranslate nohighlight">\(n\)</span> 个不同的训练集和 <span class="math notranslate nohighlight">\(n\)</span> 个不同的测试集。
这种交叉验证程序不会浪费太多数据，因为只有一个样本是从训练集中删除掉的</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">LeaveOneOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[1 2 3] [0]</span>
<span class="go">[0 2 3] [1]</span>
<span class="go">[0 1 3] [2]</span>
<span class="go">[0 1 2] [3]</span>
</pre></div>
</div>
<p>将LOO用于选择模型的潜在用户应该权衡一些已知的警告。
当把 LOO 与 <span class="math notranslate nohighlight">\(k\)</span>-fold CV 进行比较时，可以从 <span class="math notranslate nohighlight">\(n\)</span> 样本中构建 <span class="math notranslate nohighlight">\(n\)</span> 模型，而不是 <span class="math notranslate nohighlight">\(k\)</span> 模型，其中 <span class="math notranslate nohighlight">\(n &gt; k\)</span> 。
此外，每个模型在 <span class="math notranslate nohighlight">\(n - 1\)</span> 个样本而不是在 <span class="math notranslate nohighlight">\((k-1) n / k\)</span> 上进行训练。在两种方式中，假设 <span class="math notranslate nohighlight">\(k\)</span> 不是太大，
并且 <span class="math notranslate nohighlight">\(k &lt; n\)</span> ， LOO 比 <span class="math notranslate nohighlight">\(k\)</span>-fold CV 计算开销更加昂贵。</p>
<p>就精度而言，作为测试误差的估计器,LOO 经常导致较高的方差。直观地说，因为 <span class="math notranslate nohighlight">\(n\)</span> 个样本中的 <span class="math notranslate nohighlight">\(n - 1\)</span> 个被用来构建每个模型，
所以不同的两个fold包含的 <span class="math notranslate nohighlight">\(n - 1\)</span> 个训练样本几乎是一样的，所以从这些几乎一样的folds上构建的所有模型相互之间几乎完全相同，
并且这些模型与从整个训练集建立的模型也几乎完全一样。</p>
<p>但是，如果学习曲线对于所讨论的训练大小是陡峭的，那么 5- 或 10- 折交叉验证会过高的估计泛化误差(overestimate the generalization error)。</p>
<p>作为一般规则，大多数作者和经验证据表明， 5-folds 或者 10-folds 交叉验证应该优于 LOO 。</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li><a class="reference external" href="http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html">http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html</a>;</li>
<li>T. Hastie, R. Tibshirani, J. Friedman,  <a class="reference external" href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>, Springer 2009</li>
<li>L. Breiman, P. Spector <a class="reference external" href="http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf">Submodel selection and evaluation in regression: The X-random case</a>, International Statistical Review 1992;</li>
<li>R. Kohavi, <a class="reference external" href="http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf">A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</a>, Intl. Jnt. Conf. AI</li>
<li>R. Bharat Rao, G. Fung, R. Rosales, <a class="reference external" href="https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf">On the Dangers of Cross-Validation. An Experimental Evaluation</a>, SIAM 2008;</li>
<li>G. James, D. Witten, T. Hastie, R Tibshirani, <a class="reference external" href="http://www-bcf.usc.edu/~gareth/ISL">An Introduction to
Statistical Learning</a>, Springer 2013.</li>
</ul>
</div>
</div>
<div class="section" id="p-lpo">
<h4>3.1.2.1.4. 留P法(LPO)<a class="headerlink" href="#p-lpo" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut" title="sklearn.model_selection.LeavePOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePOut</span></code></a> 与 <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> 非常相似，因为它通过从整个集合中删除 <span class="math notranslate nohighlight">\(p\)</span> 个样本来创建所有可能的 训练/测试 集。
对于 <span class="math notranslate nohighlight">\(n\)</span> 个样本，这产生了 <span class="math notranslate nohighlight">\({n \choose p}\)</span> 个 训练-测试 对。与 <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> 和 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> 不同，
当 <span class="math notranslate nohighlight">\(p &gt; 1\)</span> 时，测试集会发生重叠。</p>
<p>在有 4 个样例的数据集上使用 Leave-2-Out 的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">LeavePOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpo</span> <span class="o">=</span> <span class="n">LeavePOut</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">lpo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[1 3] [0 2]</span>
<span class="go">[1 2] [0 3]</span>
<span class="go">[0 3] [1 2]</span>
<span class="go">[0 2] [1 3]</span>
<span class="go">[0 1] [2 3]</span>
</pre></div>
</div>
</div>
<div class="section" id="shufflesplit">
<span id="id7"></span><h4>3.1.2.1.5. 随机置换交叉验证,也就是: 洗牌 &amp; 分割<a class="headerlink" href="#shufflesplit" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a></p>
<p><a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> 迭代器 将会生成一个用户给定数量的独立的训练/测试数据划分。样例首先被打散然后划分为一对训练测试集合。</p>
<p>可以通过显示的设定 <code class="docutils literal notranslate"><span class="pre">random_state</span></code> ，使得伪随机生成器的结果可以重复。</p>
<p>这是一个使用 <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> 迭代器  的小例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">ShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">ss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">))</span>
<span class="go">[9 1 6 7 3 0 5] [2 8 4]</span>
<span class="go">[2 9 8 0 6 7 4] [3 5 1]</span>
<span class="go">[4 5 1 0 6 9 7] [2 3 8]</span>
<span class="go">[2 7 5 8 0 3 4] [6 1 9]</span>
<span class="go">[4 1 0 6 8 9 3] [5 2 7]</span>
</pre></div>
</div>
<p>这个例子是关于交叉验证的可视化的。请注意 <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> is not affected by classes or groups。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0061.png" src="../_images/sphx_glr_plot_cv_indices_0061.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
<p><a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> 可以替代 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> 交叉验证，因为其提供了细致的迭代数量，训练/测试划分的数量和 每一个划分中样例所占的比例等的控制。</p>
</div>
</div>
<div class="section" id="id8">
<h3>3.1.2.2. 基于类标签分层的Cross-validation迭代器.<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>一些分类问题在目标类别的分布上可能表现出很大的不平衡性：例如，可能会出现比正样本多数倍的负样本。在这种情况下，建议采用如
StratifiedKFold 和 StratifiedShuffleSplit 中实现的分层抽样方法(stratified sampling)，确保相对的类别频率在每个训练和验证 fold 中大致保留。</p>
<div class="section" id="stratified-k-fold">
<h4>3.1.2.2.1. Stratified k-fold<a class="headerlink" href="#stratified-k-fold" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> 是 <em>k-fold</em> 的变种，会返回 <em>stratified</em> folds ：每个小集合中，各个类别的样本比例大致和完整数据集中的样本类别比例相同。</p>
<p>在有10个样本的，有两个略不均衡类别的数据集上进行 stratified 3-fold 交叉验证的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">StratifiedKFold</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3 6 7 8 9] [0 1 4 5]</span>
<span class="go">[0 1 3 4 5 8 9] [2 6 7]</span>
<span class="go">[0 1 2 4 5 6 7] [3 8 9]</span>
</pre></div>
</div>
<p>Here is a visualization of the cross-validation behavior.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0071.png" src="../_images/sphx_glr_plot_cv_indices_0071.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
<p><a class="reference internal" href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a> 类可用于在每次重复中用不同的随机化重复stratified k-fold n 次。</p>
</div>
<div class="section" id="stratified-shuffle-split">
<h4>3.1.2.2.2. Stratified Shuffle Split<a class="headerlink" href="#stratified-shuffle-split" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit" title="sklearn.model_selection.StratifiedShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code></a> 是 ShuffleSplit 的一个变种，会返回 stratified splits，<em>i.e</em>：创建一个划分，
但是划分中每个类的样本比例和完整数据集中的相同。</p>
<p>Here is a visualization of the cross-validation behavior.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0091.png" src="../_images/sphx_glr_plot_cv_indices_0091.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
</div>
</div>
<div class="section" id="group-cv">
<span id="id9"></span><h3>3.1.2.3. 用于分组数据的交叉验证迭代器.<a class="headerlink" href="#group-cv" title="Permalink to this headline">¶</a></h3>
<p>如果潜在的生成过程产生几组样本，而每个组内的样本是相互依赖的 ，那么 i.i.d. 假设将会被打破。
(The i.i.d. assumption is broken if the underlying generative process yield groups of dependent samples.)</p>
<p>这样的数据分组是与特定领域相关的(domain specific)。一个例子是从多个患者收集医学数据，从每个患者身上采集多个样本。而这样的数据很可能取决于个人群体。
在我们的例子中，每个样本的患者 ID 将是其 group identifier （组标识符）。</p>
<p>在这种情况下，我们想知道在一组特定的 groups 上训练的模型是否能很好地适用于看不见的 group 。为了衡量这一点，
我们需要确保验证对象中的所有样本来自配对训练折叠中完全没有表示的组。</p>
<p>下面的交叉验证分割器(cross-validation splitters)可以用来做到这一点。 样本的 grouping identifier （分组标识符） 通过 <code class="docutils literal notranslate"><span class="pre">groups</span></code> 参数指定。</p>
<div class="section" id="group-k-fold">
<h4>3.1.2.3.1. Group k-fold<a class="headerlink" href="#group-k-fold" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a> is a variation of k-fold which ensures that the same group is
not represented in both testing and training sets. For example if the data is
obtained from different subjects with several samples per-subject and if the
model is flexible enough to learn from highly person specific features it
could fail to generalize to new subjects. <a class="reference internal" href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a> makes it possible
to detect this kind of overfitting situations.</p>
<p>Imagine you have three subjects, each with an associated number from 1 to 3:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GroupKFold</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">gkf</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[0 1 2 3 4 5] [6 7 8 9]</span>
<span class="go">[0 1 2 6 7 8 9] [3 4 5]</span>
<span class="go">[3 4 5 6 7 8 9] [0 1 2]</span>
</pre></div>
</div>
<p>Each subject is in a different testing fold, and the same subject is never in
both testing and training. Notice that the folds do not have exactly the same
size due to the imbalance in the data.</p>
<p>Here is a visualization of the cross-validation behavior.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0051.png" src="../_images/sphx_glr_plot_cv_indices_0051.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
</div>
<div class="section" id="leave-one-group-out">
<h4>3.1.2.3.2. Leave One Group Out<a class="headerlink" href="#leave-one-group-out" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a> is a cross-validation scheme which holds out
the samples according to a third-party provided array of integer groups. This
group information can be used to encode arbitrary domain specific pre-defined
cross-validation folds.</p>
<p>Each training set is thus constituted by all the samples except the ones
related to a specific group.</p>
<p>For example, in the cases of multiple experiments, <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a>
can be used to create a cross-validation based on the different experiments:
we create a training set using the samples of all the experiments except one:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">LeaveOneGroupOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">80</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logo</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">logo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3 4 5 6] [0 1]</span>
<span class="go">[0 1 4 5 6] [2 3]</span>
<span class="go">[0 1 2 3] [4 5 6]</span>
</pre></div>
</div>
<p>Another common application is to use time information: for instance the
groups could be the year of collection of the samples and thus allow
for cross-validation against time-based splits.</p>
</div>
<div class="section" id="leave-p-groups-out">
<h4>3.1.2.3.3. Leave P Groups Out<a class="headerlink" href="#leave-p-groups-out" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a> is similar as <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a>, but removes
samples related to <span class="math notranslate nohighlight">\(P\)</span> groups for each training/test set.</p>
<p>Example of Leave-2-Group Out:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">LeavePGroupsOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpgo</span> <span class="o">=</span> <span class="n">LeavePGroupsOut</span><span class="p">(</span><span class="n">n_groups</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">lpgo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[4 5] [0 1 2 3]</span>
<span class="go">[2 3] [0 1 4 5]</span>
<span class="go">[0 1] [2 3 4 5]</span>
</pre></div>
</div>
</div>
<div class="section" id="group-shuffle-split">
<h4>3.1.2.3.4. Group Shuffle Split<a class="headerlink" href="#group-shuffle-split" title="Permalink to this headline">¶</a></h4>
<p>The <a class="reference internal" href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupShuffleSplit</span></code></a> iterator behaves as a combination of
<a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> and <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a>, and generates a
sequence of randomized partitions in which a subset of groups are held
out for each split.</p>
<p>Here is a usage example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GroupShuffleSplit</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gss</span> <span class="o">=</span> <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="gp">...</span>
<span class="go">[0 1 2 3] [4 5 6 7]</span>
<span class="go">[2 3 6 7] [0 1 4 5]</span>
<span class="go">[2 3 4 5] [0 1 6 7]</span>
<span class="go">[4 5 6 7] [0 1 2 3]</span>
</pre></div>
</div>
<p>Here is a visualization of the cross-validation behavior.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0081.png" src="../_images/sphx_glr_plot_cv_indices_0081.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
<p>This class is useful when the behavior of <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a> is
desired, but the number of groups is large enough that generating all
possible partitions with <span class="math notranslate nohighlight">\(P\)</span> groups withheld would be prohibitively
expensive.  In such a scenario, <a class="reference internal" href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupShuffleSplit</span></code></a> provides
a random sample (with replacement) of the train / test splits
generated by <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a>.</p>
</div>
</div>
<div class="section" id="predefined-fold-splits-validation-sets">
<h3>3.1.2.4. Predefined Fold-Splits / Validation-Sets<a class="headerlink" href="#predefined-fold-splits-validation-sets" title="Permalink to this headline">¶</a></h3>
<p>For some datasets, a pre-defined split of the data into training- and
validation fold or into several cross-validation folds already
exists. Using <a class="reference internal" href="generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit" title="sklearn.model_selection.PredefinedSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredefinedSplit</span></code></a> it is possible to use these folds
e.g. when searching for hyperparameters.</p>
<p>For example, when using a validation set, set the <code class="docutils literal notranslate"><span class="pre">test_fold</span></code> to 0 for all
samples that are part of the validation set, and to -1 for all other samples.</p>
</div>
<div class="section" id="timeseries-cv">
<span id="id10"></span><h3>3.1.2.5. 时间序列数据的交叉验证<a class="headerlink" href="#timeseries-cv" title="Permalink to this headline">¶</a></h3>
<p>时间序列数据的特点是时间 (<a href="#id11"><span class="problematic" id="id12">*</span></a>autocorrelation*(自相关性)) 附近的观测之间的相关性。
然而，传统的交叉验证技术，例如 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> 和 <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> 假设样本是独立的且分布相同的，
并且在时间序列数据上会导致训练和测试实例之间不合理的相关性（产生广义误差的估计较差）。
因此，对 “future(未来)” 观测的时间序列数据模型的评估至少与用于训练模型的观测模型非常重要。
为了达到这个目的，一个解决方案是由 <a class="reference internal" href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code></a> 提供的。</p>
<div class="section" id="id13">
<h4>3.1.2.5.1. 时间序列划分<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code></a> 是 <em>k-fold</em> 的一个变体，它首先返回 <span class="math notranslate nohighlight">\(k\)</span> 折作为训练数据集和 <span class="math notranslate nohighlight">\((k+1)\)</span> 折作为测试数据集。
请注意，与标准的交叉验证方法不同，连续的训练集是超越前者的超集。 另外，它将所有的剩余数据添加到第一个训练分区，它总是用来训练模型。</p>
<p>这个类可以用来交叉验证以固定时间间隔观察到的时间序列数据样本。</p>
<p>对具有 6 个样本的数据集进行 3-split 时间序列交叉验证的示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">TimeSeriesSplit</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tscv</span><span class="p">)</span>  
<span class="go">TimeSeriesSplit(max_train_size=None, n_splits=3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[0 1 2] [3]</span>
<span class="go">[0 1 2 3] [4]</span>
<span class="go">[0 1 2 3 4] [5]</span>
</pre></div>
</div>
<p>Here is a visualization of the cross-validation behavior.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_0101.png" src="../_images/sphx_glr_plot_cv_indices_0101.png" style="width: 450.0px; height: 225.0px;" /></a>
</div>
</div>
</div>
</div>
<div class="section" id="id14">
<h2>3.1.3. 随机洗牌需要注意的地方<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>(如果数据的顺序不是任意的（比如说，相同标签的样例连续出现），为了获得有意义的交叉验证结果，首先对其进行随机打乱(shuffling)是很有必要的。
然而，当样例不是独立同分布时打乱则是不可行的。例如：样例是相关的文章，以他们发表的时间 进行排序，
这时候如果对数据进行打乱，将会导致模型过拟合，得到一个过高的验证分数：因为验证样例更加相似（在时间上更接近） 于训练数据。</p>
<p>一些交叉验证迭代器， 比如 <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> ，有一个内建的在划分数据前进行数据索引打乱的选项。注意:</p>
<ul class="simple">
<li>这种方式仅需要很少的内存就可以打乱数据。</li>
<li>默认不会进行打乱，包括设置 <code class="docutils literal notranslate"><span class="pre">cv=some_integer</span></code> （直接）k 折叠交叉验证的 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> ，网格搜索等。
注意 <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a> 会返回一个随机的划分。</li>
<li>参数 <code class="docutils literal notranslate"><span class="pre">random_state</span></code> 默认设置为 None ，这意为着每次进行 <code class="docutils literal notranslate"><span class="pre">KFold(...,</span> <span class="pre">shuffle=True)</span></code> 时，打乱都是不同的。
然而， <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> 通过调用 <code class="docutils literal notranslate"><span class="pre">fit</span></code> 方法验证时，将会使用相同的打乱来训练每一组参数。</li>
<li>为了保证结果的可重复性（在相同的平台上），应该给 <code class="docutils literal notranslate"><span class="pre">random_state</span></code> 设定一个固定的值。</li>
</ul>
</div>
<div class="section" id="id15">
<h2>3.1.4. 交叉验证与模型选择<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<p>交叉验证迭代器(Cross validation iterators)可以通过网格搜索得到最优的模型超参数，从而直接用于模型选择。
这是另一部分 <a class="reference internal" href="grid_search.html#grid-search"><span class="std std-ref">通过网格搜索调节估计器超参数</span></a> 的主要内容。</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  </div>
  
  <div class="footer">
    &copy; 2007 - 2018, scikit-learn developers (BSD License).
    <!--
    <a href="../_sources/modules/cross_validation.rst.txt" rel="nofollow">Show this page source</a> -->
  </div>
  <div class="rel">
    
      <div class="buttonPrevious">
        <a href="../model_selection.html">Previous
        </a>
      </div>
      <div class="buttonNext">
        <a href="grid_search.html">Next
        </a>
      </div>
      
    </div>

    
    <script>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) }; ga.l = +new Date;
      ga('create', 'UA-22606712-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    
    <script>
      (function () {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </body>
</html>