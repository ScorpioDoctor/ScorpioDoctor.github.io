

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
    <title>1.13. 特征选择(Feature selection) &#8212; scikit-learn 0.20.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../static/css/bootstrap-responsive.css"/>

    <link rel="stylesheet" href="../static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/js/copybutton.js"></script>
    <script type="text/javascript" src="../static/js/extra.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="shortcut icon" href="../static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.14. 半监督学习(Semi-Supervised)" href="label_propagation.html" />
    <link rel="prev" title="1.12. 多类和多标签算法(Multiclass and multilabel algorithms)" href="multiclass.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../static/js/bootstrap.min.js" type="text/javascript"></script>
  <script>
     VERSION_SUBDIR = (function(groups) {
         return groups ? groups[1] : null;
     })(location.href.match(/^https?:\/\/scikit-learn.org\/([^\/]+)/));
  </script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/feature_selection.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
    function showMenu() {
      var topNav = document.getElementById("scikit-navbar");
      if (topNav.className === "navbar") {
          topNav.className += " responsive";
      } else {
          topNav.className = "navbar";
      }
    };
  </script>

  <!-- 百度站长统计代码 -->
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?e7836e37a4cb7584127a787e9b44e3f1";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>


  </head><body>

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../index.html">
            <img src="../static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar" id="scikit-navbar">
            <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn <script>document.write(DOCUMENTATION_OPTIONS.VERSION + (VERSION_SUBDIR ? " (" + VERSION_SUBDIR + ")" : ""));</script></li>
            <li><a href="../tutorial/index.html">教程</a></li>
            <li><a href="../user_guide.html">用户指南</a></li>
            <li><a href="classes.html">API</a></li>
            <li><a href="../glossary.html">术语表</a></li>
            <li><a href="../faq.html">FAQ</a></li>
            <li><a href="../developers/contributing.html">贡献者</a></li>
            <li class="divider"></li>
                <script>if (VERSION_SUBDIR != "stable") document.write('<li><a href="http://scikit-learn.org/stable/documentation.html">稳定版</a></li>')</script>
                <script>if (VERSION_SUBDIR != "dev") document.write('<li><a href="http://scikit-learn.org/dev/documentation.html">开发版</a></li>')</script>
                <li><a href="http://scikit-learn.org/dev/versions.html">所有可用版本</a></li>
                <li><a href="../downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../auto_examples/index.html">案例</a></li>
            </ul>
            <a href="javascript:void(0);" onclick="showMenu()">
                <div class="nav-icon">
                    <div class="hamburger-line"></div>
                    <div class="hamburger-line"></div>
                    <div class="hamburger-line"></div>
                </div>
            </a>
            <div class="search_form">
                <div class="gcse-search" id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- GitHub "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    
        <div class="rellink">
        <a href="multiclass.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        1.12. 多类和多标签算...
        </span>
            <span class="hiddenrellink">
            1.12. 多类和多标签算法(Multiclass and multilabel algorithms)
            </span>
        </a>
        </div>
            <div class="spacer">
            &nbsp;
            </div>
        <div class="rellink">
        <a href="label_propagation.html"
        accesskey="N">Next
        <br/>
        <span class="smallrellink">
        1.14. 半监督学习(S...
        </span>
            <span class="hiddenrellink">
            1.14. 半监督学习(Semi-Supervised)
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../supervised_learning.html">
        Up
        <br/>
        <span class="smallrellink">
        1. 监督学习(Super...
        </span>
            <span class="hiddenrellink">
            1. 监督学习(Supervised learning)
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version"><b>scikit-learn v0.20.1</b><br/>
      <a href="http://scikit-learn.org/dev/versions.html">其他版本</a></p>
    <p class="citing">该中文文档由人工智能社区的<a href="http://www.studyai.com/antares" target="_blank"
      >Antares</a>翻译!</p>
    <ul>
<li><a class="reference internal" href="#">1.13. 特征选择(Feature selection)</a><ul>
<li><a class="reference internal" href="#variance-threshold">1.13.1. 去除方差比较低的特征</a></li>
<li><a class="reference internal" href="#univariate-feature-selection">1.13.2. 单变量特征选择</a></li>
<li><a class="reference internal" href="#rfe">1.13.3. 递归式特征消除</a></li>
<li><a class="reference internal" href="#selectfrommodel">1.13.4. 使用 SelectFromModel 选取特征</a><ul>
<li><a class="reference internal" href="#l1">1.13.4.1. 基于 L1 的特征选取</a></li>
<li><a class="reference internal" href="#id7">1.13.4.2. 基于树的特征选择</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id8">1.13.5. 把特征选择作为管道流的一部分</a></li>
</ul>
</li>
</ul>

    <br/>
    <p>
        <a href="http://www.studyai.com" target="_blank">
          <img src="../static/img/xxx.png" alt="座右铭"/>
        </a>
    </p>
    <br/>
    <p class="doc-version">
      注意!本网站的网址是以 <em>https://</em> 开头的，而不是以 <em>http://</em> 开头的!!!
    </p>
    <!-- <br/>
    <p>
      <a href="http://www.studyai.com" target="_blank">
        <img src="../static/img/yyy.png" alt="座右铭"/>
      </a>      
    </p> -->
    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="feature-selection">
<span id="id1"></span><h1>1.13. 特征选择(Feature selection)<a class="headerlink" href="#feature-selection" title="Permalink to this headline">¶</a></h1>
<p>特征选择模块 <a class="reference internal" href="classes.html#module-sklearn.feature_selection" title="sklearn.feature_selection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_selection</span></code></a> 中的类可以用于样本集的特征选择/降维，
既可以提高估计器的精度得分，也可以提高它们在非常高维数据集上的性能。</p>
<div class="section" id="variance-threshold">
<span id="id2"></span><h2>1.13.1. 去除方差比较低的特征<a class="headerlink" href="#variance-threshold" title="Permalink to this headline">¶</a></h2>
<p>方差阈值 <a class="reference internal" href="generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold" title="sklearn.feature_selection.VarianceThreshold"><code class="xref py py-class docutils literal notranslate"><span class="pre">VarianceThreshold</span></code></a> 是特征选择的一种简单的基线方法（baseline approach）。
它删除了所有方差不满足某些阈值的特征。默认情况下，它删除所有零方差特征(zero-variance features)，即在所有样本中具有相同值的特征。</p>
<p>例如，假设我们有一个具有若干布尔特征(boolean features)的数据集，并且我们希望删除所有在超过80%的样本中取值都为1或0(ON或OFF)的那些布尔特征。
布尔特征是伯努利随机变量(Bernoulli random variables), 这种类型的随机变量的方差 由下面给出：</p>
<div class="math notranslate nohighlight">
\[\mathrm{Var}[X] = p(1 - p)\]</div>
<p>因此我们可以使用阈值 <code class="docutils literal notranslate"><span class="pre">.8</span> <span class="pre">*</span> <span class="pre">(1</span> <span class="pre">-</span> <span class="pre">.8)</span></code> 进行选择</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">VarianceThreshold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sel</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="o">.</span><span class="mi">8</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sel</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0, 1],</span>
<span class="go">       [1, 0],</span>
<span class="go">       [0, 0],</span>
<span class="go">       [1, 1],</span>
<span class="go">       [1, 0],</span>
<span class="go">       [1, 1]])</span>
</pre></div>
</div>
<p>就像我希望的那样, <code class="docutils literal notranslate"><span class="pre">VarianceThreshold</span></code> 已经将第一列删除了, 因为第一列包含0值的概率(样本比例)是 <span class="math notranslate nohighlight">\(p = 5/6 &gt; .8\)</span> ，超过了给定的阈值 0.8。</p>
</div>
<div class="section" id="univariate-feature-selection">
<span id="id3"></span><h2>1.13.2. 单变量特征选择<a class="headerlink" href="#univariate-feature-selection" title="Permalink to this headline">¶</a></h2>
<p>单变量特征选择是通过选择那些基于单变量统计检验(univariate statistical tests)得出的的最优特征来实现的。
它可以看作是一个预处理步骤。
Scikit-learn 将一系列特征选择程序作为不同的类提供给我们，这些类都实现了  <code class="docutils literal notranslate"><span class="pre">transform</span></code> 方法:</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" title="sklearn.feature_selection.SelectKBest"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectKBest</span></code></a> 选择得分最高的 <span class="math notranslate nohighlight">\(k\)</span> 个特征，删除其余的。</li>
<li><a class="reference internal" href="generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" title="sklearn.feature_selection.SelectPercentile"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectPercentile</span></code></a> 选择得分最高的前百分之几的特征，这个百分比由用户指定，其余的特征全部删除</li>
<li>把常见的 单变量统计检验方法 用到每个特征上：
false positive rate <a class="reference internal" href="generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr" title="sklearn.feature_selection.SelectFpr"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectFpr</span></code></a>, false discovery rate
<a class="reference internal" href="generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr" title="sklearn.feature_selection.SelectFdr"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectFdr</span></code></a>, 或 family wise error <a class="reference internal" href="generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe" title="sklearn.feature_selection.SelectFwe"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectFwe</span></code></a>.</li>
<li><a class="reference internal" href="generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect" title="sklearn.feature_selection.GenericUnivariateSelect"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericUnivariateSelect</span></code></a> 允许使用一个可配置策略(a configurable strategy)进行单变量特征选择。该类允许使用超参数搜索估计器</li>
</ul>
<blockquote>
<div>(hyper-parameter search estimator)选择最优的单变量选择策略。</div></blockquote>
</div></blockquote>
<p>举个例子, 我们可以对样本执行一个 <span class="math notranslate nohighlight">\(\chi^2\)</span> 测试来仅仅挑选出两个最好的特征</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectKBest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">chi2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 2)</span>
</pre></div>
</div>
<p>上面这些对象除了 <a class="reference internal" href="generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" title="sklearn.feature_selection.SelectKBest"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectKBest</span></code></a> 和 <a class="reference internal" href="generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" title="sklearn.feature_selection.SelectPercentile"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectPercentile</span></code></a> 都接受两个参数作为输入：一个是 返回值为单变量之得分的评分函数，另一个是 p-values。
<a class="reference internal" href="generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" title="sklearn.feature_selection.SelectKBest"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectKBest</span></code></a> 和 :class:<a href="#id4"><span class="problematic" id="id5">`</span></a>SelectPercentile`对象只接受一个参数：返回值为单变量之得分的评分函数:</p>
<blockquote>
<div><ul class="simple">
<li>对于回归问题: <a class="reference internal" href="generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression" title="sklearn.feature_selection.f_regression"><code class="xref py py-func docutils literal notranslate"><span class="pre">f_regression</span></code></a>, <a class="reference internal" href="generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression" title="sklearn.feature_selection.mutual_info_regression"><code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_regression</span></code></a></li>
<li>对于分类问题: <a class="reference internal" href="generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" title="sklearn.feature_selection.chi2"><code class="xref py py-func docutils literal notranslate"><span class="pre">chi2</span></code></a>, <a class="reference internal" href="generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif" title="sklearn.feature_selection.f_classif"><code class="xref py py-func docutils literal notranslate"><span class="pre">f_classif</span></code></a>, <a class="reference internal" href="generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif" title="sklearn.feature_selection.mutual_info_classif"><code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_classif</span></code></a></li>
</ul>
</div></blockquote>
<p>基于 F-test 的方法 估计 两个随机变量之间的线性依赖度(linear dependency)。 另一方面，基于互信息(mutual information)的方法可以捕捉任何类型的
统计依赖性(statistical dependency), 但由于互信息方法是无参数方法，他们需要更多的样本进行准确的估计。</p>
<div class="topic">
<p class="topic-title first">稀疏数据的特征选择</p>
<p>如果你用的是稀疏数据 (i.e. 数据是以稀疏矩阵的形式存放的), <a class="reference internal" href="generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" title="sklearn.feature_selection.chi2"><code class="xref py py-func docutils literal notranslate"><span class="pre">chi2</span></code></a>, <a class="reference internal" href="generated/sklearn.feature_selection.mutual_info_regression.html#sklearn.feature_selection.mutual_info_regression" title="sklearn.feature_selection.mutual_info_regression"><code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_regression</span></code></a>, <a class="reference internal" href="generated/sklearn.feature_selection.mutual_info_classif.html#sklearn.feature_selection.mutual_info_classif" title="sklearn.feature_selection.mutual_info_classif"><code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_classif</span></code></a>
可以在不用把数据变为稠密矩阵的前提下使用这些稀疏矩阵。</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">小心不要把回归评分函数用在分类问题上，你会得到无用的结果。</p>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_feature_selection.html#sphx-glr-auto-examples-feature-selection-plot-feature-selection-py"><span class="std std-ref">Univariate Feature Selection</span></a></li>
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_f_test_vs_mi.html#sphx-glr-auto-examples-feature-selection-plot-f-test-vs-mi-py"><span class="std std-ref">Comparison of F-test and mutual information</span></a></li>
</ul>
</div>
</div>
<div class="section" id="rfe">
<span id="id6"></span><h2>1.13.3. 递归式特征消除<a class="headerlink" href="#rfe" title="Permalink to this headline">¶</a></h2>
<p>给定一个可以对特征向量赋予对应权重向量（比如，线性模型的相关系数）的外部估计器，，
recursive feature elimination ( <a class="reference internal" href="generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE" title="sklearn.feature_selection.RFE"><code class="xref py py-class docutils literal notranslate"><span class="pre">RFE</span></code></a> ) 通过递归地考虑越来越小的特征集合来选择特征。
首先，估计器在初始的特征集合上训练并且每一个特征的重要程度是通过一个 <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 属性
或者 <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> 属性来获得。 然后，从当前的特征集合中移除最不重要的特征。
在特征集合上不断的重复递归这个步骤，直到最终达到所需要的特征数量为止。
RFECV 在一个交叉验证的循环中执行 RFE 来找到最优的特征数量。</p>
<p><a class="reference internal" href="generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV" title="sklearn.feature_selection.RFECV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RFECV</span></code></a> 在一个交叉验证的循环中执行 RFE 来找到最优的特征数量。</p>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_digits.html#sphx-glr-auto-examples-feature-selection-plot-rfe-digits-py"><span class="std std-ref">Recursive feature elimination</span></a>: A recursive feature elimination example
showing the relevance of pixels in a digit classification task.</li>
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a>: A recursive feature
elimination example with automatic tuning of the number of features
selected with cross-validation.</li>
</ul>
</div>
</div>
<div class="section" id="selectfrommodel">
<span id="select-from-model"></span><h2>1.13.4. 使用 SelectFromModel 选取特征<a class="headerlink" href="#selectfrommodel" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">SelectFromModel</span></code></a> 是一个 元变换器(meta-transformer), 可以和任意拟合后具有属性 <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 或 <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> 的估计器一起使用。
如果与某个特征对应的 <code class="docutils literal notranslate"><span class="pre">coef_</span></code> 或 <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> 的值小于某个给定的阈值参数 <code class="docutils literal notranslate"><span class="pre">threshold</span></code> ，则认为该特征是不重要的，应该被去除。
除了以数字的方式指定阈值，还有一些内建的启发式方法可以用来寻找合适的阈值，这些方法用一个字符串做参数来指定具体的启发式策略。现在可用的启发式策略有
“mean”, “median” 以及 用浮点数乘以字符串的方式，比如 “0.1*mean”。</p>
<p>关于该类的具体使用方法的案例请看下面。</p>
<div class="topic">
<p class="topic-title first">案例</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/feature_selection/plot_select_from_model_boston.html#sphx-glr-auto-examples-feature-selection-plot-select-from-model-boston-py"><span class="std std-ref">Feature selection using SelectFromModel and LassoCV</span></a>: Selecting the two
most important features from the Boston dataset without knowing the
threshold beforehand.</li>
</ul>
</div>
<div class="section" id="l1">
<span id="l1-feature-selection"></span><h3>1.13.4.1. 基于 L1 的特征选取<a class="headerlink" href="#l1" title="Permalink to this headline">¶</a></h3>
<p>用 L1-norm 进行惩罚的线性模型 <a class="reference internal" href="linear_model.html#linear-model"><span class="std std-ref">Linear models</span></a> 可以获得稀疏解： 它们估计出的模型的很多系数都是0。
当我们的目标是使用另一个分类器对数据进行维数约简的时候，这样的分类器就可以和类 <a class="reference internal" href="generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">feature_selection.SelectFromModel</span></code></a>
一起使用来选择非零的系数。特别的，可以用做这种用途的稀疏估计器(sparse estimators)有这些: <a class="reference internal" href="generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code class="xref py py-class docutils literal notranslate"><span class="pre">linear_model.Lasso</span></code></a> 用于回归,
以及 <a class="reference internal" href="generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">linear_model.LogisticRegression</span></code></a> 和 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.LinearSVC</span></code></a> 用于分类</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectFromModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lsvc</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">dual</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">lsvc</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 3)</span>
</pre></div>
</div>
<p>在 SVM 和 logistic-regression 中，参数 C 是用来控制稀疏性的：越小的 C 会导致越少的特征被选择。
在 Lasso 中，参数 alpha 的值越大，越少的特征会被选择。</p>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a>: Comparison
of different algorithms for document classification including L1-based
feature selection.</li>
</ul>
</div>
<div class="topic" id="compressive-sensing">
<p class="topic-title first"><strong>L1-recovery 和 压缩感知(compressive sensing)</strong></p>
<p>当选择了正确的 alpha 值以后，<a class="reference internal" href="linear_model.html#lasso"><span class="std std-ref">Lasso</span></a> 可以仅通过少量观察点便完整
的恢复准确的非零变量集合，假设特定的条件可以被满足的话。
特别的，数据量需要 “足够大(sufficiently large)” ，不然 L1 模型的表现将充满不确定性。
“足够大” 的定义取决于非零系数的个数、特征数量的对数值、噪音的数量、非零系数的最小绝对值、
以及设计矩阵(design maxtrix) X 的结构。另外，设计矩阵必须有某些特定的性质，如数据不能过度相关。</p>
<p>关于如何选择 alpha 的值来恢复非零系数并没有通用的规则。alpha 值可以通过交叉验证来确定
(<code class="xref py py-class docutils literal notranslate"><span class="pre">LassoCV</span></code> 或 <code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsCV</span></code>)，
尽管这可能会导致欠惩罚的模型：包括少量的无关变量对于预测值来说并非致命的。相反的， BIC( <code class="xref py py-class docutils literal notranslate"><span class="pre">LassoLarsIC</span></code> )
倾向于给定高 alpha 值。</p>
<p><strong>参考文献</strong> Richard G. Baraniuk “Compressive Sensing”, IEEE Signal
Processing Magazine [120] July 2007
<a class="reference external" href="http://users.isr.ist.utl.pt/~aguiar/CS_notes.pdf">http://users.isr.ist.utl.pt/~aguiar/CS_notes.pdf</a></p>
</div>
</div>
<div class="section" id="id7">
<h3>1.13.4.2. 基于树的特征选择<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>很多基于树的估计器 (请看 <a class="reference internal" href="classes.html#module-sklearn.tree" title="sklearn.tree"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code></a> 模块 和 <a class="reference internal" href="classes.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a> 模块中由树构成的森林那一小节) 可被用来计算特征重要性
(feature importances), 反过来，它们也可以用于丢弃那些无关的特征
(irrelevant features：译者注：这里的无关特征或者翻译为不相关的特征指的是该特征与分类或回归的目标变量没有啥关系，说的并不是各个特征分量之间的关系)
(当于 <a class="reference internal" href="generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.feature_selection.SelectFromModel</span></code></a> meta-transformer 相耦合的时候):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <span class="n">SelectFromModel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(150, 4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">feature_importances_</span>  
<span class="go">array([ 0.04...,  0.05...,  0.4...,  0.4...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_new</span><span class="o">.</span><span class="n">shape</span>               
<span class="go">(150, 2)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li><a class="reference internal" href="../auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py"><span class="std std-ref">Feature importances with forests of trees</span></a>: example on
synthetic data showing the recovery of the actually meaningful
features.</li>
<li><a class="reference internal" href="../auto_examples/ensemble/plot_forest_importances_faces.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-faces-py"><span class="std std-ref">Pixel importances with a parallel forest of trees</span></a>: example
on face recognition data.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="id8">
<h2>1.13.5. 把特征选择作为管道流的一部分<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>在进行实际学习之前，通常使用特征选择作为预处理步骤。在 scikit-learn  中，推荐的方法是使用流水线类
<a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
  <span class="p">(</span><span class="s1">&#39;feature_selection&#39;</span><span class="p">,</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">))),</span>
  <span class="p">(</span><span class="s1">&#39;classification&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">())</span>
<span class="p">])</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>在上面的代码片段中，我们将 <a class="reference internal" href="generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" title="sklearn.svm.LinearSVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.svm.LinearSVC</span></code></a> 类 和
<a class="reference internal" href="generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.feature_selection.SelectFromModel</span></code></a> 类耦合起来，评估特征重要性并且选择那些最相关的特征(most relevant features)。
然后，<a class="reference internal" href="generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" title="sklearn.ensemble.RandomForestClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.ensemble.RandomForestClassifier</span></code></a> 类就紧跟在特征选择的输出端接收数据进行训练(i.e. 随机森林分类器只在最相关的特征上训练)。
在上面的代码片段中你可以选择其他的特征选择器类，也可以选择别的分类器进行特征重要性评估。
请参考 <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.pipeline.Pipeline</span></code></a> 类的更多案例。</p>
</div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2007 - 2018, scikit-learn developers (BSD License).
      <a href="../_sources/modules/feature_selection.rst.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="multiclass.html">Previous
      </a>
    </div>
    <div class="buttonNext">
      <a href="label_propagation.html">Next
      </a>
    </div>
    
     </div>

    
    <script>
        window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
        ga('create', 'UA-22606712-2', 'auto');
        ga('set', 'anonymizeIp', true);
        ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    
    <script>
      (function() {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </body>
</html>