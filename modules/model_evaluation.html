

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>3.3. 模型评估:对模型的预测进行量化考核 &#8212; scikit-learn 0.20.2 documentation</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../static/css/bootstrap-responsive.css" />

    <link rel="stylesheet" href="../static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/js/copybutton.js"></script>
    <script type="text/javascript" src="../static/js/extra.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="shortcut icon" href="../static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.4. 模型持久化(Model persistence)" href="model_persistence.html" />
    <link rel="prev" title="3.2.4.3.6. sklearn.ensemble.GradientBoostingRegressor" href="generated/sklearn.ensemble.GradientBoostingRegressor.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../static/js/bootstrap.min.js" type="text/javascript"></script>
<script>
  VERSION_SUBDIR = (function (groups) {
    return groups ? groups[1] : null;
  })(location.href.match(/^https?:\/\/scikit-learn.org\/([^\/]+)/));
</script>
<link rel="canonical" href="http://scikit-learn.org/stable/modules/model_evaluation.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
    function () {
      $(this).css('background-color', '#FF9C34');
    },
    function () {
      $(this).css('background-color', '#A7D6E2');
    }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
      topNav.className += " responsive";
    } else {
      topNav.className = "navbar";
    }
  };
</script>

<!-- 百度站长统计代码 -->
<script>
  var _hmt = _hmt || [];
  (function () {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e7836e37a4cb7584127a787e9b44e3f1";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>


  </head><body>

<div class="header-wrapper">
  <div class="header">
    <p class="logo"><a href="../index.html">
        <img src="../static/scikit-learn-logo-small.png" alt="Logo" />
      </a>
    </p><div class="navbar" id="scikit-navbar">
      <ul>
        <li><a href="../index.html">首页</a></li>
        <li><a href="../install.html">安装</a></li>
        <li class="btn-li">
          <div class="btn-group">
            <a href="../documentation.html">文档</a>
            <a class="btn dropdown-toggle" data-toggle="dropdown">
              <span class="caret"></span>
            </a>
            <ul class="dropdown-menu">
              <li class="link-title">Scikit-learn
                <script>document.write(DOCUMENTATION_OPTIONS.VERSION + (VERSION_SUBDIR ? " (" + VERSION_SUBDIR + ")" : ""));</script>
              </li>
              <li><a href="../tutorial/index.html">教程</a></li>
              <li><a href="../user_guide.html">用户指南</a></li>
              <li><a href="classes.html">API</a></li>
              <li><a href="../glossary.html">词汇表</a></li>
              <li><a href="../faq.html">FAQ</a></li>
              <li><a href="../developers/contributing.html">贡献</a></li>
              <li><a href="../roadmap.html">路线图</a></li>
              <li class="divider"></li>
              <script>if (VERSION_SUBDIR != "stable") document.write('<li><a href="https://www.studyai.cn">稳定版</a></li>')</script>
              <script>if (VERSION_SUBDIR != "dev") document.write('<li><a href="http://scikit-learn.org/dev/documentation.html" target="_blank">开发版</a></li>')</script>
              <li><a href="http://scikit-learn.org/dev/versions.html">所有可用版本</a></li>
              <li><a href="../downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
            </ul>
          </div>
        </li>
        <li><a href="../auto_examples/index.html">案例</a></li>
      </ul>
      <a href="javascript:void(0);" onclick="showMenu()">
        <div class="nav-icon">
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
        </div>
      </a>
      <div class="search_form">
        <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div> <!-- end navbar --></div>
</div>


<!-- GitHub "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me" style="position: absolute; top: 0; right: 0; border: 0;" src="../static/img/forkme.png"
    alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
      <div class="rel">
        
          <div class="rellink">
            <a href="generated/sklearn.ensemble.GradientBoostingRegressor.html" accesskey="P">Previous
              <br />
              <span class="smallrellink">
                3.2.4.3.6. sk...
              </span>
              <span class="hiddenrellink">
                3.2.4.3.6. sklearn.ensemble.GradientBoostingRegressor
              </span>
            </a>
          </div>
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="model_persistence.html" accesskey="N">Next
              <br />
              <span class="smallrellink">
                3.4. 模型持久化(Mo...
              </span>
              <span class="hiddenrellink">
                3.4. 模型持久化(Model persistence)
              </span>
            </a>
          </div>

          <!-- Ad a link to the 'up' page -->
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="../model_selection.html">
              Up
              <br />
              <span class="smallrellink">
                3. 模型选择与评估
              </span>
                <span class="hiddenrellink">
                  3. 模型选择与评估
                </span>
                
            </a>
          </div>
        </div>
        
        <p class="doc-version"><b>scikit-learn v0.20.2</b><br />
          <a href="http://scikit-learn.org/dev/versions.html">其他版本</a></p>
        <!-- <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite
              us </a></b>if you use the software.</p> -->
        <p class="citing">该中文文档由人工智能社区的<a href="http://www.studyai.com/antares" target="_blank">Antares</a>翻译!
        </p>
        <ul>
<li><a class="reference internal" href="#">3.3. 模型评估:对模型的预测进行量化考核</a><ul>
<li><a class="reference internal" href="#scoring">3.3.1. <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数: 定义模型评估准则</a><ul>
<li><a class="reference internal" href="#id6">3.3.1.1. 一般情况: 使用预定义的值</a></li>
<li><a class="reference internal" href="#metric">3.3.1.2. 利用指标函数 metric 自定义评分策略</a></li>
<li><a class="reference internal" href="#scoring-object">3.3.1.3. 实现你自己的 scoring object</a></li>
<li><a class="reference internal" href="#multimetric-scoring">3.3.1.4. 使用多指标评估</a></li>
</ul>
</li>
<li><a class="reference internal" href="#classification-metrics">3.3.2. 分类问题的指标</a><ul>
<li><a class="reference internal" href="#id15">3.3.2.1. 从二分类问题到多类或多标签问题</a></li>
<li><a class="reference internal" href="#accuracy-score">3.3.2.2. Accuracy score</a></li>
<li><a class="reference internal" href="#balanced-accuracy-score">3.3.2.3. Balanced accuracy score</a></li>
<li><a class="reference internal" href="#cohen-s-kappa">3.3.2.4. Cohen’s kappa</a></li>
<li><a class="reference internal" href="#confusion-matrix">3.3.2.5. Confusion matrix</a></li>
<li><a class="reference internal" href="#classification-report">3.3.2.6. Classification report</a></li>
<li><a class="reference internal" href="#hamming-loss">3.3.2.7. Hamming loss</a></li>
<li><a class="reference internal" href="#jaccard-similarity-coefficient-score">3.3.2.8. Jaccard similarity coefficient score</a></li>
<li><a class="reference internal" href="#precision-recall-and-f-measures">3.3.2.9. Precision, recall and F-measures</a><ul>
<li><a class="reference internal" href="#binary-classification">3.3.2.9.1. Binary classification</a></li>
<li><a class="reference internal" href="#id35">3.3.2.9.2. 多类分类和多标签分类</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hinge-loss">3.3.2.10. Hinge loss</a></li>
<li><a class="reference internal" href="#log-loss">3.3.2.11. Log loss</a></li>
<li><a class="reference internal" href="#matthews">3.3.2.12. Matthews相关系数</a></li>
<li><a class="reference internal" href="#receiver-operating-characteristic-roc">3.3.2.13. Receiver operating characteristic (ROC)</a></li>
<li><a class="reference internal" href="#zero-one-loss">3.3.2.14. Zero one loss</a></li>
<li><a class="reference internal" href="#brier-score-loss">3.3.2.15. Brier score loss</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multilabel-ranking-metrics">3.3.3. 多标签排序指标</a><ul>
<li><a class="reference internal" href="#coverage-error">3.3.3.1. Coverage error</a></li>
<li><a class="reference internal" href="#label-ranking-average-precision">3.3.3.2. Label ranking average precision</a></li>
<li><a class="reference internal" href="#ranking-loss">3.3.3.3. Ranking loss</a></li>
</ul>
</li>
<li><a class="reference internal" href="#regression-metrics">3.3.4. 回归问题的指标</a><ul>
<li><a class="reference internal" href="#explained-variance-score">3.3.4.1. Explained variance score</a></li>
<li><a class="reference internal" href="#mean-absolute-error">3.3.4.2. Mean absolute error</a></li>
<li><a class="reference internal" href="#mean-squared-error">3.3.4.3. Mean squared error</a></li>
<li><a class="reference internal" href="#mean-squared-logarithmic-error">3.3.4.4. Mean squared logarithmic error</a></li>
<li><a class="reference internal" href="#median-absolute-error">3.3.4.5. Median absolute error</a></li>
<li><a class="reference internal" href="#r2-score-the-coefficient-of-determination">3.3.4.6. R² score, the coefficient of determination</a></li>
</ul>
</li>
<li><a class="reference internal" href="#clustering-metrics">3.3.5. 聚类问题的测度</a></li>
<li><a class="reference internal" href="#dummy-estimators">3.3.6. 无实际意义的估计器(Dummy estimators)</a></li>
</ul>
</li>
</ul>

        <br />
        <p>
          <a href="http://www.studyai.com" target="_blank">
            <img src="../static/img/xxx.png" alt="座右铭" />
          </a>
        </p>
        <br />
        <p class="doc-version" style="font-size:10%">
          注意!本网站的网址是以 <em>https://</em> 开头的，而不是以 <em>http://</em> 开头的!!!
        </p>
      </div>
    </div>
    
    <input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
    <label for="nav-trigger"></label>
    
    


    <div class="content">
      
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="model-evaluation">
<span id="id1"></span><h1>3.3. 模型评估:对模型的预测进行量化考核<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">¶</a></h1>
<div class="topic">
<p class="topic-title first">译者注</p>
<p>在此献上我做的视频，希望对大家有所帮助。视频地址：
(<a class="reference external" href="http://www.studyai.com/course/play/9dd4fa59779d454991f55ac4c85889eb">Sklearn模型评估方法</a>);
(<a class="reference external" href="http://www.studyai.com/course/play/b8e95c00332040acb241607a78e8ff6a">Sklearn分类模型评估方法</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/8461165a12a3486390de83b402445327">准确率和混淆矩阵</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/939c66920de84096902b89674cf5a645">precision-recall-F_measures</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/88e699621b3c4c03884ecdfe4db0ff61">ROC曲线</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/d467372769204b37a217d93a6042504d">各种分类损失函数</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/ab9f9976527946f28d4c0044fb7a3afa">Sklearn 回归器评估方法</a>)。</p>
</div>
<p>有 3 种不同的 API 用于评估模型预测的质量:</p>
<ul class="simple">
<li><strong>Estimator score method</strong>: Estimators（估计器）有一个 <code class="docutils literal notranslate"><span class="pre">score</span></code> 方法，为其解决的问题提供了默认的评估准则(evaluation criterion) 。
在本页面上没有相关讨论，但是在每个 estimator 的文档中会有相关的讨论。</li>
<li><strong>Scoring parameter</strong>: 使用了 <a class="reference internal" href="cross_validation.html#cross-validation"><span class="std std-ref">cross-validation</span></a> (比如 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">model_selection.cross_val_score</span></code></a> 和 <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>)
的模型评估工具依赖于一个内部评分策略。此参数的用法参考 <a class="reference internal" href="#scoring-parameter"><span class="std std-ref">scoring 参数: 定义模型评估准则</span></a> 。</li>
<li><strong>Metric functions</strong>: 模块 <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code> 实现了一些函数用于以某种特殊目的评估模型预测误差。这些测度指标(metrics)的详细介绍在 <a class="reference internal" href="#classification-metrics"><span class="std std-ref">分类问题的指标</span></a> ，
<a class="reference internal" href="#multilabel-ranking-metrics"><span class="std std-ref">多标签排序指标</span></a> , <a class="reference internal" href="#regression-metrics"><span class="std std-ref">回归问题的指标</span></a> 以及 <a class="reference internal" href="#clustering-metrics"><span class="std std-ref">聚类问题的测度</span></a> 中。</li>
</ul>
<p>最后, <a class="reference internal" href="#dummy-estimators"><span class="std std-ref">无实际意义的估计器(Dummy estimators)</span></a> 可以针对随机预测结果计算那些测度指标的一个基准值。</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last">For “pairwise” metrics, between <em>samples</em> and not estimators or
predictions, see the <a class="reference internal" href="metrics.html#metrics"><span class="std std-ref">成对测度, 相似性 和 核</span></a> section.</p>
</div>
<div class="section" id="scoring">
<span id="scoring-parameter"></span><h2>3.3.1. <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数: 定义模型评估准则<a class="headerlink" href="#scoring" title="Permalink to this headline">¶</a></h2>
<p>模型选择与评估使用的工具，例如 <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a> 和 <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">model_selection.cross_val_score</span></code></a>,
接受一个 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数，该参数控制着估计器的评估过程中使用什么样的测度指标(metric)。</p>
<div class="section" id="id6">
<h3>3.3.1.1. 一般情况: 使用预定义的值<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>对于最常见的用例, 可以使用 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数指定一个评分器对象(scorer object); 下表显示了所有可能的值。
所有 scorer objects 遵循惯例:较高的返回值优于较低的返回值(higher return values are better than lower return values) 。
因此，度量模型和数据之间距离的测度指标(metrics), 如 <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_error</span></code></a> 可作为 neg_mean_squared_error, 返回变负的指标值。
(译者注：也就是说 有些 测度指标比如均方误差本来是越小越好，但是为了遵循越大越好的惯例，我们要把这种原来越小越好的指标取个负号，这样就符合惯例啦 )</p>
<table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="41%" />
<col width="31%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Scoring</th>
<th class="head">Function</th>
<th class="head">Comment</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><strong>Classification</strong></td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘accuracy’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.accuracy_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘balanced_accuracy’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.balanced_accuracy_score</span></code></a></td>
<td>for binary targets</td>
</tr>
<tr class="row-odd"><td>‘average_precision’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.average_precision_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘brier_score_loss’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss" title="sklearn.metrics.brier_score_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.brier_score_loss</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘f1’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></td>
<td>for binary targets</td>
</tr>
<tr class="row-even"><td>‘f1_micro’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></td>
<td>micro-averaged</td>
</tr>
<tr class="row-odd"><td>‘f1_macro’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></td>
<td>macro-averaged</td>
</tr>
<tr class="row-even"><td>‘f1_weighted’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></td>
<td>weighted average</td>
</tr>
<tr class="row-odd"><td>‘f1_samples’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.f1_score</span></code></a></td>
<td>by multilabel sample</td>
</tr>
<tr class="row-even"><td>‘neg_log_loss’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.log_loss</span></code></a></td>
<td>requires <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> support</td>
</tr>
<tr class="row-odd"><td>‘precision’ etc.</td>
<td><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.precision_score</span></code></a></td>
<td>suffixes apply as with ‘f1’</td>
</tr>
<tr class="row-even"><td>‘recall’ etc.</td>
<td><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.recall_score</span></code></a></td>
<td>suffixes apply as with ‘f1’</td>
</tr>
<tr class="row-odd"><td>‘roc_auc’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><strong>Clustering</strong></td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘adjusted_mutual_info_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score" title="sklearn.metrics.adjusted_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.adjusted_mutual_info_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘adjusted_rand_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score" title="sklearn.metrics.adjusted_rand_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.adjusted_rand_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘completeness_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.completeness_score.html#sklearn.metrics.completeness_score" title="sklearn.metrics.completeness_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.completeness_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘fowlkes_mallows_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.fowlkes_mallows_score.html#sklearn.metrics.fowlkes_mallows_score" title="sklearn.metrics.fowlkes_mallows_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.fowlkes_mallows_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘homogeneity_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.homogeneity_score.html#sklearn.metrics.homogeneity_score" title="sklearn.metrics.homogeneity_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.homogeneity_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘mutual_info_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.mutual_info_score.html#sklearn.metrics.mutual_info_score" title="sklearn.metrics.mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mutual_info_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘normalized_mutual_info_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.normalized_mutual_info_score.html#sklearn.metrics.normalized_mutual_info_score" title="sklearn.metrics.normalized_mutual_info_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.normalized_mutual_info_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘v_measure_score’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.v_measure_score.html#sklearn.metrics.v_measure_score" title="sklearn.metrics.v_measure_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.v_measure_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td><strong>Regression</strong></td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘explained_variance’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.explained_variance_score</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘neg_mean_absolute_error’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_absolute_error</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘neg_mean_squared_error’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_error</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘neg_mean_squared_log_error’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.mean_squared_log_error</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>‘neg_median_absolute_error’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.median_absolute_error</span></code></a></td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>‘r2’</td>
<td><a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.r2_score</span></code></a></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<p>用法案例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall_macro&#39;</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE</span>
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;wrong_choice&#39;</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="gr">ValueError</span>: <span class="n">&#39;wrong_choice&#39; is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">通过 <em>ValueError</em> 异常列举出来的那些值对应于度量预测精度的函数，它们会在下面的小节中介绍。
用于这些函数的评分器对象(scorer objects) 被存放在 <code class="docutils literal notranslate"><span class="pre">sklearn.metrics.SCORERS</span></code> 字典中。</p>
</div>
</div>
<div class="section" id="metric">
<span id="id7"></span><h3>3.3.1.2. 利用指标函数 metric 自定义评分策略<a class="headerlink" href="#metric" title="Permalink to this headline">¶</a></h3>
<p>模块 <a class="reference internal" href="classes.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> 也暴露了一组简单的函数：当给定真值和预测值的时候用来度量一个预测错误。</p>
<ul class="simple">
<li>以 <code class="docutils literal notranslate"><span class="pre">_score</span></code> 结尾的函数返回一个值进行最大化，值越高代表预测越好</li>
<li>以 <code class="docutils literal notranslate"><span class="pre">_error</span></code> 或 <code class="docutils literal notranslate"><span class="pre">_loss</span></code> 结尾的函数 返回一个值进行最小化，值越小代表预测越好。当我们使用函数 <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a>
把这种越小越好的metric转换成评分对象(scorer object)的时候,就需要设置参数 <code class="docutils literal notranslate"><span class="pre">greater_is_better</span></code> 为 False。 (这个参数默认是True,对这个参数下面还会解释)</li>
</ul>
<p>可用于各种机器学习任务的 Metrics （指标）在下面详细介绍。</p>
<p>许多 metrics 没有被命名以使得它们被用作 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 值，有时是因为它们需要额外的参数，例如 <a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a> 。
在这种情况下，您需要生成一个适当的评分对象(scoring object)。最简单的办法就是利用函数 <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> 生成一个用于评分的可调用对象
(callable object)。 函数 <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> 将 metrics 转换为可用于模型评估的可调用对象。
(译者注：可调用对象即callable object是Python的一个知识点，如果你知道这个知识点那么这段话不难理解，如果不知道的话，请自行查一下就会明白啦！)</p>
<p>一个典型的用法是从库中封装一个已经存在的具有非默认值参数的 metric 函数，例如 <a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a> 函数的 <code class="docutils literal notranslate"><span class="pre">beta</span></code> 参数</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ftwo_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]},</span>
<span class="gp">... </span>                    <span class="n">scoring</span><span class="o">=</span><span class="n">ftwo_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>第二个用法是使用 <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> 从简单的 python 函数构建一个完全自定义的评分对象(scorer object) ，可以接受几个参数 :</p>
<ul class="simple">
<li>你想使用的Python函数 (以 <code class="docutils literal notranslate"><span class="pre">my_custom_loss_func</span></code> 为例)</li>
<li>你的python函数返回值是 score (<code class="docutils literal notranslate"><span class="pre">greater_is_better=True</span></code>, the default) 还是 loss (<code class="docutils literal notranslate"><span class="pre">greater_is_better=False</span></code>)。
如果是 loss 的话, python函数的输出就会被 scorer object 取负号，以满足 交叉验证 中关于 评分准则越大越好 的约定惯例。</li>
<li>如果你要定义的是一个分类评分指标(classification metrics)，还要确认你的python函数需要连续的 decision certainties (<code class="docutils literal notranslate"><span class="pre">needs_threshold=True</span></code>)，
默认值是 False。</li>
<li>任意的附加参数, 比如 <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a> 函数中的 <code class="docutils literal notranslate"><span class="pre">beta</span></code> 或 <code class="docutils literal notranslate"><span class="pre">labels</span></code> .</li>
</ul>
<p>下面是一个构建自定义评分器(custom scorers)的例子,并且使用了参数 <code class="docutils literal notranslate"><span class="pre">greater_is_better</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">my_custom_loss_func</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># score will negate the return value of my_custom_loss_func,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># which will be np.log(2), 0.693, given the values for X</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and y defined below.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">my_custom_loss_func</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="k">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">my_custom_loss_func</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> 
<span class="go">0.69...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> 
<span class="go">-0.69...</span>
</pre></div>
</div>
</div>
<div class="section" id="scoring-object">
<span id="diy-scoring"></span><h3>3.3.1.3. 实现你自己的 scoring object<a class="headerlink" href="#scoring-object" title="Permalink to this headline">¶</a></h3>
<p>您可以通过从头开始构建自己的 scoring object，而不使用 <a class="reference internal" href="generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer" title="sklearn.metrics.make_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code></a> 来生成更加灵活的模型评分对象(model scorers)。
如果一个python 可调用对象 被叫做 scorer ，那么它需要符合以下两个规则所指定的协议:</p>
<ul class="simple">
<li>可以使用参数 <code class="docutils literal notranslate"><span class="pre">(estimator,</span> <span class="pre">X,</span> <span class="pre">y)</span></code> 来调用它，其中 <code class="docutils literal notranslate"><span class="pre">estimator</span></code> 是要被评估的模型，<code class="docutils literal notranslate"><span class="pre">X</span></code> 是验证数据， <code class="docutils literal notranslate"><span class="pre">y</span></code> 是 真实目标变量 (在有监督情况下)
或 None (在无监督情况下)。</li>
<li>它返回一个浮点数，用于对 <code class="docutils literal notranslate"><span class="pre">estimator</span></code> 在 <code class="docutils literal notranslate"><span class="pre">X</span></code> 上的预测质量以 <code class="docutils literal notranslate"><span class="pre">y</span></code> 为真值参考进行量化。 再就是，按照惯例，越高的数字越好，
所以如果你的 scorer 返回 loss ，那么这个值应该被取负号 。</li>
</ul>
</div>
<div class="section" id="multimetric-scoring">
<span id="id8"></span><h3>3.3.1.4. 使用多指标评估<a class="headerlink" href="#multimetric-scoring" title="Permalink to this headline">¶</a></h3>
<p>Scikit-learn 还允许在 <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, <code class="docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code> 和 <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code> 中进行多指标的评估(evaluation of multiple metrics)。</p>
<p>有两种方法可以为 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数指定 多个评分指标:</p>
<ul>
<li><dl class="first docutils">
<dt>把多个metrics的名字以字符串列表的方式传给 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数 ::</dt>
<dd><div class="first last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>以字典的形式把评分器的名称映射到评分函数上，然后把这字典作为参数传给 <code class="docutils literal notranslate"><span class="pre">scoring</span></code> 参数 ::</dt>
<dd><div class="first last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">),</span>
<span class="gp">... </span>           <span class="s1">&#39;prec&#39;</span><span class="p">:</span> <span class="s1">&#39;precision&#39;</span><span class="p">}</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
<p>要注意的是 字典的值 既可以是 scorer functions 也可以是 sklearn预定义的metric的名字字符串。</p>
<p>目前，只有那些返回单个得分值的 scorer functions 可以被传到 字典中。 那些有多个返回值的 scorer functions 不被允许传入。
如果非要这么干的话，必须对其进行封装使其只有单个返回值</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># A sample toy binary classification dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">tn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">fp</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">tp</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;tp&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">tp</span><span class="p">),</span> <span class="s1">&#39;tn&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">tn</span><span class="p">),</span>
<span class="gp">... </span>           <span class="s1">&#39;fp&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fp</span><span class="p">),</span> <span class="s1">&#39;fn&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fn</span><span class="p">)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Getting the test set true positive scores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_tp&#39;</span><span class="p">])</span>  
<span class="go">[10  9  8  7  8]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Getting the test set false negative scores</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_fn&#39;</span><span class="p">])</span>  
<span class="go">[0 1 2 3 2]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="classification-metrics">
<span id="id9"></span><h2>3.3.2. 分类问题的指标<a class="headerlink" href="#classification-metrics" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first">译者注</p>
<p>在此献上我做的视频，希望对大家有所帮助。视频地址：
(<a class="reference external" href="http://www.studyai.com/course/play/b8e95c00332040acb241607a78e8ff6a">Sklearn分类模型评估方法</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/8461165a12a3486390de83b402445327">准确率和混淆矩阵</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/939c66920de84096902b89674cf5a645">precision-recall-F_measures</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/88e699621b3c4c03884ecdfe4db0ff61">ROC曲线</a>)；
(<a class="reference external" href="http://www.studyai.com/course/play/d467372769204b37a217d93a6042504d">各种分类损失函数</a>)；</p>
</div>
<p><a class="reference internal" href="classes.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> 模块实现了几个 loss, score, 和 utility 函数来度量分类器性能。
某些测度指标(metrics)可能需要 positive class，confidence values 或 binary decisions values 的概率估计。
大多数的实现允许每个样本通过 <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> 参数为 整体得分(overall score) 提供 加权贡献(weighted contribution)。</p>
<p>这里面的一部分指标仅仅限于在二分类的情况下使用(binary classification case):</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a>(y_true,&nbsp;probas_pred)</td>
<td>Compute precision-recall pairs for different probability thresholds</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_curve</span></code></a>(y_true,&nbsp;y_score[,&nbsp;pos_label,&nbsp;…])</td>
<td>Compute Receiver operating characteristic (ROC)</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">balanced_accuracy_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;…])</td>
<td>Compute the balanced accuracy</td>
</tr>
</tbody>
</table>
<p>下面这些既能在二分类中用也能够用于多分类的情况(multiclass case):</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score" title="sklearn.metrics.cohen_kappa_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cohen_kappa_score</span></code></a>(y1,&nbsp;y2[,&nbsp;labels,&nbsp;weights,&nbsp;…])</td>
<td>Cohen’s kappa: a statistic that measures inter-annotator agreement.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute confusion matrix to evaluate the accuracy of a classification</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hinge_loss</span></code></a>(y_true,&nbsp;pred_decision[,&nbsp;labels,&nbsp;…])</td>
<td>Average hinge loss (non-regularized)</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;…])</td>
<td>Compute the Matthews correlation coefficient (MCC)</td>
</tr>
</tbody>
</table>
<p>下面的这些还可以用在多标签分类中(multilabel case):</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">accuracy_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;normalize,&nbsp;…])</td>
<td>Accuracy classification score.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report" title="sklearn.metrics.classification_report"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classification_report</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;…])</td>
<td>Build a text report showing the main classification metrics</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">f1_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the F1 score, also known as balanced F-score or F-measure</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>(y_true,&nbsp;y_pred,&nbsp;beta[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the F-beta score</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hamming_loss</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the average Hamming loss.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.jaccard_similarity_score.html#sklearn.metrics.jaccard_similarity_score" title="sklearn.metrics.jaccard_similarity_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jaccard_similarity_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;…])</td>
<td>Jaccard similarity coefficient score</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log_loss</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;eps,&nbsp;normalize,&nbsp;…])</td>
<td>Log loss, aka logistic loss or cross-entropy loss.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>(y_true,&nbsp;y_pred)</td>
<td>Compute precision, recall, F-measure and support for each class</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the precision</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recall_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the recall</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;normalize,&nbsp;…])</td>
<td>Zero-one classification loss.</td>
</tr>
</tbody>
</table>
<p>下面的这些指标可以用在两类多标签问题(不是multiclass而是binary classes喔):</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average_precision_score</span></code></a>(y_true,&nbsp;y_score[,&nbsp;…])</td>
<td>Compute average precision (AP) from prediction scores</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>(y_true,&nbsp;y_score[,&nbsp;average,&nbsp;…])</td>
<td>Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.</td>
</tr>
</tbody>
</table>
<p>在下面的小节中，我们会逐个讲解这些函数, 包括一些常用API的注解和metric的数学定义。</p>
<div class="section" id="id15">
<h3>3.3.2.1. 从二分类问题到多类或多标签问题<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>有些 metrics 基本上是为 binary classification tasks 定义的 (例如 <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a>, <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a>) 。
在这些情况下，默认情况下仅评估 positive label （正标签），默认情况下我们假定 positive label （正类） 标记为 1
(尽管可以通过 <code class="docutils literal notranslate"><span class="pre">pos_label</span></code> 参数进行配置)。</p>
<p id="average">将 binary metric （二分指标）扩展为 multiclass （多类）或 multilabel （多标签）问题时，数据将被视为二分问题的集合，每个类都有一个binary metric。
然后可以使用多种策略在整个类中计算所有二分指标的平均值(average binary metric calculations across the set of classes)，
这些不同的计算平均值的策略在某些特定场景中可能会用到。 如果可用，您应该使用 <code class="docutils literal notranslate"><span class="pre">average</span></code> 参数来选择某个平均策略。</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">&quot;macro&quot;</span></code>  简单地计算 binary metrics （二分指标）的平均值，赋予每个类别相同的权重。在不常见的类别重要的问题上，
macro-averaging （宏观平均）可能是突出表现的一种手段。另一方面，所有类别同样重要的假设通常是不真实的，
因此 macro-averaging （宏观平均）将过度强调不频繁类的典型的低性能。</li>
<li><code class="docutils literal notranslate"><span class="pre">&quot;weighted&quot;</span></code> 通过计算其在真实数据样本中的存在来对每个类的 score 进行加权的 binary metrics （二分指标）的平均值来计算类不平衡。</li>
<li><code class="docutils literal notranslate"><span class="pre">&quot;micro&quot;</span></code> 给每个 sample-class pair （样本类对）对 overall metric （总体指数）（sample-class 权重的结果除外） 等同的贡献。
除了对每个类别的 metric 进行求和之外，这个总和构成每个类别度量的 dividends （除数）和 divisors （除数）计算一个整体商。
在 multilabel settings （多标签设置）中， Micro-averaging 可能是优先选择的，包括要忽略 majority class （多数类）的 multiclass classification （多类分类）。</li>
<li><code class="docutils literal notranslate"><span class="pre">&quot;samples&quot;</span></code> 仅适用于 multilabel problems （多标签问题）。它 does not calculate a per-class measure （不计算每个类别的 measure），而是计算 evaluation data
（评估数据）中的每个样本的 true and predicted classes （真实和预测类别）的 metric （指标），并返回 (sample_weight-weighted) 加权平均。</li>
<li>选择 <code class="docutils literal notranslate"><span class="pre">average=None</span></code> 将返回一个 array 与每个类的 score 。</li>
</ul>
<p>虽然将 multiclass data 作为 array of class labels 提供给 metric ，就像 binary targets （二分类目标）一样，
multilabel data 被指定为 indicator matrix（标识矩阵），其中如果样本 <code class="docutils literal notranslate"><span class="pre">i</span></code> 具有标号 <code class="docutils literal notranslate"><span class="pre">j</span></code> ， <code class="docutils literal notranslate"><span class="pre">[i,</span> <span class="pre">j]</span></code> 具有值 1， 否则为值 0 。</p>
</div>
<div class="section" id="accuracy-score">
<span id="id16"></span><h3>3.3.2.2. Accuracy score<a class="headerlink" href="#accuracy-score" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">accuracy_score</span></code></a> 计算 <a class="reference external" href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>,
也就是计算正确预测的比例(默认)或数量(normalize=False)。</p>
<p>在多标签分类中，该函数返回子集的准确率(subset accuracy)。对某个样本的预测标签的整个集合与该样本真正的标签集合严格匹配，
那么子集准确率就是1.0,反之 子集准确率为0.0。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是 第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真实值, 则在 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> 个样本上估计的
正确预测的比例(the fraction of correct predictions)定义如下：</p>
<div class="math notranslate nohighlight">
\[\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i = y_i)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(1(x)\)</span> 是 <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">indicator function</a>。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">accuracy_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">2</span>
</pre></div>
</div>
<p>在多标签的情形下，比如 每个样本需要预测两个标签(binary label indicators)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.5</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/feature_selection/plot_permutation_test_for_classification.html#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py"><span class="std std-ref">Test with permutations the significance of a classification score</span></a>
for an example of accuracy score usage using permutations of
the dataset.</li>
</ul>
</div>
</div>
<div class="section" id="balanced-accuracy-score">
<span id="id17"></span><h3>3.3.2.3. Balanced accuracy score<a class="headerlink" href="#balanced-accuracy-score" title="Permalink to this headline">¶</a></h3>
<p>此 <a class="reference internal" href="generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score" title="sklearn.metrics.balanced_accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">balanced_accuracy_score</span></code></a> 函数计算 <a class="reference external" href="https://en.wikipedia.org/wiki/Accuracy_and_precision">balanced accuracy</a>,
它可以避免在不平衡数据集上作出夸大的性能估计。It is the macro-average of recall
scores per class or, equivalently, raw accuracy where each sample is weighted
according to the inverse prevalence of its true class.
因此，对均衡数据集， 该函数的得分与准确率得分是相等的。</p>
<p>在二分类情况下, balanced accuracy 等价于 <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">sensitivity</a>
(真正率:true positive rate) 和 <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">specificity</a> (真负率:true negative
rate) 的算术平均值, 或者 the area under the ROC curve with binary predictions rather than
scores.</p>
<p>如果分类器在两个类上都表现的一样好，该函数就会退化为传统的准确率 (i.e., 正确预测数量除以总的预测数量).</p>
<p>作为对比, 如果传统的准确率(conventional accuracy)比较好，仅仅是因为分类器利用了一个不均衡测试集，此时 balanced_accuracy,将会近似地掉到
<span class="math notranslate nohighlight">\(\frac{1}{\text{n\_classes}}\)</span>。</p>
<p>得分的范围是 0 到 1, 或者当使用 <code class="docutils literal notranslate"><span class="pre">adjusted=True</span></code> 时，得分被缩放到 从 <span class="math notranslate nohighlight">\(\frac{1}{1 - \text{n\_classes}}\)</span> 到 1, 包括边界的, 随机条件下性能得分为0.</p>
<p>如果 <span class="math notranslate nohighlight">\(y_i\)</span> 是第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的真值，并且 <span class="math notranslate nohighlight">\(w_i\)</span> 是对应的样本权重，然后我们调整样本权重到 :</p>
<div class="math notranslate nohighlight">
\[\hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(1(x)\)</span> 是 <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">indicator function</a>。
给定样本 <span class="math notranslate nohighlight">\(i\)</span> 的预测值 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> , balanced accuracy 如下定义：</p>
<div class="math notranslate nohighlight">
\[\texttt{balanced-accuracy}(y, \hat{y}, w) = \frac{1}{\sum{\hat{w}_i}} \sum_i 1(\hat{y}_i = y_i) \hat{w}_i\]</div>
<p>With <code class="docutils literal notranslate"><span class="pre">adjusted=True</span></code>, balanced accuracy reports the relative increase from
<span class="math notranslate nohighlight">\(\texttt{balanced-accuracy}(y, \mathbf{0}, w) =
\frac{1}{\text{n\_classes}}\)</span>.  In the binary case, this is also known as
<a class="reference external" href="https://en.wikipedia.org/wiki/Youden%27s_J_statistic">*Youden’s J statistic*</a>,
or <em>informedness</em>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>The multiclass definition here seems the most reasonable extension of the
metric used in binary classification, though there is no certain consensus
in the literature:</p>
<ul class="last simple">
<li>Our definition: <a class="reference internal" href="#mosley2013" id="id19">[Mosley2013]</a>, <a class="reference internal" href="#kelleher2015" id="id20">[Kelleher2015]</a> and <a class="reference internal" href="#guyon2015" id="id21">[Guyon2015]</a>, where
<a class="reference internal" href="#guyon2015" id="id22">[Guyon2015]</a> adopt the adjusted version to ensure that random predictions
have a score of <span class="math notranslate nohighlight">\(0\)</span> and perfect predictions have a score of <span class="math notranslate nohighlight">\(1\)</span>..</li>
<li>Class balanced accuracy as described in <a class="reference internal" href="#mosley2013" id="id23">[Mosley2013]</a>: the minimum between the precision
and the recall for each class is computed. Those values are then averaged over the total
number of classes to get the balanced accuracy.</li>
<li>Balanced Accuracy as described in <a class="reference internal" href="#urbanowicz2015" id="id24">[Urbanowicz2015]</a>: the average of sensitivity and specificity
is computed for each class and then averaged over total number of classes.</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<table class="docutils citation" frame="void" id="guyon2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Guyon2015]</td><td><em>(<a class="fn-backref" href="#id21">1</a>, <a class="fn-backref" href="#id22">2</a>)</em> I. Guyon, K. Bennett, G. Cawley, H.J. Escalante, S. Escalera, T.K. Ho, N. Macià,
B. Ray, M. Saeed, A.R. Statnikov, E. Viegas, <a class="reference external" href="https://ieeexplore.ieee.org/document/7280767">Design of the 2015 ChaLearn AutoML Challenge</a>,
IJCNN 2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="mosley2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Mosley2013]</td><td><em>(<a class="fn-backref" href="#id19">1</a>, <a class="fn-backref" href="#id23">2</a>)</em> L. Mosley, <a class="reference external" href="https://lib.dr.iastate.edu/etd/13537/">A balanced approach to the multi-class imbalance problem</a>,
IJCV 2010.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kelleher2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[Kelleher2015]</a></td><td>John. D. Kelleher, Brian Mac Namee, Aoife D’Arcy, <a class="reference external" href="https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics">Fundamentals of
Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples,
and Case Studies</a>,
2015.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="urbanowicz2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id24">[Urbanowicz2015]</a></td><td>Urbanowicz R.J.,  Moore, J.H. <a class="reference external" href="https://doi.org/10.1007/s12065-015-0128-8">ExSTraCS 2.0: description and evaluation of a scalable learning
classifier system</a>, Evol. Intel. (2015) 8: 89.</td></tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="cohen-s-kappa">
<span id="cohen-kappa"></span><h3>3.3.2.4. Cohen’s kappa<a class="headerlink" href="#cohen-s-kappa" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score" title="sklearn.metrics.cohen_kappa_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cohen_kappa_score</span></code></a> 计算 <a class="reference external" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen’s kappa</a> 统计.
这个度量指标旨在比较由不同的人类标注者给出的标签，而不是去比较分类器预测和真值(ground truth)。</p>
<p>The kappa score (see docstring) 是一个介于 -1 到 1 之间的数字。得分超过0.8通常被认为是 good agreement;
得分为0或者小于0意味着 no agreement。</p>
<p>Kappa scores 既可以用于 二分类也可用于多分类，但是 不能用于 多标签问题(except by manually computing a per-label score)。
and not for more than two annotators.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">cohen_kappa_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cohen_kappa_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.4285714285714286</span>
</pre></div>
</div>
</div>
<div class="section" id="confusion-matrix">
<span id="id26"></span><h3>3.3.2.5. Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a> 通过计算 混淆矩阵( <a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a>)
来评估分类准确率。confusion matrix 的每一行对应于真的类。(但是 维基百科和其他引用文献可能会使用不同的axes)。</p>
<p>按照定义, 在 confusion matrix 中，入口 <span class="math notranslate nohighlight">\(i, j\)</span> 中存储着实际上应该在group <span class="math notranslate nohighlight">\(i\)</span> 中的观测,
但是却被预测到了group <span class="math notranslate nohighlight">\(j\)</span> 里面去的这些观测的数量。 这里有一个例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([[2, 0, 0],</span>
<span class="go">       [0, 0, 1],</span>
<span class="go">       [1, 0, 2]])</span>
</pre></div>
</div>
<p>这里有一个混淆矩阵的可视化表示。 (请看来自于这个例子的图片 <a class="reference internal" href="../auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a> ):</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_confusion_matrix.html"><img alt="../images/sphx_glr_plot_confusion_matrix_0011.png" class="align-center" src="../images/sphx_glr_plot_confusion_matrix_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
<p>对于二分类问题, 我们可以得到 真负(true negatives), 假正(false positives), 假负(false negatives) 和 真正(true positives) 的数量</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span>
<span class="go">(2, 1, 2, 3)</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a>
for an example of using a confusion matrix to evaluate classifier output
quality.</li>
<li>See <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a>
for an example of using a confusion matrix to classify
hand-written digits.</li>
<li>See <a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a>
for an example of using a confusion matrix to classify text
documents.</li>
</ul>
</div>
</div>
<div class="section" id="classification-report">
<span id="id28"></span><h3>3.3.2.6. Classification report<a class="headerlink" href="#classification-report" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report" title="sklearn.metrics.classification_report"><code class="xref py py-func docutils literal notranslate"><span class="pre">classification_report</span></code></a> 会构造一个文本报告展示主要的分类指标。
下面有一个小例子，里面有自定义的 <code class="docutils literal notranslate"><span class="pre">target_names</span></code> 和 inferred labels</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">classification_report</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;class 2&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
<span class="go">              precision    recall  f1-score   support</span>

<span class="go">     class 0       0.67      1.00      0.80         2</span>
<span class="go">     class 1       0.00      0.00      0.00         1</span>
<span class="go">     class 2       1.00      0.50      0.67         2</span>

<span class="go">   micro avg       0.60      0.60      0.60         5</span>
<span class="go">   macro avg       0.56      0.50      0.49         5</span>
<span class="go">weighted avg       0.67      0.60      0.59         5</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a>
for an example of classification report usage for
hand-written digits.</li>
<li>See <a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a>
for an example of classification report usage for text
documents.</li>
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Parameter estimation using grid search with cross-validation</span></a>
for an example of classification report usage for
grid search with nested cross-validation.</li>
</ul>
</div>
</div>
<div class="section" id="hamming-loss">
<span id="id29"></span><h3>3.3.2.7. Hamming loss<a class="headerlink" href="#hamming-loss" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss" title="sklearn.metrics.hamming_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hamming_loss</span></code></a> 计算两个样本集合之间的平均 Hamming loss 或 <a class="reference external" href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a> 。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_j\)</span> 是给定样本的第 <span class="math notranslate nohighlight">\(j\)</span> 个标签的预测值，<span class="math notranslate nohighlight">\(y_j\)</span> 是对应的真值，<span class="math notranslate nohighlight">\(n_\text{labels}\)</span> 是类(或 标签)的数量，
则两个样本之间的 Hamming loss <span class="math notranslate nohighlight">\(L_{Hamming}\)</span> 定义如下：</p>
<div class="math notranslate nohighlight">
\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{labels}} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_j \not= y_j)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(1(x)\)</span> 是 <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">indicator function</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">hamming_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<p>在多标签情况下，假如每个样本有两个标签(binary label indicators)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.75</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">在多类分类任务中, Hamming loss 对应 <code class="docutils literal notranslate"><span class="pre">y_true</span></code> 和 <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> 之间的 Hamming distance，这与 <a class="reference internal" href="#zero-one-loss"><span class="std std-ref">Zero one loss</span></a> 函数是相似的。
然而，尽管 zero-one loss 惩罚的是不与真值集合严格匹配的预测集合，但是 Hamming loss 惩罚的是独立的标签(individual labels)。
因此，the Hamming loss, 以 zero-one loss 为上界, 其取值区间在 [0, 1]; 预测真实标签的一个合适的子集或超集将会给出一个范围在(0,1)之间的Hamming loss。</p>
</div>
</div>
<div class="section" id="jaccard-similarity-coefficient-score">
<span id="jaccard-similarity-score"></span><h3>3.3.2.8. Jaccard similarity coefficient score<a class="headerlink" href="#jaccard-similarity-coefficient-score" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.jaccard_similarity_score.html#sklearn.metrics.jaccard_similarity_score" title="sklearn.metrics.jaccard_similarity_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_similarity_score</span></code></a> 计算两个标签集合之间的 <a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity coefficients</a>
的average(default)或sum, 也被称之为 Jaccard index.</p>
<p>给定 <span class="math notranslate nohighlight">\(i\)</span>-th samples, 以及关于样本的 真正的标签集合 <span class="math notranslate nohighlight">\(y_i\)</span> 和 预测出的标签集合 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>,
Jaccard similarity coefficient 是如下定义的：</p>
<div class="math notranslate nohighlight">
\[J(y_i, \hat{y}_i) = \frac{|y_i \cap \hat{y}_i|}{|y_i \cup \hat{y}_i|}.\]</div>
<p>在两类分类和多类分类中, Jaccard similarity coefficient score 等价于 分类准确率。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">jaccard_similarity_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">2</span>
</pre></div>
</div>
<p>在具有二元标签指示符(binary label indicators)的多标签情况下:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.75</span>
</pre></div>
</div>
</div>
<div class="section" id="precision-recall-and-f-measures">
<span id="precision-recall-f-measure-metrics"></span><h3>3.3.2.9. Precision, recall and F-measures<a class="headerlink" href="#precision-recall-and-f-measures" title="Permalink to this headline">¶</a></h3>
<p>直观地讲, 精度(<a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall#Precision">precision</a>) 指的是分类器不会把负样本标记为正样本的能力；
召回率(或叫 查全率 <a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall">recall</a>) 指的是分类器找到数据集中所有的正样本的能力。</p>
<p>F-度量(<a class="reference external" href="https://en.wikipedia.org/wiki/F1_score">F-measure</a> (包括 <span class="math notranslate nohighlight">\(F_\beta\)</span> 和 <span class="math notranslate nohighlight">\(F_1\)</span> 度量) ) 可被解释为精度(precision)和
查全率(recall)的加权调和均值(weighted harmonic mean)。
一个 <span class="math notranslate nohighlight">\(F_\beta\)</span> measure 在取值为1的时候达到它的最好值，而取值为0的时候达到最差得分。当 <span class="math notranslate nohighlight">\(\beta = 1\)</span> 时,  <span class="math notranslate nohighlight">\(F_\beta\)</span> 和 <span class="math notranslate nohighlight">\(F_1\)</span>
是等价的，而且这时候 recall 和 precision 在 <span class="math notranslate nohighlight">\(F_1\)</span> 的计算中是同等重要的。</p>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> 通过不断改变决策阈值 (decision threshold) 从真实标签和分类器给出的一个得分中计算一条 precision-recall 曲线。</p>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> 从预测得分中计算平均精度
( <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Information_retrieval&amp;oldid=793358396#Average_precision">average precision</a>
(AP))。 它的取值在0到1之间，越高越好。平均精度(AP)是如下定义的：</p>
<div class="math notranslate nohighlight">
\[\text{AP} = \sum_n (R_n - R_{n-1}) P_n\]</div>
<p>其中 <span class="math notranslate nohighlight">\(P_n\)</span> 和 <span class="math notranslate nohighlight">\(R_n\)</span> 是第n个阈值处的precision 和 recall。对于随机预测，AP 是正样本的比例。</p>
<p>参考文献 <a class="reference internal" href="#manning2008" id="id31">[Manning2008]</a> 和 <a class="reference internal" href="#everingham2010" id="id32">[Everingham2010]</a> 提出了AP的两种可替代变体对precision-recall曲线进行内插。
当前，函数 <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> 还没有实现任何具备内插的变体版本。
参考文献 <a class="reference internal" href="#davis2006" id="id33">[Davis2006]</a> 和 <a class="reference internal" href="#flach2015" id="id34">[Flach2015]</a> 描述了为什么precision-recall曲线上的点的线性内插提供了一个过于乐观(overly-optimistic)的分类器性能度量。
在函数 <a class="reference internal" href="generated/sklearn.metrics.auc.html#sklearn.metrics.auc" title="sklearn.metrics.auc"><code class="xref py py-func docutils literal notranslate"><span class="pre">auc</span></code></a> 中使用梯形规则(trapezoidal rule)计算曲线下面积的时候，这个线性内插(linear interpolation)会被使用。</p>
<p>下面这些函数允许你分析  precision, recall 和 F-measures score:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">average_precision_score</span></code></a>(y_true,&nbsp;y_score[,&nbsp;…])</td>
<td>Compute average precision (AP) from prediction scores</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">f1_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the F1 score, also known as balanced F-score or F-measure</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>(y_true,&nbsp;y_pred,&nbsp;beta[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the F-beta score</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a>(y_true,&nbsp;probas_pred)</td>
<td>Compute precision-recall pairs for different probability thresholds</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>(y_true,&nbsp;y_pred)</td>
<td>Compute precision, recall, F-measure and support for each class</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">precision_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the precision</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recall_score</span></code></a>(y_true,&nbsp;y_pred[,&nbsp;labels,&nbsp;…])</td>
<td>Compute the recall</td>
</tr>
</tbody>
</table>
<p>注意 函数 <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> 只能在二分类的情形下使用。函数 <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> 只能工作在 binary classification 和
multilabel indicator 情形下。</p>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a>
for an example of <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a> usage to classify  text
documents.</li>
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Parameter estimation using grid search with cross-validation</span></a>
for an example of <a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_score</span></code></a> and <a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall_score</span></code></a> usage
to estimate parameters using grid search with nested cross-validation.</li>
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py"><span class="std std-ref">Precision-Recall</span></a>
for an example of <a class="reference internal" href="generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve" title="sklearn.metrics.precision_recall_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></a> usage to evaluate
classifier output quality.</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<table class="docutils citation" frame="void" id="manning2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id31">[Manning2008]</a></td><td>C.D. Manning, P. Raghavan, H. Schütze, <a class="reference external" href="http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html">Introduction to Information Retrieval</a>,
2008.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="everingham2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id32">[Everingham2010]</a></td><td>M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman,
<a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&amp;rep=rep1&amp;type=pdf">The Pascal Visual Object Classes (VOC) Challenge</a>,
IJCV 2010.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="davis2006" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id33">[Davis2006]</a></td><td>J. Davis, M. Goadrich, <a class="reference external" href="http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf">The Relationship Between Precision-Recall and ROC Curves</a>,
ICML 2006.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="flach2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id34">[Flach2015]</a></td><td>P.A. Flach, M. Kull, <a class="reference external" href="http://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf">Precision-Recall-Gain Curves: PR Analysis Done Right</a>,
NIPS 2015.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="binary-classification">
<h4>3.3.2.9.1. Binary classification<a class="headerlink" href="#binary-classification" title="Permalink to this headline">¶</a></h4>
<p>在一个二分类任务中，词语 ‘’positive’’ 和 ‘’negative’’ 指的是分类器的预测，词语 ‘’true’’ 和 ‘’false’’ 指的是预测是否和来自外部判断
(external judgment，sometimes known as the ‘’observation’‘)相互对应。有了上述词汇的定义，我们就可以给出下面这个表啦：</p>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="32%" />
<col width="39%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>&#160;</td>
<td colspan="2">Actual class (observation)</td>
</tr>
<tr class="row-even"><td rowspan="2">Predicted class
(expectation)</td>
<td>tp (true positive)
Correct result</td>
<td>fp (false positive)
Unexpected result</td>
</tr>
<tr class="row-odd"><td>fn (false negative)
Missing result</td>
<td>tn (true negative)
Correct absence of result</td>
</tr>
</tbody>
</table>
<p>以此为上下文, 我们可以定义 precision, recall 和 F-measure 如下所示:</p>
<div class="math notranslate nohighlight">
\[\text{precision} = \frac{tp}{tp + fp},\]</div>
<div class="math notranslate nohighlight">
\[\text{recall} = \frac{tp}{tp + fn},\]</div>
<div class="math notranslate nohighlight">
\[F_\beta = (1 + \beta^2) \frac{\text{precision} \times \text{recall}}{\beta^2 \text{precision} + \text{recall}}.\]</div>
<p>下面是一些二分类的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  
<span class="go">0.83...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> 
<span class="go">0.55...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  
<span class="go">(array([0.66..., 1.        ]), array([1. , 0.5]), array([0.71..., 0.83...]), array([2, 2]))</span>


<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">precision_recall_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span>  
<span class="go">array([0.66..., 0.5       , 1.        , 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">recall</span>
<span class="go">array([1. , 0.5, 0.5, 0. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threshold</span>
<span class="go">array([0.35, 0.4 , 0.8 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>  
<span class="go">0.83...</span>
</pre></div>
</div>
</div>
<div class="section" id="id35">
<h4>3.3.2.9.2. 多类分类和多标签分类<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h4>
<p>在多类和多标签分类任务中，precision, recall, 和 F-measures 的概念可以独立的应用到每一个标签上。
有很多方法可以把所有标签上的结果组合起来，这可以通过设置参数 <code class="docutils literal notranslate"><span class="pre">average</span></code> 为
<a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> (multilabel only), <a class="reference internal" href="generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score" title="sklearn.metrics.f1_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code></a>,
<a class="reference internal" href="generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score" title="sklearn.metrics.fbeta_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code></a>, <a class="reference internal" href="generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support" title="sklearn.metrics.precision_recall_fscore_support"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code></a>,
<a class="reference internal" href="generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score" title="sklearn.metrics.precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">precision_score</span></code></a> 和 <a class="reference internal" href="generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score" title="sklearn.metrics.recall_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">recall_score</span></code></a> 这些函数来实现，就像在 <a class="reference internal" href="#average"><span class="std std-ref">above</span></a> 中描述的那样。
请注意 如果所有标签都包括了，在多类分类的设置下取 “micro” 平均策略 将会使产生的 precision, recall 和 <span class="math notranslate nohighlight">\(F\)</span> 都跟准确率(accuracy)一样。
还要注意的是 “weighted” averaging 策略会产生一个取值范围不在precision 和 recall 之间的 F-score。</p>
<p>要使这更显式更明确，请考虑以下表示法:</p>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(y\)</span> the set of <em>predicted</em> <span class="math notranslate nohighlight">\((sample, label)\)</span> pairs</li>
<li><span class="math notranslate nohighlight">\(\hat{y}\)</span> the set of <em>true</em> <span class="math notranslate nohighlight">\((sample, label)\)</span> pairs</li>
<li><span class="math notranslate nohighlight">\(L\)</span> the set of labels</li>
<li><span class="math notranslate nohighlight">\(S\)</span> the set of samples</li>
<li><span class="math notranslate nohighlight">\(y_s\)</span> the subset of <span class="math notranslate nohighlight">\(y\)</span> with sample <span class="math notranslate nohighlight">\(s\)</span>,
i.e. <span class="math notranslate nohighlight">\(y_s := \left\{(s', l) \in y | s' = s\right\}\)</span></li>
<li><span class="math notranslate nohighlight">\(y_l\)</span> the subset of <span class="math notranslate nohighlight">\(y\)</span> with label <span class="math notranslate nohighlight">\(l\)</span></li>
<li>similarly, <span class="math notranslate nohighlight">\(\hat{y}_s\)</span> and <span class="math notranslate nohighlight">\(\hat{y}_l\)</span> are subsets of
<span class="math notranslate nohighlight">\(\hat{y}\)</span></li>
<li><span class="math notranslate nohighlight">\(P(A, B) := \frac{\left| A \cap B \right|}{\left|A\right|}\)</span></li>
<li><span class="math notranslate nohighlight">\(R(A, B) := \frac{\left| A \cap B \right|}{\left|B\right|}\)</span>
(Conventions vary on handling <span class="math notranslate nohighlight">\(B = \emptyset\)</span>; this implementation uses
<span class="math notranslate nohighlight">\(R(A, B):=0\)</span>, and similar for <span class="math notranslate nohighlight">\(P\)</span>.)</li>
<li><span class="math notranslate nohighlight">\(F_\beta(A, B) := \left(1 + \beta^2\right) \frac{P(A, B) \times R(A, B)}{\beta^2 P(A, B) + R(A, B)}\)</span></li>
</ul>
<p>然后这些指标就可以定义如下：</p>
<table border="1" class="docutils">
<colgroup>
<col width="4%" />
<col width="32%" />
<col width="32%" />
<col width="33%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><code class="docutils literal notranslate"><span class="pre">average</span></code></th>
<th class="head">Precision</th>
<th class="head">Recall</th>
<th class="head">F_beta</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">&quot;micro&quot;</span></code></td>
<td><span class="math notranslate nohighlight">\(P(y, \hat{y})\)</span></td>
<td><span class="math notranslate nohighlight">\(R(y, \hat{y})\)</span></td>
<td><span class="math notranslate nohighlight">\(F_\beta(y, \hat{y})\)</span></td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">&quot;samples&quot;</span></code></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|S\right|} \sum_{s \in S} P(y_s, \hat{y}_s)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|S\right|} \sum_{s \in S} R(y_s, \hat{y}_s)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|S\right|} \sum_{s \in S} F_\beta(y_s, \hat{y}_s)\)</span></td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">&quot;macro&quot;</span></code></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|L\right|} \sum_{l \in L} P(y_l, \hat{y}_l)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|L\right|} \sum_{l \in L} R(y_l, \hat{y}_l)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\left|L\right|} \sum_{l \in L} F_\beta(y_l, \hat{y}_l)\)</span></td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">&quot;weighted&quot;</span></code></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| P(y_l, \hat{y}_l)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| R(y_l, \hat{y}_l)\)</span></td>
<td><span class="math notranslate nohighlight">\(\frac{1}{\sum_{l \in L} \left|\hat{y}_l\right|} \sum_{l \in L} \left|\hat{y}_l\right| F_\beta(y_l, \hat{y}_l)\)</span></td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">None</span></code></td>
<td><span class="math notranslate nohighlight">\(\langle P(y_l, \hat{y}_l) | l \in L \rangle\)</span></td>
<td><span class="math notranslate nohighlight">\(\langle R(y_l, \hat{y}_l) | l \in L \rangle\)</span></td>
<td><span class="math notranslate nohighlight">\(\langle F_\beta(y_l, \hat{y}_l) | l \in L \rangle\)</span></td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>  <span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.22...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.33...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>  <span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.23...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">(array([0.66..., 0.        , 0.        ]), array([1., 0., 0.]), array([0.71..., 0.        , 0.        ]), array([2, 2, 2]...))</span>
</pre></div>
</div>
<p>对于带有一个 “negative class” 的多分类任务, 不包括某些标签是可能的:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># excluding 0, no labels were correctly recalled</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>类似的, labels not present in the data sample may be accounted for in macro-averaging.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.166...</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="hinge-loss">
<span id="id36"></span><h3>3.3.2.10. Hinge loss<a class="headerlink" href="#hinge-loss" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> 使用 <a class="reference external" href="https://en.wikipedia.org/wiki/Hinge_loss">hinge loss</a> 计算模型和数据之间的平均距离。
折叶损失(hinge loss)是一种 单边测度指标(one-sided metric),它仅仅考虑预测误差。
(Hinge loss 被用在最大间隔分类器(maximal margin classifiers)如SVMs中)。</p>
<p>如果类标签被编码为 +1 和 -1， <span class="math notranslate nohighlight">\(y\)</span>: 是真值，并且 <span class="math notranslate nohighlight">\(w\)</span> 是用 <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>
预测得到的作为输出的决策，那么 hinge loss 定义如下:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y, w) = \max\left\{1 - wy, 0\right\} = \left|1 - wy\right|_+\]</div>
<p>如果有两个以上的标签, <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> 会使用一个多类变种(multiclass variant) 根据 Crammer &amp; Singer 的
论文所描述的：<a class="reference external" href="http://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf">Here</a> 。</p>
<p>如果 <span class="math notranslate nohighlight">\(y_w\)</span> 是对真实标签预测出的决策，并且 <span class="math notranslate nohighlight">\(y_t\)</span> 是所有其他标签的预测中的最大值，
其中 预测出的决策是决策函数(decision function)的输出，那么多个类的hinge loss定义如下:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y_w, y_t) = \max\left\{1 + y_t - y_w, 0\right\}\]</div>
<p>下面展示了一个例子说明如何使用 <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> 函数 将svm分类器用在二分类问题中</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">hinge_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span>
<span class="go">     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,</span>
<span class="go">     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=0, tol=0.0001,</span>
<span class="go">     verbose=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span>  
<span class="go">array([-2.18...,  2.36...,  0.09...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hinge_loss</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pred_decision</span><span class="p">)</span>  
<span class="go">0.3...</span>
</pre></div>
</div>
<p>下面展示了一个例子说明如何使用 <a class="reference internal" href="generated/sklearn.metrics.hinge_loss.html#sklearn.metrics.hinge_loss" title="sklearn.metrics.hinge_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code></a> 函数 将svm分类器用在多类分类问题中</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="go">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span>
<span class="go">     intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,</span>
<span class="go">     multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001,</span>
<span class="go">     verbose=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hinge_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>  
<span class="go">0.56...</span>
</pre></div>
</div>
</div>
<div class="section" id="log-loss">
<span id="id38"></span><h3>3.3.2.11. Log loss<a class="headerlink" href="#log-loss" title="Permalink to this headline">¶</a></h3>
<p>对数损失(Log loss)，又被称为logistic回归损失(logistic regression loss) 或者 交叉熵损失(cross-entropy loss),
定义在概率估计(probability estimates)上。 它通常用于(多项式)logistic回归 (multinomial logistic regression)
和 神经网络(neural networks) 以及 期望最大化(expectation-maximization)的一些变体中，
并且可用于评估分类器的概率输出(probability outputs: <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>)而不是其离散预测值(discrete predictions)。</p>
<p>对于二分类问题，并伴有 真实类标签 <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span> 以及 一个概率估计 <span class="math notranslate nohighlight">\(p = \operatorname{Pr}(y = 1)\)</span>,
则 每个样本的对数损失是给定真实标签时分类器的负对数似然函数(negative log-likelihood):</p>
<div class="math notranslate nohighlight">
\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</div>
<p>上面的公式可以按下述方法扩展到多类别分类的情形。
首先把一个样本集合的真实类标签编码成 1-of-K 二进制指示矩阵(1-of-K binary indicator matrix): <span class="math notranslate nohighlight">\(Y\)</span>,
也就是说，如果样本 <span class="math notranslate nohighlight">\(i\)</span> 有标签 <span class="math notranslate nohighlight">\(k\)</span>，而 标签 <span class="math notranslate nohighlight">\(k\)</span> 又是取自于 <span class="math notranslate nohighlight">\(K\)</span> 个类标签的集合中，那么就让 <span class="math notranslate nohighlight">\(y_{i,k} = 1\)</span>。
再令 <span class="math notranslate nohighlight">\(P\)</span> 是概率的估计值的矩阵，并有 <span class="math notranslate nohighlight">\(p_{i,k} = \operatorname{Pr}(t_{i,k} = 1)\)</span>。
那么 整个样本集上的对数损失就定义如下：</p>
<div class="math notranslate nohighlight">
\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</div>
<p>为了让你看清楚上面的公式是如何对二类对数损失(binary log loss)进行推广的，请注意 在二分类情况下，
<span class="math notranslate nohighlight">\(p_{i,0} = 1 - p_{i,1}\)</span> 和 <span class="math notranslate nohighlight">\(y_{i,0} = 1 - y_{i,1}\)</span>,
因此在 <span class="math notranslate nohighlight">\(y_{i,k} \in \{0,1\}\)</span> 上扩展内部核 就可以得到(binary log loss)。</p>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss" title="sklearn.metrics.log_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">log_loss</span></code></a> 在真实标签和概率矩阵的列表给定后计算对数损失, as returned by an estimator’s <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>
method.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">log_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="o">.</span><span class="mi">01</span><span class="p">,</span> <span class="o">.</span><span class="mi">99</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>    <span class="c1"># doctest: +ELLIPSIS</span>
<span class="go">0.1738...</span>
</pre></div>
</div>
<p>在 <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> 中的第一个预测 <code class="docutils literal notranslate"><span class="pre">[.9,</span> <span class="pre">.1]</span></code> 意味着 第一个样本的标签是0的概率达到了90%。对数损失是非负的。</p>
</div>
<div class="section" id="matthews">
<span id="matthews-corrcoef"></span><h3>3.3.2.12. Matthews相关系数<a class="headerlink" href="#matthews" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a> 计算用于binary classes的 <a class="reference external" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthew’s correlation coefficient (MCC)</a>
引用维基百科对 Matthews相关系数 的解释：</p>
<blockquote>
<div>“Matthews相关系数(The Matthews correlation coefficient)在机器学习中用作二分类的质量的度量。
它以正负阴阳(true and false positives and negatives)为考虑， 并且被广泛认为是一个均衡的度量，
即使是在各个类的样本集大小非常不一样大的时候也可以使用。MCC本质上是一个取值范围在-1到+1的相关系数(correlation coefficient),
“0” 代表了 平均随机预测(average random prediction)，”-1” 代表了 反转预测(inverse prediction)。
The statistic is also known as the phi coefficient.</div></blockquote>
<p>在二分类情况下, <span class="math notranslate nohighlight">\(tp\)</span>, <span class="math notranslate nohighlight">\(tn\)</span>, <span class="math notranslate nohighlight">\(fp\)</span> 和 <span class="math notranslate nohighlight">\(fn\)</span> 分别指的是 the number of true positives, true negatives, false
positives and false negatives, 那么 MCC 就定义为：</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</div>
<p>在多类分类任务中, 给定 <span class="math notranslate nohighlight">\(K\)</span> 个类的 <a class="reference internal" href="generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix" title="sklearn.metrics.confusion_matrix"><code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code></a> <span class="math notranslate nohighlight">\(C\)</span> 以后，Matthews 相关系数可以如此定义
<a class="reference external" href="http://rk.kvl.dk/introduction/index.html">defined</a> 。  为了简化它的定义，我们用以下这些中间变量：</p>
<ul class="simple">
<li><span class="math notranslate nohighlight">\(t_k=\sum_{i}^{K} C_{ik}\)</span> the number of times class <span class="math notranslate nohighlight">\(k\)</span> truly occurred,</li>
<li><span class="math notranslate nohighlight">\(p_k=\sum_{i}^{K} C_{ki}\)</span> the number of times class <span class="math notranslate nohighlight">\(k\)</span> was predicted,</li>
<li><span class="math notranslate nohighlight">\(c=\sum_{k}^{K} C_{kk}\)</span> the total number of samples correctly predicted,</li>
<li><span class="math notranslate nohighlight">\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\)</span> the total number of samples.</li>
</ul>
<p>然后，multiclass MCC 的定义如下所示：</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{
    c \times s - \sum_{k}^{K} p_k \times t_k
}{\sqrt{
    (s^2 - \sum_{k}^{K} p_k^2) \times
    (s^2 - \sum_{k}^{K} t_k^2)
}}\]</div>
<p>当有两种以上类标签的时候，MCC的值将不再在-1到+1之间。它的最小值将是一个介于-1到0之间的数，具体数值取决于真实类标签的数量和分布。
它的最大值总是+1。</p>
<p>下面是使用 <a class="reference internal" href="generated/sklearn.metrics.matthews_corrcoef.html#sklearn.metrics.matthews_corrcoef" title="sklearn.metrics.matthews_corrcoef"><code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code></a> 函数的一个简单小例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">matthews_corrcoef</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">-0.33...</span>
</pre></div>
</div>
</div>
<div class="section" id="receiver-operating-characteristic-roc">
<span id="roc-metrics"></span><h3>3.3.2.13. Receiver operating characteristic (ROC)<a class="headerlink" href="#receiver-operating-characteristic-roc" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code></a> 计算 接收机操作特性曲线( <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">receiver operating characteristic curve, or ROC curve</a>)。</p>
<p>引用自维基百科 :</p>
<blockquote>
<div>“一个 接收机操作特性 (ROC), 或简单点叫做 ROC 曲线, 是一幅图，这幅图展示了一个二分类器系统在它的判别阈值(discrimination threshold)
不断变化的时候的性能。这条曲线上坐标点的纵轴取值是真正的正样本的比例(真阳率: TPR= true positive rate, i.e. the fraction of true positives out of the positives);
这条曲线上坐标点的横轴取值是负样本中假的正样本的比例(假阳率or虚警率 FPR = false positive rate，i.e.  the fraction of false positives out of the negatives)。
当不断改变二分类器的阈值的时候，上述TPR和FPR就会跟着发生变化。这样每一个阈值都会对应一对坐标点(TPR,FPR)，只要不断改变阈值就会产生一条曲线。
TPR 也被称之为 灵敏度(sensitivity), 而 FPR 是 one minus the specificity or true negative rate.”
(译者注：在二分类问题中，我们有时候会把其中一类特别关注，比如疾病检查的时候各种身体指标有阴性和阳性之分，阳性代表不正常的类是需要被特别关注的；
再比如在雷达目标检测中，对真正的目标的检出是非常重要的，雷达系统灵敏度越高就代表能够捕捉的真实目标就越多，
但是灵敏度太高会导致雷达系统把非真实目标看作是真实目标从而报虚警。
但是报虚警总比漏检真实目标带来的危害小，因为在雷达武器系统中漏检真实目标是致命的错误。这两个例子中的二分类问题都有一个重点关注的类：positive类。
所以ROC曲线反应的指标也是以positive类为核心的：真阳率(TPR) vs 假阳率(FPR))</div></blockquote>
<p>This function requires the true binary
value and the target scores, which can either be probability estimates of the
positive class, confidence values, or binary decisions.
下面是函数 <a class="reference internal" href="generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve" title="sklearn.metrics.roc_curve"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code></a> 的一个小例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span>
<span class="go">array([0. , 0. , 0.5, 0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr</span>
<span class="go">array([0. , 0.5, 0.5, 1. , 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresholds</span>
<span class="go">array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])</span>
</pre></div>
</div>
<p>下图展示了这样一个ROC曲线的例子:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../images/sphx_glr_plot_roc_0011.png" class="align-center" src="../images/sphx_glr_plot_roc_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> 计算 ROC曲线下的面积, 也被记为 AUC 或 AUROC.  通过计算曲线下的面积，ROC曲线信息被总结到一个数字中。
更多详细信息请参考  <a class="reference external" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve">Wikipedia article on AUC</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">roc_auc_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="go">0.75</span>
</pre></div>
</div>
<p>在多标签分类问题中，函数 <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> 被扩展到计算所有标签上的平均值，就像这个  <a class="reference internal" href="#average"><span class="std std-ref">above</span></a> 一样。</p>
<p>与这些 the subset accuracy, the Hamming loss, 或 the F1 score 相比, ROC 不需要对每个label都优化一个阈值。
如果预测输出已经被二值化(binarized)，那么函数 <a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> 也可被用于多类分类问题中。</p>
<p>在那些高虚警率(false positive rate)不被容忍的情况下，<a class="reference internal" href="generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score" title="sklearn.metrics.roc_auc_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code></a> 函数的参数 <code class="docutils literal notranslate"><span class="pre">max_fpr</span></code> 可被用来把ROC曲线累加到一个给定的限制(
can be used to summarize the ROC curve up to the given limit)。</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../images/sphx_glr_plot_roc_0021.png" class="align-center" src="../images/sphx_glr_plot_roc_0021.png" style="width: 480.0px; height: 360.0px;" /></a>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py"><span class="std std-ref">Receiver Operating Characteristic (ROC)</span></a>
for an example of using ROC to
evaluate the quality of the output of a classifier.</li>
<li>See <a class="reference internal" href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a>
for an example of using ROC to
evaluate classifier output quality, using cross-validation.</li>
<li>See <a class="reference internal" href="../auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">Species distribution modeling</span></a>
for an example of using ROC to
model species distribution.</li>
</ul>
</div>
</div>
<div class="section" id="zero-one-loss">
<span id="id39"></span><h3>3.3.2.14. Zero one loss<a class="headerlink" href="#zero-one-loss" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a> 计算在一个样本上的 0-1 分类损失(<span class="math notranslate nohighlight">\(L_{0-1}\)</span>) 的和或均值。
默认情况下，该函数会在样本上进行归一化(normalize)。如果想要获得 <span class="math notranslate nohighlight">\(L_{0-1}\)</span> 的和，
把 <code class="docutils literal notranslate"><span class="pre">normalize</span></code> 设为 <code class="docutils literal notranslate"><span class="pre">False</span></code> 。</p>
<p>在多标签分类问题中，函数 <a class="reference internal" href="generated/sklearn.metrics.zero_one_loss.html#sklearn.metrics.zero_one_loss" title="sklearn.metrics.zero_one_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code></a> 给一个子集评分为 1 如果这个子集的真实标签与预测严格匹配，反之如果有任何一处不匹配则评分为 0.
默认情况下，函数返回不完美预测子集的百分比(the percentage of imperfectly predicted subsets)。
如果想要获得这些不完美预测子集的数量，只需要把参数 <code class="docutils literal notranslate"><span class="pre">normalize</span></code> 设置成 <code class="docutils literal notranslate"><span class="pre">False</span></code>。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是 第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的预测值，<span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真值，那么 0-1损失 <span class="math notranslate nohighlight">\(L_{0-1}\)</span> 定义如下：</p>
<div class="math notranslate nohighlight">
\[L_{0-1}(y_i, \hat{y}_i) = 1(\hat{y}_i \not= y_i)\]</div>
<p>其中 <span class="math notranslate nohighlight">\(1(x)\)</span> 是示性函数(<a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">indicator function</a>)。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">zero_one_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1</span>
</pre></div>
</div>
<p>In the multilabel case with binary label indicators, where the first label
set [0,1] has an error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.5</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>  <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">示例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a>
for an example of zero one loss usage to perform recursive feature
elimination with cross-validation.</li>
</ul>
</div>
</div>
<div class="section" id="brier-score-loss">
<span id="id41"></span><h3>3.3.2.15. Brier score loss<a class="headerlink" href="#brier-score-loss" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss" title="sklearn.metrics.brier_score_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">brier_score_loss</span></code></a> 函数计算用于二分类的 <a class="reference external" href="https://en.wikipedia.org/wiki/Brier_score">Brier score</a>，
引用维基百科的话说:</p>
<blockquote>
<div>“The Brier score 是一个用于度量概率性预测(probabilistic predictions)的准确率的合适的评分函数。
它可以被用到某些任务中，在这些任务里面 预测必须分配概率到一个由互斥离散输出组成的集合上。
It is applicable to tasks in which predictions
must assign probabilities to a set of mutually exclusive discrete outcomes.”</div></blockquote>
<p>该函数返回实际输出(actual outcome)和可能输出(possible outcome)的预测概率之间的平均平方差的得分。
实际输出必须是 1 或 0 (true or false)，而实际输出的预测概率可以是一个介于0和1之间的数。</p>
<p>brier score loss 也是一个介于 0 到 1 之间的数，而且得分越低(也就是平均平方误差)则预测越精确。
它可被认为是对一组概率性预测的 “calibration” 的度量。(It can be thought of as a measure of the
“calibration” of a set of probabilistic predictions.)</p>
<div class="math notranslate nohighlight">
\[BS = \frac{1}{N} \sum_{t=1}^{N}(f_t - o_t)^2\]</div>
<p>其中 : <span class="math notranslate nohighlight">\(N\)</span> 是预测的总数, <span class="math notranslate nohighlight">\(f_t\)</span> 是实际输出 <span class="math notranslate nohighlight">\(o_t\)</span> 的预测出的概率(predicted probability)。</p>
<p>下面是该函数的用法示例：:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">brier_score_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true_categorical</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;spam&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;ham&quot;</span><span class="p">,</span> <span class="s2">&quot;spam&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true_categorical</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="s2">&quot;ham&quot;</span><span class="p">)</span>
<span class="go">0.055</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brier_score_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/calibration/plot_calibration.html#sphx-glr-auto-examples-calibration-plot-calibration-py"><span class="std std-ref">Probability calibration of classifiers</span></a>
for an example of Brier score loss usage to perform probability
calibration of classifiers.</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li>G. Brier, <a class="reference external" href="ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf">Verification of forecasts expressed in terms of probability</a>,
Monthly weather review 78.1 (1950)</li>
</ul>
</div>
</div>
</div>
<div class="section" id="multilabel-ranking-metrics">
<span id="id42"></span><h2>3.3.3. 多标签排序指标<a class="headerlink" href="#multilabel-ranking-metrics" title="Permalink to this headline">¶</a></h2>
<p>在多标签学习中，每个样本可以有任意数量的真实标签与其自身关联。学习的目标是对真实的标签给出高的得分和更好的排序。
(In multilabel learning, each sample can have any number of ground truth labels
associated with it. The goal is to give high scores and better rank to
the ground truth labels.)</p>
<div class="section" id="coverage-error">
<span id="id43"></span><h3>3.3.3.1. Coverage error<a class="headerlink" href="#coverage-error" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="generated/sklearn.metrics.coverage_error.html#sklearn.metrics.coverage_error" title="sklearn.metrics.coverage_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">coverage_error</span></code></a> function computes the average number of labels that
have to be included in the final prediction such that all true labels
are predicted. This is useful if you want to know how many top-scored-labels
you have to predict in average without missing any true one. The best value
of this metrics is thus the average number of true labels.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Our implementation’s score is 1 greater than the one given in Tsoumakas
et al., 2010. This extends it to handle the degenerate case in which an
instance has 0 true labels.</p>
</div>
<p>Formally, given a binary indicator matrix of the ground truth labels
<span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span> and the
score associated with each label
<span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>,
the coverage is defined as</p>
<div class="math notranslate nohighlight">
\[coverage(y, \hat{f}) = \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \max_{j:y_{ij} = 1} \text{rank}_{ij}\]</div>
<p>with <span class="math notranslate nohighlight">\(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\)</span>.
Given the rank definition, ties in <code class="docutils literal notranslate"><span class="pre">y_scores</span></code> are broken by giving the
maximal rank that would have been assigned to all tied values.</p>
<p>Here is a small example of usage of this function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">coverage_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">coverage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">2.5</span>
</pre></div>
</div>
</div>
<div class="section" id="label-ranking-average-precision">
<span id="id44"></span><h3>3.3.3.2. Label ranking average precision<a class="headerlink" href="#label-ranking-average-precision" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="generated/sklearn.metrics.label_ranking_average_precision_score.html#sklearn.metrics.label_ranking_average_precision_score" title="sklearn.metrics.label_ranking_average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">label_ranking_average_precision_score</span></code></a> function
implements label ranking average precision (LRAP). This metric is linked to
the <a class="reference internal" href="generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score" title="sklearn.metrics.average_precision_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">average_precision_score</span></code></a> function, but is based on the notion of
label ranking instead of precision and recall.</p>
<p>Label ranking average precision (LRAP) averages over the samples the answer to
the following question: for each ground truth label, what fraction of
higher-ranked labels were true labels? This performance measure will be higher
if you are able to give better rank to the labels associated with each sample.
The obtained score is always strictly greater than 0, and the best value is 1.
If there is exactly one relevant label per sample, label ranking average
precision is equivalent to the <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank">mean
reciprocal rank</a>.</p>
<p>Formally, given a binary indicator matrix of the ground truth labels
<span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span>
and the score associated with each label
<span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>,
the average precision is defined as</p>
<div class="math notranslate nohighlight">
\[LRAP(y, \hat{f}) = \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0}
  \sum_{j:y_{ij} = 1} \frac{|\mathcal{L}_{ij}|}{\text{rank}_{ij}}\]</div>
<p>where
<span class="math notranslate nohighlight">\(\mathcal{L}_{ij} = \left\{k: y_{ik} = 1, \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\)</span>,
<span class="math notranslate nohighlight">\(\text{rank}_{ij} = \left|\left\{k: \hat{f}_{ik} \geq \hat{f}_{ij} \right\}\right|\)</span>,
<span class="math notranslate nohighlight">\(|\cdot|\)</span> computes the cardinality of the set (i.e., the number of
elements in the set), and <span class="math notranslate nohighlight">\(||\cdot||_0\)</span> is the <span class="math notranslate nohighlight">\(\ell_0\)</span> “norm”
(which computes the number of nonzero elements in a vector).</p>
<p>Here is a small example of usage of this function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">label_ranking_average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span> 
<span class="go">0.416...</span>
</pre></div>
</div>
</div>
<div class="section" id="ranking-loss">
<span id="label-ranking-loss"></span><h3>3.3.3.3. Ranking loss<a class="headerlink" href="#ranking-loss" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="generated/sklearn.metrics.label_ranking_loss.html#sklearn.metrics.label_ranking_loss" title="sklearn.metrics.label_ranking_loss"><code class="xref py py-func docutils literal notranslate"><span class="pre">label_ranking_loss</span></code></a> function computes the ranking loss which
averages over the samples the number of label pairs that are incorrectly
ordered, i.e. true labels have a lower score than false labels, weighted by
the inverse of the number of ordered pairs of false and true labels.
The lowest achievable ranking loss is zero.</p>
<p>Formally, given a binary indicator matrix of the ground truth labels
<span class="math notranslate nohighlight">\(y \in \left\{0, 1\right\}^{n_\text{samples} \times n_\text{labels}}\)</span> and the
score associated with each label
<span class="math notranslate nohighlight">\(\hat{f} \in \mathbb{R}^{n_\text{samples} \times n_\text{labels}}\)</span>,
the ranking loss is defined as</p>
<div class="math notranslate nohighlight">
\[\text{ranking\_loss}(y, \hat{f}) =  \frac{1}{n_{\text{samples}}}
  \sum_{i=0}^{n_{\text{samples}} - 1} \frac{1}{||y_i||_0(n_\text{labels} - ||y_i||_0)}
  \left|\left\{(k, l): \hat{f}_{ik} \leq \hat{f}_{il}, y_{ik} = 1, y_{il} = 0&nbsp;\right\}\right|\]</div>
<p>where <span class="math notranslate nohighlight">\(|\cdot|\)</span> computes the cardinality of the set (i.e., the number of
elements in the set) and <span class="math notranslate nohighlight">\(||\cdot||_0\)</span> is the <span class="math notranslate nohighlight">\(\ell_0\)</span> “norm”
(which computes the number of nonzero elements in a vector).</p>
<p>Here is a small example of usage of this function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">label_ranking_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span> 
<span class="go">0.75...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With the following prediction, we have perfect and minimal loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label_ranking_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li>Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2010). Mining multi-label data. In
Data mining and knowledge discovery handbook (pp. 667-685). Springer US.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="regression-metrics">
<span id="id45"></span><h2>3.3.4. 回归问题的指标<a class="headerlink" href="#regression-metrics" title="Permalink to this headline">¶</a></h2>
<div class="topic">
<p class="topic-title first">译者注</p>
<p>在此献上我做的视频，希望对大家有所帮助。视频地址：
(<a class="reference external" href="http://www.studyai.com/course/play/ab9f9976527946f28d4c0044fb7a3afa">Sklearn 回归器评估方法</a>)</p>
</div>
<p><a class="reference internal" href="classes.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> 模块 实现了若干 loss, score, 和 工具函数 来度量回归算法的性能。
他们中的其中一些已经被加强用来处理多输出问题，例如： <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a>,
<a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a>, <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> 和
<a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>.</p>
<p>这些函数都有一个关键字参数 <code class="docutils literal notranslate"><span class="pre">multioutput</span></code> 用来指定对每个独立目标的得分或损失进行平均的方式。
默认的参数取值是 <code class="docutils literal notranslate"><span class="pre">'uniform_average'</span></code> ，也就是对所有目标输出的得分或损失进行均匀加权后再取平均的方式。
如果一个shape为 <code class="docutils literal notranslate"><span class="pre">(n_outputs,)</span></code> 的 <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> 被传入，那么它的每个元素被解释为权重，然后指标函数就会返回对应的加权平均值。
are interpreted as weights and an according weighted average is
returned. 如果 参数 <code class="docutils literal notranslate"><span class="pre">multioutput</span></code> 被设置为 <code class="docutils literal notranslate"><span class="pre">'raw_values'</span></code> , 那么所有未经改变的单独的得分或者损失将会被指标函数作为数组返回，
返回数组的shape是 <code class="docutils literal notranslate"><span class="pre">(n_outputs,)</span></code>。</p>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> 和 <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> 的 <code class="docutils literal notranslate"><span class="pre">multioutput</span></code> 参数 还可接受另外的一种取值：<code class="docutils literal notranslate"><span class="pre">'variance_weighted'</span></code>。
这个参数选项会导致每个单独的得分被加权，而权重数值则恰好是对应目标变量的方差。这个参数设置量化了全局捕获的未缩放的方差(globally captured
unscaled variance)。如果多个目标变量有不同的尺度，那么这个加权得分将会把更多的重要性放在具有良好解释的方差较高的变量上。
为了向后兼容， <code class="docutils literal notranslate"><span class="pre">multioutput='variance_weighted'</span></code> 是函数 <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> 的默认取值, 在后面的sklearn版本中将会改为 <code class="docutils literal notranslate"><span class="pre">'uniform_average'</span></code> 。</p>
<div class="section" id="explained-variance-score">
<span id="id47"></span><h3>3.3.4.1. Explained variance score<a class="headerlink" href="#explained-variance-score" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> 计算 <a class="reference external" href="https://en.wikipedia.org/wiki/Explained_variation">explained variance regression score</a>.</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是 <span class="math notranslate nohighlight">\(i\)</span>-th 样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真实目标值,
<span class="math notranslate nohighlight">\(Var\)</span> 是 <a class="reference external" href="https://en.wikipedia.org/wiki/Variance">Variance</a>, 即 标准差的平方,
则 explained variance 用下面的方法估计得到:</p>
<div class="math notranslate nohighlight">
\[\texttt{explained\_{}variance}(y, \hat{y}) = 1 - \frac{Var\{ y - \hat{y}\}}{Var\{y\}}\]</div>
<p>最好的得分是 1.0, explained variance 的值越低越不好。</p>
<p>下面是 <a class="reference internal" href="generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score" title="sklearn.metrics.explained_variance_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">explained_variance_score</span></code></a> 函数的用法示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">explained_variance_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.957...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">array([0.967..., 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">0.990...</span>
</pre></div>
</div>
</div>
<div class="section" id="mean-absolute-error">
<span id="id48"></span><h3>3.3.4.2. Mean absolute error<a class="headerlink" href="#mean-absolute-error" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a> 计算平均绝对误差(<a class="reference external" href="https://en.wikipedia.org/wiki/Mean_absolute_error">mean absolute error</a>),
它是一个对应于 绝对误差损失 或 <span class="math notranslate nohighlight">\(l1\)</span>-norm损失 的期望值的风险指标。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是 <span class="math notranslate nohighlight">\(i\)</span>-th 样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真实值, 则在 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> 个样本上估计的
平均绝对误差(MAE)定义如下：</p>
<div class="math notranslate nohighlight">
\[\text{MAE}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1} \left| y_i - \hat{y}_i \right|.\]</div>
<p>下面是 <a class="reference internal" href="generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error" title="sklearn.metrics.mean_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_absolute_error</span></code></a> 函数的用法示例:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">0.85...</span>
</pre></div>
</div>
</div>
<div class="section" id="mean-squared-error">
<span id="id50"></span><h3>3.3.4.3. Mean squared error<a class="headerlink" href="#mean-squared-error" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a> 计算均方误差 ( <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_squared_error">mean square error</a> ),
是一个对应于平方（二次）误差或损失的期望值的风险度量。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是 <span class="math notranslate nohighlight">\(i\)</span>-th 样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真实值, 则在 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> 个样本上估计的
均方误差（MSE）定义如下：</p>
<div class="math notranslate nohighlight">
\[\text{MSE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (y_i - \hat{y}_i)^2.\]</div>
<p>下面是函数 <a class="reference internal" href="generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error" title="sklearn.metrics.mean_squared_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_error</span></code></a> 的例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.375</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.7083...</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/ensemble/plot_gradient_boosting_regression.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regression-py"><span class="std std-ref">Gradient Boosting regression</span></a>
for an example of mean squared error usage to
evaluate gradient boosting regression.</li>
</ul>
</div>
</div>
<div class="section" id="mean-squared-logarithmic-error">
<span id="mean-squared-log-error"></span><h3>3.3.4.4. Mean squared logarithmic error<a class="headerlink" href="#mean-squared-logarithmic-error" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_log_error</span></code></a> 计算一个与平方对数误差(或损失)的期望值相对应的风险指标(risk metric)：</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真值, 在 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span>
个样本集上估计的MSLE(mean squared logarithmic error) 定义如下：</p>
<div class="math notranslate nohighlight">
\[\text{MSLE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (\log_e (1 + y_i) - \log_e (1 + \hat{y}_i) )^2.\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\log_e (x)\)</span> 是 <span class="math notranslate nohighlight">\(x\)</span> 的自然对数。 当目标变量(target variable)呈现指数增长的时候(比如 人口数量，商品月平均销量)使用这个测度指标是最好的。This metric
请注意 这个测度指标对under-predicted estimate的惩罚大于over-predicted estimate。</p>
<p>下面是使用函数 <a class="reference internal" href="generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error" title="sklearn.metrics.mean_squared_log_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">mean_squared_log_error</span></code></a> 的一个小例子</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_squared_log_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.039...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.044...</span>
</pre></div>
</div>
</div>
<div class="section" id="median-absolute-error">
<span id="id51"></span><h3>3.3.4.5. Median absolute error<a class="headerlink" href="#median-absolute-error" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a> 相当有意思，因为它对离群点(outliers)比较鲁棒。 损失的计算是通过对所有样本点上的目标值和预测值的绝对误差取中值进行的。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真值，在 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> 个样本上估计的
中值绝对误差(MedAE:median absolute error) 如下定义：</p>
<div class="math notranslate nohighlight">
\[\text{MedAE}(y, \hat{y}) = \text{median}(\mid y_1 - \hat{y}_1 \mid, \ldots, \mid y_n - \hat{y}_n \mid).\]</div>
<p><a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a> 函数不支持 multioutput。</p>
<p>下面是函数 <a class="reference internal" href="generated/sklearn.metrics.median_absolute_error.html#sklearn.metrics.median_absolute_error" title="sklearn.metrics.median_absolute_error"><code class="xref py py-func docutils literal notranslate"><span class="pre">median_absolute_error</span></code></a> 用法示例</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">median_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
</div>
<div class="section" id="r2-score-the-coefficient-of-determination">
<span id="r2-score"></span><h3>3.3.4.6. R² score, the coefficient of determination<a class="headerlink" href="#r2-score-the-coefficient-of-determination" title="Permalink to this headline">¶</a></h3>
<p>函数 <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> 计算 R², the <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of determination</a>.
它提供了模型对未来样本的预测好坏的度量(It provides a measure of how well future samples are likely to
be predicted by the model.)。 可能的最好得分是 1.0 而且它可以取负值 (因为模型可能要多坏有多坏).
对于一个常量模型不管输入特征如何变化，它的预测结果总是 y 的期望值，那么这个模型的 R^2 得分将是0.0。</p>
<p>如果 <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> 是第 <span class="math notranslate nohighlight">\(i\)</span> 个样本的预测值, 并且 <span class="math notranslate nohighlight">\(y_i\)</span> 是对应的真值，
那么 <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span> 个样本上估计出的 R² score 定义如下：</p>
<div class="math notranslate nohighlight">
\[R^2(y, \hat{y}) = 1 - \frac{\sum_{i=0}^{n_{\text{samples}} - 1} (y_i - \hat{y}_i)^2}{\sum_{i=0}^{n_\text{samples} - 1} (y_i - \bar{y})^2}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\bar{y} =  \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1} y_i\)</span>.</p>
<p>下面 是一个使用 函数 <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a> 的例子:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">r2_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>  
<span class="go">0.948...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;variance_weighted&#39;</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">0.938...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;uniform_average&#39;</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">0.936...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="gp">... </span>
<span class="go">array([0.965..., 0.908...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">0.925...</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>See <a class="reference internal" href="../auto_examples/linear_model/plot_lasso_and_elasticnet.html#sphx-glr-auto-examples-linear-model-plot-lasso-and-elasticnet-py"><span class="std std-ref">Lasso and Elastic Net for Sparse Signals</span></a>
for an example of R² score usage to
evaluate Lasso and Elastic Net on sparse signals.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="clustering-metrics">
<span id="id52"></span><h2>3.3.5. 聚类问题的测度<a class="headerlink" href="#clustering-metrics" title="Permalink to this headline">¶</a></h2>
<p>该 <a class="reference internal" href="classes.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> 模块实现了一些 loss, score 和 utility 函数. 更多信息请参阅
<a class="reference internal" href="clustering.html#clustering-evaluation"><span class="std std-ref">聚类算法性能评估</span></a> 部分, 例如聚类, 以及用于 <a class="reference internal" href="biclustering.html#biclustering-evaluation"><span class="std std-ref">Biclustering evaluation</span></a> 的评测.</p>
</div>
<div class="section" id="dummy-estimators">
<span id="id53"></span><h2>3.3.6. 无实际意义的估计器(Dummy estimators)<a class="headerlink" href="#dummy-estimators" title="Permalink to this headline">¶</a></h2>
<p>在进行监督学习的过程中，简单的 sanity check（理性检查）包括将人的估计与简单的经验法则进行比较.
<a class="reference internal" href="generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="sklearn.dummy.DummyClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code></a> 类实现了一些这样的简单分类策略:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">stratified</span></code> 根据训练集中类的分布做出随机预测</li>
<li><code class="docutils literal notranslate"><span class="pre">most_frequent</span></code> 总是以训练集中频率最高的类标签作为预测.</li>
<li><code class="docutils literal notranslate"><span class="pre">prior</span></code> 总是给出能够最大化类先验概率的预测 (类似于 <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>) 并且 <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> 返回类先验概率.</li>
<li><code class="docutils literal notranslate"><span class="pre">uniform</span></code> 产生均匀随机猜测式的预测结果.</li>
<li><dl class="first docutils">
<dt><code class="docutils literal notranslate"><span class="pre">constant</span></code> 预测的类标签是由用户指定的某个固定标签.</dt>
<dd>这种方法的主要动机是 F1-scoring, 这种情况下正类比较少.</dd>
</dl>
</li>
</ul>
<p>请注意, 以上这些所有的策略, <code class="docutils literal notranslate"><span class="pre">predict</span></code> 方法完全的忽略了输入数据!</p>
<p>为了展示 <a class="reference internal" href="generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier" title="sklearn.dummy.DummyClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code></a> 的用法, 让我们首先创建一个非平衡数据集</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>接着，我们比较 <code class="docutils literal notranslate"><span class="pre">SVC</span></code> 和 <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code> 的准确性</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="k">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> 
<span class="go">0.63...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">DummyClassifier(constant=None, random_state=0, strategy=&#39;most_frequent&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  
<span class="go">0.57...</span>
</pre></div>
</div>
<p>我们看到 <code class="docutils literal notranslate"><span class="pre">SVC</span></code> 做的并不比 dummy classifier 好。现在我们修改核函数</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  
<span class="go">0.97...</span>
</pre></div>
</div>
<p>我们看到准确率提升到将近 100%. 建议采用交叉验证策略, 以更好地估计精度, 如果不是太耗 CPU 的话。
更多信息请参阅 <a class="reference internal" href="cross_validation.html#cross-validation"><span class="std std-ref">交叉验证:评估估计器的性能</span></a> 部分. 此外，如果要优化参数空间，强烈建议您使用适当的方法;
更多详情请参阅 <a class="reference internal" href="grid_search.html#grid-search"><span class="std std-ref">通过网格搜索调节估计器超参数</span></a> 部分。</p>
<p>通常来说，当分类器的准确度太接近随机情况时，这可能意味着出现了一些问题: 特征没有帮助, 超参数没有正确调整, 类数目不平衡造成分类器有问题等…</p>
<p><a class="reference internal" href="generated/sklearn.dummy.DummyRegressor.html#sklearn.dummy.DummyRegressor" title="sklearn.dummy.DummyRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">DummyRegressor</span></code></a> 还实现了四个简单的经验法则来进行回归:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">mean</span></code> 总是预测训练目标的平均值.</li>
<li><code class="docutils literal notranslate"><span class="pre">median</span></code> 总是预测训练目标的中值.</li>
<li><code class="docutils literal notranslate"><span class="pre">quantile</span></code> 总是预测用户提供的训练目标的 quantile（分位数）.</li>
<li><code class="docutils literal notranslate"><span class="pre">constant</span></code> 总是预测由用户提供的常数值.</li>
</ul>
<p>在以上所有的策略中, <code class="docutils literal notranslate"><span class="pre">predict</span></code> 方法完全忽略了输入数据.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  </div>
  
  <div class="footer">
    &copy; 2007 - 2018, scikit-learn developers (BSD License).
    <!--
    <a href="../_sources/modules/model_evaluation.rst.txt" rel="nofollow">Show this page source</a> -->
  </div>
  <div class="rel">
    
      <div class="buttonPrevious">
        <a href="generated/sklearn.ensemble.GradientBoostingRegressor.html">Previous
        </a>
      </div>
      <div class="buttonNext">
        <a href="model_persistence.html">Next
        </a>
      </div>
      
    </div>

    
    <script>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) }; ga.l = +new Date;
      ga('create', 'UA-22606712-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    
    <script>
      (function () {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </body>
</html>