

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    <title>2.7. 新奇点和孤立点检测(Novelty and Outlier Detection) &#8212; scikit-learn 0.20.2 documentation</title>
<!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="../static/css/bootstrap.min.css" media="screen" />
<link rel="stylesheet" href="../static/css/bootstrap-responsive.css" />

    <link rel="stylesheet" href="../static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
    <script type="text/javascript" src="../static/jquery.js"></script>
    <script type="text/javascript" src="../static/underscore.js"></script>
    <script type="text/javascript" src="../static/doctools.js"></script>
    <script type="text/javascript" src="../static/js/copybutton.js"></script>
    <script type="text/javascript" src="../static/js/extra.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_SVG"></script>
    <link rel="shortcut icon" href="../static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2.8. 概率密度估计(Density Estimation)" href="density.html" />
    <link rel="prev" title="2.6. 协方差估计(Covariance estimation)" href="covariance.html" />


<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<script src="../static/js/bootstrap.min.js" type="text/javascript"></script>
<script>
  VERSION_SUBDIR = (function (groups) {
    return groups ? groups[1] : null;
  })(location.href.match(/^https?:\/\/scikit-learn.org\/([^\/]+)/));
</script>
<link rel="canonical" href="http://scikit-learn.org/stable/modules/outlier_detection.html" />

<script type="text/javascript">
  $("div.buttonNext, div.buttonPrevious").hover(
    function () {
      $(this).css('background-color', '#FF9C34');
    },
    function () {
      $(this).css('background-color', '#A7D6E2');
    }
  );
  function showMenu() {
    var topNav = document.getElementById("scikit-navbar");
    if (topNav.className === "navbar") {
      topNav.className += " responsive";
    } else {
      topNav.className = "navbar";
    }
  };
</script>

<!-- 百度站长统计代码 -->
<script>
  var _hmt = _hmt || [];
  (function () {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e7836e37a4cb7584127a787e9b44e3f1";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
</script>


  </head><body>

<div class="header-wrapper">
  <div class="header">
    <p class="logo"><a href="../index.html">
        <img src="../static/scikit-learn-logo-small.png" alt="Logo" />
      </a>
    </p><div class="navbar" id="scikit-navbar">
      <ul>
        <li><a href="../index.html">首页</a></li>
        <li><a href="../install.html">安装</a></li>
        <li class="btn-li">
          <div class="btn-group">
            <a href="../documentation.html">文档</a>
            <a class="btn dropdown-toggle" data-toggle="dropdown">
              <span class="caret"></span>
            </a>
            <ul class="dropdown-menu">
              <li class="link-title">Scikit-learn
                <script>document.write(DOCUMENTATION_OPTIONS.VERSION + (VERSION_SUBDIR ? " (" + VERSION_SUBDIR + ")" : ""));</script>
              </li>
              <li><a href="../tutorial/index.html">教程</a></li>
              <li><a href="../user_guide.html">用户指南</a></li>
              <li><a href="classes.html">API</a></li>
              <li><a href="../glossary.html">词汇表</a></li>
              <li><a href="../faq.html">FAQ</a></li>
              <li><a href="../developers/contributing.html">贡献</a></li>
              <li><a href="../roadmap.html">路线图</a></li>
              <li class="divider"></li>
              <script>if (VERSION_SUBDIR != "stable") document.write('<li><a href="https://www.studyai.cn">稳定版</a></li>')</script>
              <script>if (VERSION_SUBDIR != "dev") document.write('<li><a href="http://scikit-learn.org/dev/documentation.html" target="_blank">开发版</a></li>')</script>
              <li><a href="http://scikit-learn.org/dev/versions.html">所有可用版本</a></li>
              <li><a href="../downloads/scikit-learn-docs.pdf">PDF 文档</a></li>
            </ul>
          </div>
        </li>
        <li><a href="../auto_examples/index.html">案例</a></li>
      </ul>
      <a href="javascript:void(0);" onclick="showMenu()">
        <div class="nav-icon">
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
          <div class="hamburger-line"></div>
        </div>
      </a>
      <div class="search_form">
        <div class="gcse-search" id="cse" style="width: 100%;"></div>
      </div>
    </div> <!-- end navbar --></div>
</div>


<!-- GitHub "fork me" ribbon -->
<a href="https://github.com/scikit-learn/scikit-learn">
  <img class="fork-me" style="position: absolute; top: 0; right: 0; border: 0;" src="../static/img/forkme.png"
    alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
  <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
      <div class="rel">
        
          <div class="rellink">
            <a href="covariance.html" accesskey="P">Previous
              <br />
              <span class="smallrellink">
                2.6. 协方差估计(Co...
              </span>
              <span class="hiddenrellink">
                2.6. 协方差估计(Covariance estimation)
              </span>
            </a>
          </div>
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="density.html" accesskey="N">Next
              <br />
              <span class="smallrellink">
                2.8. 概率密度估计(D...
              </span>
              <span class="hiddenrellink">
                2.8. 概率密度估计(Density Estimation)
              </span>
            </a>
          </div>

          <!-- Ad a link to the 'up' page -->
          <div class="spacer">
            &nbsp;
          </div>
          <div class="rellink">
            <a href="../unsupervised_learning.html">
              Up
              <br />
              <span class="smallrellink">
                2. 无监督学习(unsu...
              </span>
                <span class="hiddenrellink">
                  2. 无监督学习(unsupervised learning)
                </span>
                
            </a>
          </div>
        </div>
        
        <p class="doc-version"><b>scikit-learn v0.20.2</b><br />
          <a href="http://scikit-learn.org/dev/versions.html">其他版本</a></p>
        <!-- <p class="citing">Please <b><a href="../about.html#citing-scikit-learn" style="font-size: 110%;">cite
              us </a></b>if you use the software.</p> -->
        <p class="citing">该中文文档由人工智能社区的<a href="http://www.studyai.com/antares" target="_blank">Antares</a>翻译!
        </p>
        <ul>
<li><a class="reference internal" href="#">2.7. 新奇点和孤立点检测(Novelty and Outlier Detection)</a><ul>
<li><a class="reference internal" href="#id1">2.7.1. 孤立点检测方法一览</a></li>
<li><a class="reference internal" href="#novelty-detection">2.7.2. 新奇点检测(Novelty Detection)</a></li>
<li><a class="reference internal" href="#id2">2.7.3. 孤立点检测(Outlier Detection)</a><ul>
<li><a class="reference internal" href="#id3">2.7.3.1. 拟合椭圆包络</a></li>
<li><a class="reference internal" href="#isolation-forest">2.7.3.2. Isolation Forest</a></li>
<li><a class="reference internal" href="#id5">2.7.3.3. 局部离群因子</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lof">2.7.4. 使用LOF进行新奇点检测</a></li>
</ul>
</li>
</ul>

        <br />
        <p>
          <a href="http://www.studyai.com" target="_blank">
            <img src="../static/img/advitise1.png" alt="座右铭" />
          </a>
        </p>
        <br />
        <p class="doc-version" style="font-size:10%">
          注意!本网站的网址是以 <em>https://</em> 开头的，而不是以 <em>http://</em> 开头的!!!
        </p>
      </div>
    </div>
    
    <input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
    <label for="nav-trigger"></label>
    
    


    <div class="content">
      
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="novelty-and-outlier-detection">
<span id="outlier-detection"></span><h1>2.7. 新奇点和孤立点检测(Novelty and Outlier Detection)<a class="headerlink" href="#novelty-and-outlier-detection" title="Permalink to this headline">¶</a></h1>
<p>很多机器学习应用都需要有能力判断一个新的观测是否跟已有观测具有相同的分布，或者来自不同的分布。
如果来自于相同的分布，则这个新的观测就是一个 <em>inlier</em> ; 如果不同，则这个新的观测被称为 <em>outlier</em> 。
这种能力通常用于对真实的数据集进行清洗。首先我们要区分两个重要的概念:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">outlier detection:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body">训练数据中包含有一些outliers,它们被定义为远离其他观测值的观测值。所以，outliers应该译为“离群点，孤立点”。
孤立点检测器(Outlier detection estimators) 因此尝试在训练数据最集中的那些区域上进行拟合，
而忽略那些异常的观测值(deviant observations)。</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">novelty detection:</th></tr>
<tr class="field-even field"><td>&#160;</td><td class="field-body">已有的训练数据并没有被outliers污染，而我们感兴趣的是去检测一个 <strong>新来的</strong> 观测值是否是outlier。
在这样的一个语境下，此时的outlier我们称之为 novelty。
在这儿 ，我把 novelty 译为 “新奇点” ,意为 <strong>新来的奇怪的点</strong> 。</td>
</tr>
</tbody>
</table>
<p>孤立点检测 和 新奇点检测 都被用于异常检测(anomaly detection), 所谓anomaly detection就是
检测反常的的观测或不平常的观测。
孤立点检测 也被称之为 无监督异常检测; 而 新奇点检测 被称之为 半监督异常检测。
在孤立点检测的语境下, outliers/anomalies 不能够形成一个稠密的聚类簇，因为可用的estimators都假定了
outliers/anomalies 位于低密度区域。相反的，在新奇点检测的语境下， novelties/anomalies 是可以形成
稠密聚类簇(dense cluster)的，只要它们在训练数据的一个低密度区域，这被认为是正常的(normal)。</p>
<p>scikit-learn 提供了一系列机器学习工具可以被用于新奇点或孤立点检测。
这些检测策略被实现成一些 以无监督学习的方式从数据中学习 的估计器类(estimator):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>fit好了estimator以后，新的观测数据可以用 <code class="docutils literal notranslate"><span class="pre">predict</span></code> 方法判断其是 inliers or outliers？:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Inliers 被标记为 1, 而 outliers 被标记为 -1。 预测方法使用一个阈值在估计器计算出的原始评分函数上。
这个评分函数可以通过方法 <code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 进行访问，而且 这个阈值可以由参数 <code class="docutils literal notranslate"><span class="pre">contamination</span></code> 控制。</p>
<p><code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 方法也是从评分函数定义的，这样的话，得分为负值的就是 outliers, 得分为非负的就是 inliers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>请注意 <a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类默认不支持 <code class="docutils literal notranslate"><span class="pre">predict</span></code>, <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 和
<code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 方法，而只支持 <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> 方法, 因为这个 estimator 一开始就是要把它用到孤立点检测中去的。
训练样本的异常性得分(scores of abnormality)可以通过 <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> 属性来访问获取。</p>
<p>如果你真的特别想用 <a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类进行 新奇点检测(novelty detection),
i.e. 对新的未见过的样本 预测其标签或计算其异常性得分, 你可以在实例化这个estimator的时候将其
<code class="docutils literal notranslate"><span class="pre">novelty</span></code> 参数设为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，这一步必须要在拟合之前做。这样的话，<code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> 方法就不可用了。</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p><strong>使用局部异常因子(Local Outlier Factor,LOF)进行新奇点检测</strong></p>
<p class="last">当 <code class="docutils literal notranslate"><span class="pre">novelty</span></code> 参数被设为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，要当心 你必须只能使用 <code class="docutils literal notranslate"><span class="pre">predict</span></code>,
<code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 和 <code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 在新的未见过的数据上，而不能把这几个函数用在训练数据上，
因为这样会导致错误的结果。训练样本的异常性得分总是可以通过 <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> 属性来访问获取。</p>
</div>
<p><a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类在孤立点检测和新奇点检测中的行为被总结在下面的表格里啦。</p>
<table border="1" class="docutils">
<colgroup>
<col width="28%" />
<col width="43%" />
<col width="28%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Method</th>
<th class="head">Outlier detection</th>
<th class="head">Novelty detection</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">fit_predict</span></code></td>
<td>可用</td>
<td>不可用</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">predict</span></code></td>
<td>不可用</td>
<td>只能用于新数据</td>
</tr>
<tr class="row-even"><td><code class="docutils literal notranslate"><span class="pre">decision_function</span></code></td>
<td>不可用</td>
<td>只能用于新数据</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal notranslate"><span class="pre">score_samples</span></code></td>
<td>用 <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code></td>
<td>只能用于新数据</td>
</tr>
</tbody>
</table>
<div class="section" id="id1">
<h2>2.7.1. 孤立点检测方法一览<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>下面这个案例针对scikit-learn 中的所有孤立点检测算法进行了对比。
局部异常因子(LOF) 没有在图的背景上画出决策边界，因为在孤立点检测中使用LOF时
它没有 predict 方法可以用在新数据上（见上面表格）。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/plot_anomaly_comparison.html"><img alt="../images/sphx_glr_plot_anomaly_comparison_0011.png" src="../images/sphx_glr_plot_anomaly_comparison_0011.png" style="width: 550.0px; height: 625.0px;" /></a>
</div>
<p><a class="reference internal" href="generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="sklearn.ensemble.IsolationForest"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.IsolationForest</span></code></a> 和 <a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a>
在这里所用的数据集上表现得相当好。 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.OneClassSVM</span></code></a> 类对outliers本来就很敏感，
因此在outlier的检测中表现的不是很好。最后, <a class="reference internal" href="generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope" title="sklearn.covariance.EllipticEnvelope"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.EllipticEnvelope</span></code></a> 类
假定了数据是服从高斯分布的且要学习一个椭圆(ellipse)。关于这个对比试验中各种estimators的更多详细信息
请参考 <a class="reference internal" href="../auto_examples/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py"><span class="std std-ref">在各种toy数据集上比较用于孤立点检测的异常检测算法</span></a> 和后续小节。</p>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py"><span class="std std-ref">在各种toy数据集上比较用于孤立点检测的异常检测算法</span></a>
对比实验，包括了 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.OneClassSVM</span></code></a> 类, <a class="reference internal" href="generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="sklearn.ensemble.IsolationForest"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.IsolationForest</span></code></a> 类,
<a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类以及 <a class="reference internal" href="generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope" title="sklearn.covariance.EllipticEnvelope"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.EllipticEnvelope</span></code></a> 类。</li>
</ul>
</div>
</div>
<div class="section" id="novelty-detection">
<h2>2.7.2. 新奇点检测(Novelty Detection)<a class="headerlink" href="#novelty-detection" title="Permalink to this headline">¶</a></h2>
<p>我们现在有一个从相同的分布(该分布由 <span class="math notranslate nohighlight">\(p\)</span> 个特征分量描述)中得到的 <span class="math notranslate nohighlight">\(n\)</span> 个观测组成的数据集。
现在我们再往这个观测集合中添加一个新的观测(a new observation)。那么这个新加入的观测是否与该集合中旧有的那些观测
非常不一样以至于我们必须怀疑它是否是正常的(regular or not)? (也就是说这个新的观测是否来自于一个相同的分布？)
或者我们从反向考虑，这个新的观测是否与旧有的那些观测特别的相似以至于我们无法将它与原来的旧观测数据区别开来？
这就是 新奇点检测(novelty detection) 中要强调的问题和它要给我们提供的工具的用途。</p>
<p>一般情况下，新奇点检测器 将学习一个粗糙的、封闭的边界来划分初始观测分布的等高线，绘制在嵌入 <span class="math notranslate nohighlight">\(p\)</span> 维空间中。
然后，如果新的观测在边界分隔的子空间内(within the frontier-delimited subspace)，他们被认为来自相同的群体，
而不是最初的观测。否则，如果这些新观测数据身处边界之外，我们可以说他们是不正常的(abnormal)，
并且根据我们的评估给出一个置信度。</p>
<p>One-Class SVM 已经被 Schölkopf 引入来完成这样一个目的，而且它被实现在 <a class="reference internal" href="svm.html#svm"><span class="std std-ref">支持向量机(Support Vector Machines)</span></a> 模块中
的 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.OneClassSVM</span></code></a> 类中。 使用该类需要选择一个 kernel 和一个标量参数来定义上面提到的边界(frontier)。
RBF kernel 是通常的选项，尽管没有准确的公式或算法来设置RBF kernel的带宽参数(bandwidth)。
这是 scikit-learn 中的默认实现。 参数 <span class="math notranslate nohighlight">\(\nu\)</span> , 也被称为One-Class SVM的边界(margin),
对应于在边界外边(outside frontier)找到一个新的但是正常的观测的概率。</p>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li><a class="reference external" href="http://dl.acm.org/citation.cfm?id=1119749">Estimating the support of a high-dimensional distribution</a> Schölkopf,
Bernhard, et al. Neural computation 13.7 (2001): 1443-1471.</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/svm/plot_oneclass.html#sphx-glr-auto-examples-svm-plot-oneclass-py"><span class="std std-ref">One-class SVM with non-linear kernel (RBF)</span></a> 用于可视化 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.OneClassSVM</span></code></a> 类对象
从数据中学习到的边界(frontier)。</li>
<li><a class="reference internal" href="../auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">Species distribution modeling</span></a></li>
</ul>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/svm/plot_oneclass.html"><img alt="../images/sphx_glr_plot_oneclass_0011.png" src="../images/sphx_glr_plot_oneclass_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
</div>
<div class="section" id="id2">
<h2>2.7.3. 孤立点检测(Outlier Detection)<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>孤立点检测与新奇点检测类似，其目的是将常规观测的核心(a core of regular observations)
与一些污染性(polluting)观测分离开来，即所谓的离群点或孤立点(Outliers).
然而，在孤立点检测中，我们并没有一个干净的只包含常规观测的数据集用来训练估计器。</p>
<div class="section" id="id3">
<h3>2.7.3.1. 拟合椭圆包络<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>进行孤立点检测的一种常见方法是假定常规数据(regular data)来自于某个已知的分布(比如高斯分布)。
有了这样一个假定以后，我们试图从广义上定义数据的”shape”，并且定义 <strong>外围观测(outlying observations)</strong>
就是那些足够远离”shape”的观测。</p>
<p>scikit-learn 提供了一个对象 <a class="reference internal" href="generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope" title="sklearn.covariance.EllipticEnvelope"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.EllipticEnvelope</span></code></a> 可以在给定的数据上拟合一个鲁棒的协方差估计
, 并且因此拟合一个椭圆(ellipse)到中央数据点(central data points), 忽略那些远离中央的外围点。</p>
<p>比如, 假定 inlier data 是呈高斯分布的, 上述的类对象将会以鲁棒的方法估计inlier location和协方差
(即 此鲁棒估计不会受到数据集中的outliers的影响)。从这一鲁棒估计获得的Mahalanobis距离用来推导一个
衡量外围程度的度量(a measure of outlyingness)。
下面的图和实例说明了这一策略。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/covariance/plot_mahalanobis_distances.html"><img alt="../images/sphx_glr_plot_mahalanobis_distances_0011.png" src="../images/sphx_glr_plot_mahalanobis_distances_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/covariance/plot_mahalanobis_distances.html#sphx-glr-auto-examples-covariance-plot-mahalanobis-distances-py"><span class="std std-ref">Robust covariance estimation and Mahalanobis distances relevance</span></a> 。这个案例
用于说明 标准的经验协方差估计(<a class="reference internal" href="generated/sklearn.covariance.EmpiricalCovariance.html#sklearn.covariance.EmpiricalCovariance" title="sklearn.covariance.EmpiricalCovariance"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.EmpiricalCovariance</span></code></a>) 与
位置和协方差的鲁棒估计(<a class="reference internal" href="generated/sklearn.covariance.MinCovDet.html#sklearn.covariance.MinCovDet" title="sklearn.covariance.MinCovDet"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.MinCovDet</span></code></a>) 之间在评估一个观测的外围性的程度上的区别</li>
</ul>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li>Rousseeuw, P.J., Van Driessen, K. “A fast algorithm for the minimum
covariance determinant estimator” Technometrics 41(3), 212 (1999)</li>
</ul>
</div>
</div>
<div class="section" id="isolation-forest">
<span id="id4"></span><h3>2.7.3.2. Isolation Forest<a class="headerlink" href="#isolation-forest" title="Permalink to this headline">¶</a></h3>
<p>在高维数据集上进行孤立点检测的一个有效方法是使用随机森林。
<a class="reference internal" href="generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="sklearn.ensemble.IsolationForest"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.IsolationForest</span></code></a> 通过随机选择一个特征，然后在所选特征的最大值和最小值之间随机选择一个分割值来”分离(isolate)”观测集合。</p>
<p>由于递归划分可以用树结构表示，因此分离一个样本(isolate a sample)所需的分割数相当于从根节点到终止节点的路径长度。</p>
<p>这个路径长度(path length)，是这样一个随机树林中的平均值，是正规性(normality)和我们的决策函数的一种度量
(a measure of normality and our decision function)。</p>
<p>随机划分为异常数据(anomalies)产生明显较短的路径。因此，当随机树木的森林集体地对特定样本产生较短的路径长度时，这些特定样本很可能是异常样本。</p>
<p>该策略已在下面的例子中进行了说明。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/ensemble/plot_isolation_forest.html"><img alt="../images/sphx_glr_plot_isolation_forest_0011.png" src="../images/sphx_glr_plot_isolation_forest_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/ensemble/plot_isolation_forest.html#sphx-glr-auto-examples-ensemble-plot-isolation-forest-py"><span class="std std-ref">IsolationForest 例子</span></a> 。 这个例子是对类</li>
</ul>
<blockquote>
<div><a class="reference internal" href="generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="sklearn.ensemble.IsolationForest"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.IsolationForest</span></code></a> 的用法的示例说明。</div></blockquote>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py"><span class="std std-ref">在各种toy数据集上比较用于孤立点检测的异常检测算法</span></a></li>
</ul>
<blockquote>
<div>类 <a class="reference internal" href="generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" title="sklearn.ensemble.IsolationForest"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.IsolationForest</span></code></a> ，类 <a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a>,
类 <a class="reference internal" href="generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM" title="sklearn.svm.OneClassSVM"><code class="xref py py-class docutils literal notranslate"><span class="pre">svm.OneClassSVM</span></code></a> (调整为像孤立点检测方法一样执行) 以及
一个基于协方差的孤立点检测和 <a class="reference internal" href="generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope" title="sklearn.covariance.EllipticEnvelope"><code class="xref py py-class docutils literal notranslate"><span class="pre">covariance.EllipticEnvelope</span></code></a> 类。</div></blockquote>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li>Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. “Isolation forest.”
Data Mining, 2008. ICDM‘08. Eighth IEEE International Conference on.</li>
</ul>
</div>
</div>
<div class="section" id="id5">
<h3>2.7.3.3. 局部离群因子<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>在中高维数据集上进行孤立点检测的另一种有效方法是使用局部离群因子(Local Outlier Factor,LOF)算法。</p>
<p><a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> (LOF)算法计算反映观测数据异常程度(degree of abnormality)
的分数(称为局部离群因子)。它测量给定数据点相对于其邻域的局部密度偏差。
这样做的目的是检测那些密度比邻居低得多的样本。</p>
<p>在实践中，局部密度(local density)是从k近邻得到的。一个观测的LOF分数等于他的k近邻的平均局部密度和它自己的局部密度的比率：
一个正常的观测数据被期望有一个与它的邻居相似的局部密度，而异常的观测数据被期望有更小的局部密度。</p>
<p>所考虑的邻居数目k(即参数n_neighbors)通常比cluster必须包含的最小对象数目大，这样的话，
其他对象可以是相对于该cluster的本地异常值，此外，所考虑的邻居数目k小于可能是本地异常值的对象的最大关闭数。
在实践中，这类信息通常是不可得的，而取n_neighbors=20 似乎在一般情况下是很好的。
当异常值的比例很高时(如下面的示例所示，大于10%)，则 n_neighbors 应该更大(下面的示例中n_neighbors=35)。</p>
<p>LOF算法的优点在于它考虑了数据集的局部和全局特性：即使在异常样本具有不同的底层密度时，它表现地也很好。
问题不在于样品有多孤立，而在于它与周围的邻居之间有多孤立。</p>
<p>当使用 LOF 进行孤立点检测的时候，不能使用 <code class="docutils literal notranslate"><span class="pre">predict</span></code>, <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 和 <code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 方法，
只能使用 <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> 方法。训练样本的异常性得分可以通过 <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> 属性来获得。
注意当使用LOF算法进行新奇点检测的时候(<code class="docutils literal notranslate"><span class="pre">novelty</span></code> 设为 <code class="docutils literal notranslate"><span class="pre">True</span></code>)， <code class="docutils literal notranslate"><span class="pre">predict</span></code>, <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 和
<code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 函数可被用于新的未见过的观测数据。请查看 <a class="reference internal" href="#novelty-with-lof"><span class="std std-ref">使用LOF进行新奇点检测</span></a> 小节的说明。</p>
<p>该策略已在下面的例子中进行了说明。</p>
<div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/neighbors/plot_lof_outlier_detection.html"><img alt="../images/sphx_glr_plot_lof_outlier_detection_0011.png" src="../images/sphx_glr_plot_lof_outlier_detection_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
<div class="topic">
<p class="topic-title first">案例:</p>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/neighbors/plot_lof_outlier_detection.html#sphx-glr-auto-examples-neighbors-plot-lof-outlier-detection-py"><span class="std std-ref">Outlier detection with Local Outlier Factor (LOF)</span></a> 。这个例子展示了</li>
</ul>
<blockquote>
<div><a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类的用法的示例说明。</div></blockquote>
<ul class="simple">
<li>请看 <a class="reference internal" href="../auto_examples/plot_anomaly_comparison.html#sphx-glr-auto-examples-plot-anomaly-comparison-py"><span class="std std-ref">在各种toy数据集上比较用于孤立点检测的异常检测算法</span></a> 。这个例子将该算法</li>
</ul>
<blockquote>
<div>与其他的异常检测(anomaly detection)算法进行对比。</div></blockquote>
</div>
<div class="topic">
<p class="topic-title first">参考文献:</p>
<ul class="simple">
<li>Breunig, Kriegel, Ng, and Sander (2000)
<a class="reference external" href="http://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf">LOF: identifying density-based local outliers.</a>
Proc. ACM SIGMOD</li>
</ul>
</div>
</div>
</div>
<div class="section" id="lof">
<span id="novelty-with-lof"></span><h2>2.7.4. 使用LOF进行新奇点检测<a class="headerlink" href="#lof" title="Permalink to this headline">¶</a></h2>
<p>如果要用 <a class="reference internal" href="generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a> 类进行 新奇点检测,
i.e. 对新的未见过的样本 预测其标签或计算其异常性得分, 你可以在实例化这个estimator的时候将其
<code class="docutils literal notranslate"><span class="pre">novelty</span></code> 参数设为 <code class="docutils literal notranslate"><span class="pre">True</span></code> ，这一步必须要在拟合之前做:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">novelty</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">lof</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p>请注意 <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> 方法在这情况下就不可用了。</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p><strong>使用 局部异常因子(LOF) 进行新奇点检测</strong></p>
<p class="last">当 <code class="docutils literal notranslate"><span class="pre">novelty</span></code> 参数被设为 <code class="docutils literal notranslate"><span class="pre">True</span></code> 时，要当心 你必须只能使用 <code class="docutils literal notranslate"><span class="pre">predict</span></code>,
<code class="docutils literal notranslate"><span class="pre">decision_function</span></code> 和 <code class="docutils literal notranslate"><span class="pre">score_samples</span></code> 在新的未见过的数据上，而不能把这几个函数用在训练数据上，
因为这样会导致错误的结果。训练样本的异常性得分总是可以通过 <code class="docutils literal notranslate"><span class="pre">negative_outlier_factor_</span></code> 属性来访问获取。</p>
</div>
<p>使用 局部异常因子(LOF)进行新奇点检测 的示例见下图。</p>
<blockquote>
<div><div class="figure align-center">
<a class="reference external image-reference" href="../auto_examples/neighbors/plot_lof_novelty_detection.html"><img alt="../images/sphx_glr_plot_lof_novelty_detection_0011.png" src="../images/sphx_glr_plot_lof_novelty_detection_0011.png" style="width: 480.0px; height: 360.0px;" /></a>
</div>
</div></blockquote>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
  </div>
  
  <div class="footer">
    &copy; 2007 - 2018, scikit-learn developers (BSD License).
    <!--
    <a href="../_sources/modules/outlier_detection.rst.txt" rel="nofollow">Show this page source</a> -->
  </div>
  <div class="rel">
    
      <div class="buttonPrevious">
        <a href="covariance.html">Previous
        </a>
      </div>
      <div class="buttonNext">
        <a href="density.html">Next
        </a>
      </div>
      
    </div>

    
    <script>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) }; ga.l = +new Date;
      ga('create', 'UA-22606712-2', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    
    <script>
      (function () {
        var cx = '016639176250731907682:tjtqbvtvij0';
        var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
      })();
    </script>
  </body>
</html>